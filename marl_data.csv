,round,trainer,policy,episode_reward_max,episode_reward_min,episode_reward_mean,episode_len_mean,episodes_this_iter,policy_reward_min,policy_reward_max,policy_reward_mean,custom_metrics,hist_stats,sampler_perf,off_policy_estimator,num_healthy_workers,timesteps_total,timers,info,done,episodes_total,training_iteration,experiment_id,date,timestamp,time_this_iter_s,time_total_s,pid,hostname,node_ip,config,time_since_restore,timesteps_since_restore,iterations_since_restore,perf
0,0,MARL,gneJ12,-13116058146.125181,-13116058146.125181,-13116058146.125181,3093.0,1,-3968399839.5715966,-3968399839.5715966,-3968399839.5715966,{},"{'episode_reward': [-13116058146.125181], 'episode_lengths': [3093], 'policy_gneJ12_reward': [-3968399839.5715966], 'policy_light1_reward': [-9147658306.553596]}","{'mean_env_wait_ms': 13.845850187252534, 'mean_processing_ms': 1.9753338604740904, 'mean_inference_ms': 1.7608984861633712}",{},0,4000,"{'sample_time_ms': 70382.866, 'sample_throughput': 56.832, 'learn_time_ms': 16563.785, 'learn_throughput': 241.491}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.2, 'cur_lr': 0.001, 'total_loss': 858185699164160.0, 'policy_loss': -0.027891391568118706, 'vf_loss': 858185699164160.0, 'vf_explained_var': 8.009374e-08, 'kl': 0.05674701614771038, 'entropy': 1.5299798287451267, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.2, 'cur_lr': 0.001, 'total_loss': 4218081761034240.0, 'policy_loss': 0.004549157194560394, 'vf_loss': 4218081761034240.0, 'vf_explained_var': 4.8428774e-08, 'kl': 0.012202847865410149, 'entropy': 1.4125534072518349, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 4000, 'num_steps_trained': 4000}",False,1,1,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_18-41-32,1615761692,86.94569873809814,86.94569873809814,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",86.94569873809814,0,1,"{'cpu_util_percent': 28.1390243902439, 'ram_util_percent': 57.01056910569106}"
1,0,MARL,light1,-13116058146.125181,-13116058146.125181,-13116058146.125181,3093.0,1,-9147658306.553596,-9147658306.553596,-9147658306.553596,{},"{'episode_reward': [-13116058146.125181], 'episode_lengths': [3093], 'policy_gneJ12_reward': [-3968399839.5715966], 'policy_light1_reward': [-9147658306.553596]}","{'mean_env_wait_ms': 13.845850187252534, 'mean_processing_ms': 1.9753338604740904, 'mean_inference_ms': 1.7608984861633712}",{},0,4000,"{'sample_time_ms': 70382.866, 'sample_throughput': 56.832, 'learn_time_ms': 16563.785, 'learn_throughput': 241.491}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.2, 'cur_lr': 0.001, 'total_loss': 858185699164160.0, 'policy_loss': -0.027891391568118706, 'vf_loss': 858185699164160.0, 'vf_explained_var': 8.009374e-08, 'kl': 0.05674701614771038, 'entropy': 1.5299798287451267, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.2, 'cur_lr': 0.001, 'total_loss': 4218081761034240.0, 'policy_loss': 0.004549157194560394, 'vf_loss': 4218081761034240.0, 'vf_explained_var': 4.8428774e-08, 'kl': 0.012202847865410149, 'entropy': 1.4125534072518349, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 4000, 'num_steps_trained': 4000}",False,1,1,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_18-41-32,1615761692,86.94569873809814,86.94569873809814,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",86.94569873809814,0,1,"{'cpu_util_percent': 28.1390243902439, 'ram_util_percent': 57.01056910569106}"
2,1,MARL,gneJ12,-7573132672.541883,-13116058146.125181,-10344595409.333532,2696.0,1,-3968399839.5715966,-1556936693.5085864,-2762668266.5400915,{},"{'episode_reward': [-7573132672.541883, -13116058146.125181], 'episode_lengths': [2299, 3093], 'policy_gneJ12_reward': [-1556936693.5085864, -3968399839.5715966], 'policy_light1_reward': [-6016195979.033288, -9147658306.553596]}","{'mean_env_wait_ms': 13.868907145704963, 'mean_processing_ms': 1.9698276927612062, 'mean_inference_ms': 1.8147010719851528}",{},0,8000,"{'sample_time_ms': 70944.875, 'sample_throughput': 56.382, 'learn_time_ms': 17299.024, 'learn_throughput': 231.227}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.30000000000000004, 'cur_lr': 0.001, 'total_loss': 5634599900151808.0, 'policy_loss': -0.007129185643862002, 'vf_loss': 5634599900151808.0, 'vf_explained_var': -5.2154064e-08, 'kl': 0.01069889533391688, 'entropy': 1.6937955804169178, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.2, 'cur_lr': 0.001, 'total_loss': 1.2694086758694912e+16, 'policy_loss': -0.003315998619655147, 'vf_loss': 1.2694086758694912e+16, 'vf_explained_var': -7.4505806e-08, 'kl': 0.023836495474824915, 'entropy': 1.4461453221738338, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 8000, 'num_steps_trained': 8000}",False,2,2,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_18-43-02,1615761782,89.54055500030518,176.48625373840332,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",176.48625373840332,0,2,"{'cpu_util_percent': 39.460317460317476, 'ram_util_percent': 57.06666666666668}"
3,1,MARL,light1,-7573132672.541883,-13116058146.125181,-10344595409.333532,2696.0,1,-9147658306.553596,-6016195979.033288,-7581927142.793442,{},"{'episode_reward': [-7573132672.541883, -13116058146.125181], 'episode_lengths': [2299, 3093], 'policy_gneJ12_reward': [-1556936693.5085864, -3968399839.5715966], 'policy_light1_reward': [-6016195979.033288, -9147658306.553596]}","{'mean_env_wait_ms': 13.868907145704963, 'mean_processing_ms': 1.9698276927612062, 'mean_inference_ms': 1.8147010719851528}",{},0,8000,"{'sample_time_ms': 70944.875, 'sample_throughput': 56.382, 'learn_time_ms': 17299.024, 'learn_throughput': 231.227}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.30000000000000004, 'cur_lr': 0.001, 'total_loss': 5634599900151808.0, 'policy_loss': -0.007129185643862002, 'vf_loss': 5634599900151808.0, 'vf_explained_var': -5.2154064e-08, 'kl': 0.01069889533391688, 'entropy': 1.6937955804169178, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.2, 'cur_lr': 0.001, 'total_loss': 1.2694086758694912e+16, 'policy_loss': -0.003315998619655147, 'vf_loss': 1.2694086758694912e+16, 'vf_explained_var': -7.4505806e-08, 'kl': 0.023836495474824915, 'entropy': 1.4461453221738338, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 8000, 'num_steps_trained': 8000}",False,2,2,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_18-43-02,1615761782,89.54055500030518,176.48625373840332,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",176.48625373840332,0,2,"{'cpu_util_percent': 39.460317460317476, 'ram_util_percent': 57.06666666666668}"
4,2,MARL,gneJ12,-7573132672.541883,-27133052971.985477,-16090428636.124847,2817.25,2,-9822213661.916977,-1556936693.5085864,-4576741615.110197,{},"{'episode_reward': [-27133052971.985477, -16539470753.84684, -13116058146.125181, -7573132672.541883], 'episode_lengths': [2694, 3183, 3093, 2299], 'policy_gneJ12_reward': [-9822213661.916977, -2959416265.443628, -3968399839.5715966, -1556936693.5085864], 'policy_light1_reward': [-17310839310.06847, -13580054488.403181, -9147658306.553596, -6016195979.033288]}","{'mean_env_wait_ms': 13.924214882002977, 'mean_processing_ms': 2.2645617285196766, 'mean_inference_ms': 1.8701892962401354}",{},0,12000,"{'sample_time_ms': 73901.507, 'sample_throughput': 54.126, 'learn_time_ms': 17536.863, 'learn_throughput': 228.091}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.30000000000000004, 'cur_lr': 0.001, 'total_loss': 450311682523136.0, 'policy_loss': -0.009612728434149176, 'vf_loss': 450311682523136.0, 'vf_explained_var': -3.7252903e-09, 'kl': 0.029191472625825554, 'entropy': 1.5269905366003513, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.30000000000000004, 'cur_lr': 0.001, 'total_loss': 6671111244742656.0, 'policy_loss': -0.010034023376647383, 'vf_loss': 6671111244742656.0, 'vf_explained_var': -3.3527613e-08, 'kl': 0.00849348482734058, 'entropy': 1.4815295524895191, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 12000, 'num_steps_trained': 12000}",False,4,3,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_18-44-40,1615761880,97.82679796218872,274.31305170059204,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",274.31305170059204,0,3,"{'cpu_util_percent': 42.284671532846716, 'ram_util_percent': 56.99562043795621}"
5,2,MARL,light1,-7573132672.541883,-27133052971.985477,-16090428636.124847,2817.25,2,-17310839310.06847,-6016195979.033288,-11513687021.014633,{},"{'episode_reward': [-27133052971.985477, -16539470753.84684, -13116058146.125181, -7573132672.541883], 'episode_lengths': [2694, 3183, 3093, 2299], 'policy_gneJ12_reward': [-9822213661.916977, -2959416265.443628, -3968399839.5715966, -1556936693.5085864], 'policy_light1_reward': [-17310839310.06847, -13580054488.403181, -9147658306.553596, -6016195979.033288]}","{'mean_env_wait_ms': 13.924214882002977, 'mean_processing_ms': 2.2645617285196766, 'mean_inference_ms': 1.8701892962401354}",{},0,12000,"{'sample_time_ms': 73901.507, 'sample_throughput': 54.126, 'learn_time_ms': 17536.863, 'learn_throughput': 228.091}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.30000000000000004, 'cur_lr': 0.001, 'total_loss': 450311682523136.0, 'policy_loss': -0.009612728434149176, 'vf_loss': 450311682523136.0, 'vf_explained_var': -3.7252903e-09, 'kl': 0.029191472625825554, 'entropy': 1.5269905366003513, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.30000000000000004, 'cur_lr': 0.001, 'total_loss': 6671111244742656.0, 'policy_loss': -0.010034023376647383, 'vf_loss': 6671111244742656.0, 'vf_explained_var': -3.3527613e-08, 'kl': 0.00849348482734058, 'entropy': 1.4815295524895191, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 12000, 'num_steps_trained': 12000}",False,4,3,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_18-44-40,1615761880,97.82679796218872,274.31305170059204,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",274.31305170059204,0,3,"{'cpu_util_percent': 42.284671532846716, 'ram_util_percent': 56.99562043795621}"
6,3,MARL,gneJ12,-7573132672.541883,-27133052971.985477,-15509721880.2104,2867.2,1,-9822213661.916977,-1556936693.5085864,-4141117735.873332,{},"{'episode_reward': [-13186894856.55263, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684], 'episode_lengths': [3067, 3093, 2299, 2694, 3183], 'policy_gneJ12_reward': [-2398622218.9258766, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628], 'policy_light1_reward': [-10788272637.626764, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181]}","{'mean_env_wait_ms': 13.879053845995212, 'mean_processing_ms': 2.295491085467886, 'mean_inference_ms': 1.8757845522733632}",{},0,16000,"{'sample_time_ms': 72103.953, 'sample_throughput': 55.475, 'learn_time_ms': 17333.144, 'learn_throughput': 230.772}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 717183306956800.0, 'policy_loss': -0.0004095069889444858, 'vf_loss': 717183306956800.0, 'vf_explained_var': -1.4901161e-08, 'kl': 0.013964384655992035, 'entropy': 1.5649900659918785, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.30000000000000004, 'cur_lr': 0.001, 'total_loss': 7273185296777216.0, 'policy_loss': -0.008387312962440774, 'vf_loss': 7273185296777216.0, 'vf_explained_var': -4.0978193e-08, 'kl': 0.015121715347049758, 'entropy': 1.5063241124153137, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 16000, 'num_steps_trained': 16000}",False,5,4,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_18-46-03,1615761963,83.43381929397583,357.74687099456787,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",357.74687099456787,0,4,"{'cpu_util_percent': 31.399145299145303, 'ram_util_percent': 55.842735042735036}"
7,3,MARL,light1,-7573132672.541883,-27133052971.985477,-15509721880.2104,2867.2,1,-17310839310.06847,-6016195979.033288,-11368604144.33706,{},"{'episode_reward': [-13186894856.55263, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684], 'episode_lengths': [3067, 3093, 2299, 2694, 3183], 'policy_gneJ12_reward': [-2398622218.9258766, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628], 'policy_light1_reward': [-10788272637.626764, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181]}","{'mean_env_wait_ms': 13.879053845995212, 'mean_processing_ms': 2.295491085467886, 'mean_inference_ms': 1.8757845522733632}",{},0,16000,"{'sample_time_ms': 72103.953, 'sample_throughput': 55.475, 'learn_time_ms': 17333.144, 'learn_throughput': 230.772}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 717183306956800.0, 'policy_loss': -0.0004095069889444858, 'vf_loss': 717183306956800.0, 'vf_explained_var': -1.4901161e-08, 'kl': 0.013964384655992035, 'entropy': 1.5649900659918785, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.30000000000000004, 'cur_lr': 0.001, 'total_loss': 7273185296777216.0, 'policy_loss': -0.008387312962440774, 'vf_loss': 7273185296777216.0, 'vf_explained_var': -4.0978193e-08, 'kl': 0.015121715347049758, 'entropy': 1.5063241124153137, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 16000, 'num_steps_trained': 16000}",False,5,4,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_18-46-03,1615761963,83.43381929397583,357.74687099456787,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",357.74687099456787,0,4,"{'cpu_util_percent': 31.399145299145303, 'ram_util_percent': 55.842735042735036}"
8,4,MARL,gneJ12,-6512142718.846902,-27133052971.985477,-14287698913.391882,2796.1428571428573,2,-9822213661.916977,-1085759341.428287,-3615360065.000715,{},"{'episode_reward': [-15953140273.844273, -6512142718.846902, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263], 'episode_lengths': [2493, 2744, 3093, 2299, 2694, 3183, 3067], 'policy_gneJ12_reward': [-3516172434.210055, -1085759341.428287, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766], 'policy_light1_reward': [-12436967839.634207, -5426383377.418624, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764]}","{'mean_env_wait_ms': 13.754051815408987, 'mean_processing_ms': 2.439832401820289, 'mean_inference_ms': 1.8759777378705265}",{},0,20000,"{'sample_time_ms': 72514.217, 'sample_throughput': 55.162, 'learn_time_ms': 17126.108, 'learn_throughput': 233.562}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 312774537248768.0, 'policy_loss': -0.0051517671381589025, 'vf_loss': 312774537248768.0, 'vf_explained_var': -2.9802322e-08, 'kl': 0.008786997430433985, 'entropy': 1.3677632063627243, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.30000000000000004, 'cur_lr': 0.001, 'total_loss': 3875472043671552.0, 'policy_loss': -0.012209633365273476, 'vf_loss': 3875472043671552.0, 'vf_explained_var': -1.1175871e-08, 'kl': 0.013964678728370927, 'entropy': 1.3458774648606777, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 20000, 'num_steps_trained': 20000}",False,7,5,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_18-47-33,1615762053,90.45295214653015,448.199823141098,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",448.199823141098,0,5,"{'cpu_util_percent': 28.336220472440942, 'ram_util_percent': 55.85039370078739}"
9,4,MARL,light1,-6512142718.846902,-27133052971.985477,-14287698913.391882,2796.1428571428573,2,-17310839310.06847,-5426383377.418624,-10672338848.391161,{},"{'episode_reward': [-15953140273.844273, -6512142718.846902, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263], 'episode_lengths': [2493, 2744, 3093, 2299, 2694, 3183, 3067], 'policy_gneJ12_reward': [-3516172434.210055, -1085759341.428287, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766], 'policy_light1_reward': [-12436967839.634207, -5426383377.418624, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764]}","{'mean_env_wait_ms': 13.754051815408987, 'mean_processing_ms': 2.439832401820289, 'mean_inference_ms': 1.8759777378705265}",{},0,20000,"{'sample_time_ms': 72514.217, 'sample_throughput': 55.162, 'learn_time_ms': 17126.108, 'learn_throughput': 233.562}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 312774537248768.0, 'policy_loss': -0.0051517671381589025, 'vf_loss': 312774537248768.0, 'vf_explained_var': -2.9802322e-08, 'kl': 0.008786997430433985, 'entropy': 1.3677632063627243, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.30000000000000004, 'cur_lr': 0.001, 'total_loss': 3875472043671552.0, 'policy_loss': -0.012209633365273476, 'vf_loss': 3875472043671552.0, 'vf_explained_var': -1.1175871e-08, 'kl': 0.013964678728370927, 'entropy': 1.3458774648606777, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 20000, 'num_steps_trained': 20000}",False,7,5,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_18-47-33,1615762053,90.45295214653015,448.199823141098,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",448.199823141098,0,5,"{'cpu_util_percent': 28.336220472440942, 'ram_util_percent': 55.85039370078739}"
10,5,MARL,gneJ12,-6512142718.846902,-27133052971.985477,-14252280791.784105,2761.25,1,-9822213661.916977,-1085759341.428287,-3501580394.660828,{},"{'episode_reward': [-14004353940.529661, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902], 'episode_lengths': [2517, 3093, 2299, 2694, 3183, 3067, 2493, 2744], 'policy_gneJ12_reward': [-2705122702.2816195, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287], 'policy_light1_reward': [-11299231238.24798, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624]}","{'mean_env_wait_ms': 13.708371196897858, 'mean_processing_ms': 2.4707266238169288, 'mean_inference_ms': 1.8740101218447176}",{},0,24000,"{'sample_time_ms': 71781.752, 'sample_throughput': 55.724, 'learn_time_ms': 17065.328, 'learn_throughput': 234.393}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 2020796360818688.0, 'policy_loss': -0.0004351408570073545, 'vf_loss': 2020796360818688.0, 'vf_explained_var': -3.1664968e-08, 'kl': 0.009231676260242239, 'entropy': 1.510474644601345, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.30000000000000004, 'cur_lr': 0.001, 'total_loss': 1.1083993562742784e+16, 'policy_loss': -0.018209146612207405, 'vf_loss': 1.1083993562742784e+16, 'vf_explained_var': 1.1175871e-08, 'kl': 0.011929274260182865, 'entropy': 1.4148469865322113, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 24000, 'num_steps_trained': 24000}",False,8,6,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_18-48-58,1615762138,84.88104605674744,533.0808691978455,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",533.0808691978455,0,6,"{'cpu_util_percent': 29.725833333333338, 'ram_util_percent': 55.85333333333332}"
11,5,MARL,light1,-6512142718.846902,-27133052971.985477,-14252280791.784105,2761.25,1,-17310839310.06847,-5426383377.418624,-10750700397.123264,{},"{'episode_reward': [-14004353940.529661, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902], 'episode_lengths': [2517, 3093, 2299, 2694, 3183, 3067, 2493, 2744], 'policy_gneJ12_reward': [-2705122702.2816195, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287], 'policy_light1_reward': [-11299231238.24798, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624]}","{'mean_env_wait_ms': 13.708371196897858, 'mean_processing_ms': 2.4707266238169288, 'mean_inference_ms': 1.8740101218447176}",{},0,24000,"{'sample_time_ms': 71781.752, 'sample_throughput': 55.724, 'learn_time_ms': 17065.328, 'learn_throughput': 234.393}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 2020796360818688.0, 'policy_loss': -0.0004351408570073545, 'vf_loss': 2020796360818688.0, 'vf_explained_var': -3.1664968e-08, 'kl': 0.009231676260242239, 'entropy': 1.510474644601345, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.30000000000000004, 'cur_lr': 0.001, 'total_loss': 1.1083993562742784e+16, 'policy_loss': -0.018209146612207405, 'vf_loss': 1.1083993562742784e+16, 'vf_explained_var': 1.1175871e-08, 'kl': 0.011929274260182865, 'entropy': 1.4148469865322113, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 24000, 'num_steps_trained': 24000}",False,8,6,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_18-48-58,1615762138,84.88104605674744,533.0808691978455,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",533.0808691978455,0,6,"{'cpu_util_percent': 29.725833333333338, 'ram_util_percent': 55.85333333333332}"
12,6,MARL,gneJ12,-6448153420.684994,-27133052971.985477,-13736303936.777739,2646.0,2,-9822213661.916977,-1085759341.428287,-3394228948.8389397,{},"{'episode_reward': [-16896639612.819538, -6448153420.684994, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661], 'episode_lengths': [2236, 2134, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517], 'policy_gneJ12_reward': [-4833371426.223814, -1096274904.8789558, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195], 'policy_light1_reward': [-12063268186.595642, -5351878515.806033, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798]}","{'mean_env_wait_ms': 13.616005114453094, 'mean_processing_ms': 2.548333846385794, 'mean_inference_ms': 1.868687126080762}",{},0,28000,"{'sample_time_ms': 71848.542, 'sample_throughput': 55.673, 'learn_time_ms': 16948.214, 'learn_throughput': 236.013}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 156511508365312.0, 'policy_loss': -0.014908598735928535, 'vf_loss': 156511508365312.0, 'vf_explained_var': 1.3038516e-08, 'kl': 0.018745032532024197, 'entropy': 1.3199479132890701, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.30000000000000004, 'cur_lr': 0.001, 'total_loss': 4046985095020544.0, 'policy_loss': -0.011038403870770708, 'vf_loss': 4046985095020544.0, 'vf_explained_var': -1.15484e-07, 'kl': 0.014216754207154736, 'entropy': 1.2510941177606583, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 28000, 'num_steps_trained': 28000}",False,10,7,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_18-50-27,1615762227,88.49442672729492,621.5752959251404,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",621.5752959251404,0,7,"{'cpu_util_percent': 28.487903225806452, 'ram_util_percent': 55.89677419354836}"
13,6,MARL,light1,-6448153420.684994,-27133052971.985477,-13736303936.777739,2646.0,2,-17310839310.06847,-5351878515.806033,-10342074987.938778,{},"{'episode_reward': [-16896639612.819538, -6448153420.684994, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661], 'episode_lengths': [2236, 2134, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517], 'policy_gneJ12_reward': [-4833371426.223814, -1096274904.8789558, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195], 'policy_light1_reward': [-12063268186.595642, -5351878515.806033, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798]}","{'mean_env_wait_ms': 13.616005114453094, 'mean_processing_ms': 2.548333846385794, 'mean_inference_ms': 1.868687126080762}",{},0,28000,"{'sample_time_ms': 71848.542, 'sample_throughput': 55.673, 'learn_time_ms': 16948.214, 'learn_throughput': 236.013}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 156511508365312.0, 'policy_loss': -0.014908598735928535, 'vf_loss': 156511508365312.0, 'vf_explained_var': 1.3038516e-08, 'kl': 0.018745032532024197, 'entropy': 1.3199479132890701, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.30000000000000004, 'cur_lr': 0.001, 'total_loss': 4046985095020544.0, 'policy_loss': -0.011038403870770708, 'vf_loss': 4046985095020544.0, 'vf_explained_var': -1.15484e-07, 'kl': 0.014216754207154736, 'entropy': 1.2510941177606583, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 28000, 'num_steps_trained': 28000}",False,10,7,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_18-50-27,1615762227,88.49442672729492,621.5752959251404,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",621.5752959251404,0,7,"{'cpu_util_percent': 28.487903225806452, 'ram_util_percent': 55.89677419354836}"
14,7,MARL,gneJ12,-3687500179.839026,-27133052971.985477,-12616432381.641222,2617.5833333333335,2,-9822213661.916977,-536462358.0920263,-3010276332.658194,{},"{'episode_reward': [-10346649032.078262, -3687500179.839026, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994], 'episode_lengths': [2387, 2564, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134], 'policy_gneJ12_reward': [-1644564145.4169137, -536462358.0920263, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558], 'policy_light1_reward': [-8702084886.661364, -3151037821.747003, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033]}","{'mean_env_wait_ms': 13.535938107444423, 'mean_processing_ms': 2.6184428798637893, 'mean_inference_ms': 1.864141601543911}",{},0,32000,"{'sample_time_ms': 71821.209, 'sample_throughput': 55.694, 'learn_time_ms': 16839.641, 'learn_throughput': 237.535}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 116470557442048.0, 'policy_loss': -0.0021668720291927457, 'vf_loss': 116470557442048.0, 'vf_explained_var': -5.5879354e-09, 'kl': 0.014281760901212692, 'entropy': 1.3333834782242775, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.30000000000000004, 'cur_lr': 0.001, 'total_loss': 2679690674307072.0, 'policy_loss': -0.0024418121902272105, 'vf_loss': 2679690674307072.0, 'vf_explained_var': -4.0978193e-08, 'kl': 0.030044507555430755, 'entropy': 1.120599951595068, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 32000, 'num_steps_trained': 32000}",False,12,8,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_18-51-55,1615762315,87.70916199684143,709.2844579219818,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",709.2844579219818,0,8,"{'cpu_util_percent': 28.350406504065038, 'ram_util_percent': 55.89999999999998}"
15,7,MARL,light1,-3687500179.839026,-27133052971.985477,-12616432381.641222,2617.5833333333335,2,-17310839310.06847,-3151037821.747003,-9606156048.983013,{},"{'episode_reward': [-10346649032.078262, -3687500179.839026, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994], 'episode_lengths': [2387, 2564, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134], 'policy_gneJ12_reward': [-1644564145.4169137, -536462358.0920263, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558], 'policy_light1_reward': [-8702084886.661364, -3151037821.747003, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033]}","{'mean_env_wait_ms': 13.535938107444423, 'mean_processing_ms': 2.6184428798637893, 'mean_inference_ms': 1.864141601543911}",{},0,32000,"{'sample_time_ms': 71821.209, 'sample_throughput': 55.694, 'learn_time_ms': 16839.641, 'learn_throughput': 237.535}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 116470557442048.0, 'policy_loss': -0.0021668720291927457, 'vf_loss': 116470557442048.0, 'vf_explained_var': -5.5879354e-09, 'kl': 0.014281760901212692, 'entropy': 1.3333834782242775, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.30000000000000004, 'cur_lr': 0.001, 'total_loss': 2679690674307072.0, 'policy_loss': -0.0024418121902272105, 'vf_loss': 2679690674307072.0, 'vf_explained_var': -4.0978193e-08, 'kl': 0.030044507555430755, 'entropy': 1.120599951595068, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 32000, 'num_steps_trained': 32000}",False,12,8,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_18-51-55,1615762315,87.70916199684143,709.2844579219818,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",709.2844579219818,0,8,"{'cpu_util_percent': 28.350406504065038, 'ram_util_percent': 55.89999999999998}"
16,8,MARL,gneJ12,-3687500179.839026,-27133052971.985477,-12607523173.182844,2593.923076923077,1,-9822213661.916977,-536462358.0920263,-2969933959.7952375,{},"{'episode_reward': [-12500612671.682323, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026], 'episode_lengths': [2310, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564], 'policy_gneJ12_reward': [-2485825485.4397535, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263], 'policy_light1_reward': [-10014787186.24253, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003]}","{'mean_env_wait_ms': 13.500933205515246, 'mean_processing_ms': 2.6374189741141416, 'mean_inference_ms': 1.8619255351484698}",{},0,36000,"{'sample_time_ms': 71162.166, 'sample_throughput': 56.21, 'learn_time_ms': 16771.098, 'learn_throughput': 238.506}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 459614645649408.0, 'policy_loss': -0.007866687898058444, 'vf_loss': 459614645649408.0, 'vf_explained_var': 9.313226e-09, 'kl': 0.008462875630357303, 'entropy': 1.3674688674509525, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 3787844686446592.0, 'policy_loss': -0.013810749893309548, 'vf_loss': 3787844686446592.0, 'vf_explained_var': 4.0978193e-08, 'kl': 0.014542437696945854, 'entropy': 1.030644915997982, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 36000, 'num_steps_trained': 36000}",False,13,9,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_18-53-17,1615762397,82.11264300346375,791.3971009254456,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",791.3971009254456,0,9,"{'cpu_util_percent': 30.895652173913042, 'ram_util_percent': 55.89999999999998}"
17,8,MARL,light1,-3687500179.839026,-27133052971.985477,-12607523173.182844,2593.923076923077,1,-17310839310.06847,-3151037821.747003,-9637589213.387592,{},"{'episode_reward': [-12500612671.682323, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026], 'episode_lengths': [2310, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564], 'policy_gneJ12_reward': [-2485825485.4397535, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263], 'policy_light1_reward': [-10014787186.24253, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003]}","{'mean_env_wait_ms': 13.500933205515246, 'mean_processing_ms': 2.6374189741141416, 'mean_inference_ms': 1.8619255351484698}",{},0,36000,"{'sample_time_ms': 71162.166, 'sample_throughput': 56.21, 'learn_time_ms': 16771.098, 'learn_throughput': 238.506}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 459614645649408.0, 'policy_loss': -0.007866687898058444, 'vf_loss': 459614645649408.0, 'vf_explained_var': 9.313226e-09, 'kl': 0.008462875630357303, 'entropy': 1.3674688674509525, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 3787844686446592.0, 'policy_loss': -0.013810749893309548, 'vf_loss': 3787844686446592.0, 'vf_explained_var': 4.0978193e-08, 'kl': 0.014542437696945854, 'entropy': 1.030644915997982, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 36000, 'num_steps_trained': 36000}",False,13,9,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_18-53-17,1615762397,82.11264300346375,791.3971009254456,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",791.3971009254456,0,9,"{'cpu_util_percent': 30.895652173913042, 'ram_util_percent': 55.89999999999998}"
18,9,MARL,gneJ12,-3687500179.839026,-27133052971.985477,-12166542991.481924,2640.3333333333335,2,-9822213661.916977,-536462358.0920263,-2704184875.457529,{},"{'episode_reward': [-4491168260.46376, -14109175360.388123, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323], 'episode_lengths': [3070, 2814, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310], 'policy_gneJ12_reward': [-633971142.2095352, -1319660512.3153203, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535], 'policy_light1_reward': [-3857197118.254221, -12789514848.072807, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253]}","{'mean_env_wait_ms': 13.438299348080358, 'mean_processing_ms': 2.68188913320028, 'mean_inference_ms': 1.857548395278287}",{},0,40000,"{'sample_time_ms': 71361.475, 'sample_throughput': 56.053, 'learn_time_ms': 16784.358, 'learn_throughput': 238.317}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 99083639586816.0, 'policy_loss': -0.008108712470857427, 'vf_loss': 99083639586816.0, 'vf_explained_var': 9.313226e-09, 'kl': 0.017709923879010603, 'entropy': 1.4344734959304333, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 6465117432578048.0, 'policy_loss': -0.009905358834657818, 'vf_loss': 6465117432578048.0, 'vf_explained_var': -3.7252903e-09, 'kl': 0.012050745557644404, 'entropy': 1.0592906195670366, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 40000, 'num_steps_trained': 40000}",False,15,10,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_18-54-47,1615762487,90.05853223800659,881.4556331634521,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",881.4556331634521,0,10,"{'cpu_util_percent': 28.740476190476187, 'ram_util_percent': 55.92460317460317}"
19,9,MARL,light1,-3687500179.839026,-27133052971.985477,-12166542991.481924,2640.3333333333335,2,-17310839310.06847,-3151037821.747003,-9462358116.024382,{},"{'episode_reward': [-4491168260.46376, -14109175360.388123, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323], 'episode_lengths': [3070, 2814, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310], 'policy_gneJ12_reward': [-633971142.2095352, -1319660512.3153203, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535], 'policy_light1_reward': [-3857197118.254221, -12789514848.072807, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253]}","{'mean_env_wait_ms': 13.438299348080358, 'mean_processing_ms': 2.68188913320028, 'mean_inference_ms': 1.857548395278287}",{},0,40000,"{'sample_time_ms': 71361.475, 'sample_throughput': 56.053, 'learn_time_ms': 16784.358, 'learn_throughput': 238.317}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 99083639586816.0, 'policy_loss': -0.008108712470857427, 'vf_loss': 99083639586816.0, 'vf_explained_var': 9.313226e-09, 'kl': 0.017709923879010603, 'entropy': 1.4344734959304333, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 6465117432578048.0, 'policy_loss': -0.009905358834657818, 'vf_loss': 6465117432578048.0, 'vf_explained_var': -3.7252903e-09, 'kl': 0.012050745557644404, 'entropy': 1.0592906195670366, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 40000, 'num_steps_trained': 40000}",False,15,10,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_18-54-47,1615762487,90.05853223800659,881.4556331634521,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",881.4556331634521,0,10,"{'cpu_util_percent': 28.740476190476187, 'ram_util_percent': 55.92460317460317}"
20,10,MARL,gneJ12,-3687500179.839026,-27133052971.985477,-12200708933.727596,2665.0625,1,-9822213661.916977,-536462358.0920263,-2633562811.4321404,{},"{'episode_reward': [-12713198067.412659, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123], 'episode_lengths': [3036, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814], 'policy_gneJ12_reward': [-1574231851.051301, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203], 'policy_light1_reward': [-11138966216.361372, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807]}","{'mean_env_wait_ms': 13.416980886725732, 'mean_processing_ms': 2.6954199427243704, 'mean_inference_ms': 1.857209949387133}",{},0,44000,"{'sample_time_ms': 71532.294, 'sample_throughput': 55.919, 'learn_time_ms': 16917.93, 'learn_throughput': 236.436}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 159193926991872.0, 'policy_loss': -0.014567490958143026, 'vf_loss': 159193926991872.0, 'vf_explained_var': 3.1664968e-08, 'kl': 0.013154421612853184, 'entropy': 1.3071151226758957, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 5840737434337280.0, 'policy_loss': -0.01232924940995872, 'vf_loss': 5840737434337280.0, 'vf_explained_var': 5.9604645e-08, 'kl': 0.013722310031880625, 'entropy': 1.061469953507185, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 44000, 'num_steps_trained': 44000}",False,16,11,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_18-56-17,1615762577,89.99157476425171,971.4472079277039,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",971.4472079277039,0,11,"{'cpu_util_percent': 39.511111111111106, 'ram_util_percent': 56.27936507936511}"
21,10,MARL,light1,-3687500179.839026,-27133052971.985477,-12200708933.727596,2665.0625,1,-17310839310.06847,-3151037821.747003,-9567146122.295443,{},"{'episode_reward': [-12713198067.412659, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123], 'episode_lengths': [3036, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814], 'policy_gneJ12_reward': [-1574231851.051301, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203], 'policy_light1_reward': [-11138966216.361372, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807]}","{'mean_env_wait_ms': 13.416980886725732, 'mean_processing_ms': 2.6954199427243704, 'mean_inference_ms': 1.857209949387133}",{},0,44000,"{'sample_time_ms': 71532.294, 'sample_throughput': 55.919, 'learn_time_ms': 16917.93, 'learn_throughput': 236.436}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 159193926991872.0, 'policy_loss': -0.014567490958143026, 'vf_loss': 159193926991872.0, 'vf_explained_var': 3.1664968e-08, 'kl': 0.013154421612853184, 'entropy': 1.3071151226758957, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 5840737434337280.0, 'policy_loss': -0.01232924940995872, 'vf_loss': 5840737434337280.0, 'vf_explained_var': 5.9604645e-08, 'kl': 0.013722310031880625, 'entropy': 1.061469953507185, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 44000, 'num_steps_trained': 44000}",False,16,11,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_18-56-17,1615762577,89.99157476425171,971.4472079277039,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",971.4472079277039,0,11,"{'cpu_util_percent': 39.511111111111106, 'ram_util_percent': 56.27936507936511}"
22,11,MARL,gneJ12,-3687500179.839026,-27133052971.985477,-12707984241.89059,2661.5555555555557,2,-9822213661.916977,-536462358.0920263,-2884823773.94905,{},"{'episode_reward': [-11552320043.761782, -21980053370.627327, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659], 'episode_lengths': [2567, 2700, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036], 'policy_gneJ12_reward': [-1364616194.8083677, -8425206753.36029, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301], 'policy_light1_reward': [-10187703848.953398, -13554846617.26706, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372]}","{'mean_env_wait_ms': 13.395494436234667, 'mean_processing_ms': 2.731040002900895, 'mean_inference_ms': 1.858555101370329}",{},0,48000,"{'sample_time_ms': 72778.581, 'sample_throughput': 54.961, 'learn_time_ms': 16926.837, 'learn_throughput': 236.311}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 4108898524987392.0, 'policy_loss': 0.007693259249208495, 'vf_loss': 4108898524987392.0, 'vf_explained_var': 5.7742e-08, 'kl': 0.016920745038078167, 'entropy': 1.4212154224514961, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 1.0123795876544512e+16, 'policy_loss': -0.010400134313385934, 'vf_loss': 1.0123795876544512e+16, 'vf_explained_var': -4.4703484e-08, 'kl': 0.013943836180260405, 'entropy': 1.1547349244356155, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 48000, 'num_steps_trained': 48000}",False,18,12,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_18-57-59,1615762679,102.09284925460815,1073.540057182312,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1073.540057182312,0,12,"{'cpu_util_percent': 37.726056338028165, 'ram_util_percent': 56.169014084507026}"
23,11,MARL,light1,-3687500179.839026,-27133052971.985477,-12707984241.89059,2661.5555555555557,2,-17310839310.06847,-3151037821.747003,-9823160467.94153,{},"{'episode_reward': [-11552320043.761782, -21980053370.627327, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659], 'episode_lengths': [2567, 2700, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036], 'policy_gneJ12_reward': [-1364616194.8083677, -8425206753.36029, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301], 'policy_light1_reward': [-10187703848.953398, -13554846617.26706, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372]}","{'mean_env_wait_ms': 13.395494436234667, 'mean_processing_ms': 2.731040002900895, 'mean_inference_ms': 1.858555101370329}",{},0,48000,"{'sample_time_ms': 72778.581, 'sample_throughput': 54.961, 'learn_time_ms': 16926.837, 'learn_throughput': 236.311}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 4108898524987392.0, 'policy_loss': 0.007693259249208495, 'vf_loss': 4108898524987392.0, 'vf_explained_var': 5.7742e-08, 'kl': 0.016920745038078167, 'entropy': 1.4212154224514961, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 1.0123795876544512e+16, 'policy_loss': -0.010400134313385934, 'vf_loss': 1.0123795876544512e+16, 'vf_explained_var': -4.4703484e-08, 'kl': 0.013943836180260405, 'entropy': 1.1547349244356155, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 48000, 'num_steps_trained': 48000}",False,18,12,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_18-57-59,1615762679,102.09284925460815,1073.540057182312,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1073.540057182312,0,12,"{'cpu_util_percent': 37.726056338028165, 'ram_util_percent': 56.169014084507026}"
24,12,MARL,gneJ12,-3687500179.839026,-27133052971.985477,-12649173532.796074,2666.1052631578946,1,-9822213661.916977,-536462358.0920263,-2813955627.396549,{},"{'episode_reward': [-11590580769.094769, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327], 'episode_lengths': [2748, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700], 'policy_gneJ12_reward': [-1538328989.4515386, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029], 'policy_light1_reward': [-10052251779.643225, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706]}","{'mean_env_wait_ms': 13.388680425439631, 'mean_processing_ms': 2.7419812983469973, 'mean_inference_ms': 1.8597208161386711}",{},0,52000,"{'sample_time_ms': 71923.481, 'sample_throughput': 55.615, 'learn_time_ms': 16907.595, 'learn_throughput': 236.58}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 153213278093312.0, 'policy_loss': -0.009876816591713578, 'vf_loss': 153213278093312.0, 'vf_explained_var': -4.0978193e-08, 'kl': 0.012096127233235165, 'entropy': 1.2363036163151264, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 4508559660285952.0, 'policy_loss': -0.007614141795784235, 'vf_loss': 4508559660285952.0, 'vf_explained_var': -6.7055225e-08, 'kl': 0.01244496344588697, 'entropy': 1.0587528869509697, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 52000, 'num_steps_trained': 52000}",False,19,13,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_18-59-28,1615762768,89.08365321159363,1162.6237103939056,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1162.6237103939056,0,13,"{'cpu_util_percent': 39.4576, 'ram_util_percent': 56.227199999999996}"
25,12,MARL,light1,-3687500179.839026,-27133052971.985477,-12649173532.796074,2666.1052631578946,1,-17310839310.06847,-3151037821.747003,-9835217905.399511,{},"{'episode_reward': [-11590580769.094769, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327], 'episode_lengths': [2748, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700], 'policy_gneJ12_reward': [-1538328989.4515386, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029], 'policy_light1_reward': [-10052251779.643225, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706]}","{'mean_env_wait_ms': 13.388680425439631, 'mean_processing_ms': 2.7419812983469973, 'mean_inference_ms': 1.8597208161386711}",{},0,52000,"{'sample_time_ms': 71923.481, 'sample_throughput': 55.615, 'learn_time_ms': 16907.595, 'learn_throughput': 236.58}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 153213278093312.0, 'policy_loss': -0.009876816591713578, 'vf_loss': 153213278093312.0, 'vf_explained_var': -4.0978193e-08, 'kl': 0.012096127233235165, 'entropy': 1.2363036163151264, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 4508559660285952.0, 'policy_loss': -0.007614141795784235, 'vf_loss': 4508559660285952.0, 'vf_explained_var': -6.7055225e-08, 'kl': 0.01244496344588697, 'entropy': 1.0587528869509697, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 52000, 'num_steps_trained': 52000}",False,19,13,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_18-59-28,1615762768,89.08365321159363,1162.6237103939056,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1162.6237103939056,0,13,"{'cpu_util_percent': 39.4576, 'ram_util_percent': 56.227199999999996}"
26,13,MARL,gneJ12,-3687500179.839026,-27133052971.985477,-12198976007.800129,2603.285714285714,2,-9822213661.916977,-536462358.0920263,-2645411718.2211943,{},"{'episode_reward': [-6661114249.465764, -9183084791.211535, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769], 'episode_lengths': [2020, 1993, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748], 'policy_gneJ12_reward': [-897009640.7584012, -1191479521.3522346, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386], 'policy_light1_reward': [-5764104608.707362, -7991605269.859306, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225]}","{'mean_env_wait_ms': 13.376387787257096, 'mean_processing_ms': 2.7658097479461015, 'mean_inference_ms': 1.861798379669599}",{},0,56000,"{'sample_time_ms': 72757.213, 'sample_throughput': 54.977, 'learn_time_ms': 16897.455, 'learn_throughput': 236.722}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 143265120387072.0, 'policy_loss': -0.010880441783228889, 'vf_loss': 143265120387072.0, 'vf_explained_var': -3.3527613e-08, 'kl': 0.015714032429968938, 'entropy': 1.2253652401268482, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 5255435212816384.0, 'policy_loss': -0.004159077565418556, 'vf_loss': 5255435212816384.0, 'vf_explained_var': 0.0, 'kl': 0.011427889796323143, 'entropy': 1.1026413217186928, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 56000, 'num_steps_trained': 56000}",False,21,14,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-01-00,1615762860,91.66878294944763,1254.2924933433533,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1254.2924933433533,0,14,"{'cpu_util_percent': 32.44609375, 'ram_util_percent': 56.140625000000014}"
27,13,MARL,light1,-3687500179.839026,-27133052971.985477,-12198976007.800129,2603.285714285714,2,-17310839310.06847,-3151037821.747003,-9553564289.578924,{},"{'episode_reward': [-6661114249.465764, -9183084791.211535, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769], 'episode_lengths': [2020, 1993, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748], 'policy_gneJ12_reward': [-897009640.7584012, -1191479521.3522346, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386], 'policy_light1_reward': [-5764104608.707362, -7991605269.859306, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225]}","{'mean_env_wait_ms': 13.376387787257096, 'mean_processing_ms': 2.7658097479461015, 'mean_inference_ms': 1.861798379669599}",{},0,56000,"{'sample_time_ms': 72757.213, 'sample_throughput': 54.977, 'learn_time_ms': 16897.455, 'learn_throughput': 236.722}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 143265120387072.0, 'policy_loss': -0.010880441783228889, 'vf_loss': 143265120387072.0, 'vf_explained_var': -3.3527613e-08, 'kl': 0.015714032429968938, 'entropy': 1.2253652401268482, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 5255435212816384.0, 'policy_loss': -0.004159077565418556, 'vf_loss': 5255435212816384.0, 'vf_explained_var': 0.0, 'kl': 0.011427889796323143, 'entropy': 1.1026413217186928, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 56000, 'num_steps_trained': 56000}",False,21,14,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-01-00,1615762860,91.66878294944763,1254.2924933433533,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1254.2924933433533,0,14,"{'cpu_util_percent': 32.44609375, 'ram_util_percent': 56.140625000000014}"
28,14,MARL,gneJ12,-3687500179.839026,-27133052971.985477,-12116244961.262753,2625.0,1,-9822213661.916977,-536462358.0920263,-2581490080.2419877,{},"{'episode_reward': [-10378892983.977835, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535], 'episode_lengths': [3081, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993], 'policy_gneJ12_reward': [-1239135682.6786587, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346], 'policy_light1_reward': [-9139757301.299171, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306]}","{'mean_env_wait_ms': 13.368814230196717, 'mean_processing_ms': 2.773117844661604, 'mean_inference_ms': 1.862280350975994}",{},0,60000,"{'sample_time_ms': 71850.943, 'sample_throughput': 55.671, 'learn_time_ms': 16901.236, 'learn_throughput': 236.669}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 77174217506816.0, 'policy_loss': -0.011481046705739573, 'vf_loss': 77174217506816.0, 'vf_explained_var': 2.7939677e-08, 'kl': 0.019416957075009122, 'entropy': 1.1536663323640823, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 3867233382039552.0, 'policy_loss': -0.006733489281032234, 'vf_loss': 3867233382039552.0, 'vf_explained_var': 2.6077032e-08, 'kl': 0.02154579240595922, 'entropy': 0.9650275390595198, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 60000, 'num_steps_trained': 60000}",False,22,15,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-02-21,1615762941,81.42876315116882,1335.721256494522,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1335.721256494522,0,15,"{'cpu_util_percent': 31.077192982456143, 'ram_util_percent': 56.04122807017544}"
29,14,MARL,light1,-3687500179.839026,-27133052971.985477,-12116244961.262753,2625.0,1,-17310839310.06847,-3151037821.747003,-9534754881.020754,{},"{'episode_reward': [-10378892983.977835, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535], 'episode_lengths': [3081, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993], 'policy_gneJ12_reward': [-1239135682.6786587, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346], 'policy_light1_reward': [-9139757301.299171, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306]}","{'mean_env_wait_ms': 13.368814230196717, 'mean_processing_ms': 2.773117844661604, 'mean_inference_ms': 1.862280350975994}",{},0,60000,"{'sample_time_ms': 71850.943, 'sample_throughput': 55.671, 'learn_time_ms': 16901.236, 'learn_throughput': 236.669}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 77174217506816.0, 'policy_loss': -0.011481046705739573, 'vf_loss': 77174217506816.0, 'vf_explained_var': 2.7939677e-08, 'kl': 0.019416957075009122, 'entropy': 1.1536663323640823, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 3867233382039552.0, 'policy_loss': -0.006733489281032234, 'vf_loss': 3867233382039552.0, 'vf_explained_var': 2.6077032e-08, 'kl': 0.02154579240595922, 'entropy': 0.9650275390595198, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 60000, 'num_steps_trained': 60000}",False,22,15,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-02-21,1615762941,81.42876315116882,1335.721256494522,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1335.721256494522,0,15,"{'cpu_util_percent': 31.077192982456143, 'ram_util_percent': 56.04122807017544}"
30,15,MARL,gneJ12,-2381148663.4006,-27133052971.985477,-11575182882.691092,2616.4583333333335,2,-9822213661.916977,-311659252.60711795,-2420286022.7585783,{},"{'episode_reward': [-8865851373.405058, -2381148663.4006, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835], 'episode_lengths': [2524, 2521, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081], 'policy_gneJ12_reward': [-982423528.2750291, -311659252.60711795, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587], 'policy_light1_reward': [-7883427845.130044, -2069489410.7934828, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171]}","{'mean_env_wait_ms': 13.351581071250727, 'mean_processing_ms': 2.7910364617082686, 'mean_inference_ms': 1.862576178118431}",{},0,64000,"{'sample_time_ms': 72292.118, 'sample_throughput': 55.331, 'learn_time_ms': 16819.784, 'learn_throughput': 237.815}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 86455892967424.0, 'policy_loss': -0.02094730903627351, 'vf_loss': 86455892967424.0, 'vf_explained_var': -5.5879354e-08, 'kl': 0.018340039008762687, 'entropy': 1.0871015675365925, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 2473042135482368.0, 'policy_loss': -0.017150111933005974, 'vf_loss': 2473042135482368.0, 'vf_explained_var': -1.6763806e-08, 'kl': 0.01390425612044055, 'entropy': 0.7164905294775963, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 64000, 'num_steps_trained': 64000}",False,24,16,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-03-50,1615763030,88.47765922546387,1424.198915719986,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1424.198915719986,0,16,"{'cpu_util_percent': 27.917741935483868, 'ram_util_percent': 56.031451612903226}"
31,15,MARL,light1,-2381148663.4006,-27133052971.985477,-11575182882.691092,2616.4583333333335,2,-17310839310.06847,-2069489410.7934828,-9154896859.932505,{},"{'episode_reward': [-8865851373.405058, -2381148663.4006, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835], 'episode_lengths': [2524, 2521, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081], 'policy_gneJ12_reward': [-982423528.2750291, -311659252.60711795, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587], 'policy_light1_reward': [-7883427845.130044, -2069489410.7934828, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171]}","{'mean_env_wait_ms': 13.351581071250727, 'mean_processing_ms': 2.7910364617082686, 'mean_inference_ms': 1.862576178118431}",{},0,64000,"{'sample_time_ms': 72292.118, 'sample_throughput': 55.331, 'learn_time_ms': 16819.784, 'learn_throughput': 237.815}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 86455892967424.0, 'policy_loss': -0.02094730903627351, 'vf_loss': 86455892967424.0, 'vf_explained_var': -5.5879354e-08, 'kl': 0.018340039008762687, 'entropy': 1.0871015675365925, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 2473042135482368.0, 'policy_loss': -0.017150111933005974, 'vf_loss': 2473042135482368.0, 'vf_explained_var': -1.6763806e-08, 'kl': 0.01390425612044055, 'entropy': 0.7164905294775963, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 64000, 'num_steps_trained': 64000}",False,24,16,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-03-50,1615763030,88.47765922546387,1424.198915719986,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1424.198915719986,0,16,"{'cpu_util_percent': 27.917741935483868, 'ram_util_percent': 56.031451612903226}"
32,16,MARL,gneJ12,-2381148663.4006,-27133052971.985477,-11418352200.37982,2608.4615384615386,2,-9822213661.916977,-311659252.60711795,-2357297659.0365214,{},"{'episode_reward': [-10716238761.282564, -8356529264.006624, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006], 'episode_lengths': [2547, 2478, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521], 'policy_gneJ12_reward': [-2107559441.6996064, -1095315147.044081, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795], 'policy_light1_reward': [-8608679319.582975, -7261214116.962533, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828]}","{'mean_env_wait_ms': 13.334879647052036, 'mean_processing_ms': 2.8096312538975363, 'mean_inference_ms': 1.8623781731123743}",{},0,68000,"{'sample_time_ms': 72353.346, 'sample_throughput': 55.284, 'learn_time_ms': 16842.201, 'learn_throughput': 237.499}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 319948163645440.0, 'policy_loss': -0.006208271195646375, 'vf_loss': 319948163645440.0, 'vf_explained_var': -2.7939677e-08, 'kl': 0.023094450996723026, 'entropy': 1.2840097844600677, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 3324869668241408.0, 'policy_loss': -0.012023480201605707, 'vf_loss': 3324869668241408.0, 'vf_explained_var': -7.0780516e-08, 'kl': 0.01889176327676978, 'entropy': 0.9228999894112349, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 68000, 'num_steps_trained': 68000}",False,26,17,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-05-19,1615763119,89.33082985877991,1513.5297455787659,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1513.5297455787659,0,17,"{'cpu_util_percent': 27.523200000000003, 'ram_util_percent': 56.0}"
33,16,MARL,light1,-2381148663.4006,-27133052971.985477,-11418352200.37982,2608.4615384615386,2,-17310839310.06847,-2069489410.7934828,-9061054541.343294,{},"{'episode_reward': [-10716238761.282564, -8356529264.006624, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006], 'episode_lengths': [2547, 2478, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521], 'policy_gneJ12_reward': [-2107559441.6996064, -1095315147.044081, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795], 'policy_light1_reward': [-8608679319.582975, -7261214116.962533, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828]}","{'mean_env_wait_ms': 13.334879647052036, 'mean_processing_ms': 2.8096312538975363, 'mean_inference_ms': 1.8623781731123743}",{},0,68000,"{'sample_time_ms': 72353.346, 'sample_throughput': 55.284, 'learn_time_ms': 16842.201, 'learn_throughput': 237.499}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 319948163645440.0, 'policy_loss': -0.006208271195646375, 'vf_loss': 319948163645440.0, 'vf_explained_var': -2.7939677e-08, 'kl': 0.023094450996723026, 'entropy': 1.2840097844600677, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 3324869668241408.0, 'policy_loss': -0.012023480201605707, 'vf_loss': 3324869668241408.0, 'vf_explained_var': -7.0780516e-08, 'kl': 0.01889176327676978, 'entropy': 0.9228999894112349, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 68000, 'num_steps_trained': 68000}",False,26,17,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-05-19,1615763119,89.33082985877991,1513.5297455787659,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1513.5297455787659,0,17,"{'cpu_util_percent': 27.523200000000003, 'ram_util_percent': 56.0}"
34,17,MARL,gneJ12,-2381148663.4006,-27133052971.985477,-11305404710.788218,2615.222222222222,1,-9822213661.916977,-311659252.60711795,-2312952644.1055446,{},"{'episode_reward': [-8368769981.406484, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624], 'episode_lengths': [2791, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478], 'policy_gneJ12_reward': [-1159982255.9001245, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081], 'policy_light1_reward': [-7208787725.506382, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533]}","{'mean_env_wait_ms': 13.325984814228573, 'mean_processing_ms': 2.8157024835902327, 'mean_inference_ms': 1.8620472380905273}",{},0,72000,"{'sample_time_ms': 71644.78, 'sample_throughput': 55.831, 'learn_time_ms': 16873.39, 'learn_throughput': 237.06}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 98255028355072.0, 'policy_loss': -0.01175935406354256, 'vf_loss': 98255028355072.0, 'vf_explained_var': 3.7252903e-09, 'kl': 0.009003580446005799, 'entropy': 1.2828796245157719, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 3050125307936768.0, 'policy_loss': -0.006171911547426134, 'vf_loss': 3050125307936768.0, 'vf_explained_var': -1.1175871e-08, 'kl': 0.010822325086337514, 'entropy': 0.9332308750599623, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 72000, 'num_steps_trained': 72000}",False,27,18,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-06-40,1615763200,80.9362862110138,1594.4660317897797,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1594.4660317897797,0,18,"{'cpu_util_percent': 29.2578947368421, 'ram_util_percent': 56.0}"
35,17,MARL,light1,-2381148663.4006,-27133052971.985477,-11305404710.788218,2615.222222222222,1,-17310839310.06847,-2069489410.7934828,-8992452066.682669,{},"{'episode_reward': [-8368769981.406484, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624], 'episode_lengths': [2791, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478], 'policy_gneJ12_reward': [-1159982255.9001245, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081], 'policy_light1_reward': [-7208787725.506382, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533]}","{'mean_env_wait_ms': 13.325984814228573, 'mean_processing_ms': 2.8157024835902327, 'mean_inference_ms': 1.8620472380905273}",{},0,72000,"{'sample_time_ms': 71644.78, 'sample_throughput': 55.831, 'learn_time_ms': 16873.39, 'learn_throughput': 237.06}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 98255028355072.0, 'policy_loss': -0.01175935406354256, 'vf_loss': 98255028355072.0, 'vf_explained_var': 3.7252903e-09, 'kl': 0.009003580446005799, 'entropy': 1.2828796245157719, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 3050125307936768.0, 'policy_loss': -0.006171911547426134, 'vf_loss': 3050125307936768.0, 'vf_explained_var': -1.1175871e-08, 'kl': 0.010822325086337514, 'entropy': 0.9332308750599623, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 72000, 'num_steps_trained': 72000}",False,27,18,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-06-40,1615763200,80.9362862110138,1594.4660317897797,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1594.4660317897797,0,18,"{'cpu_util_percent': 29.2578947368421, 'ram_util_percent': 56.0}"
36,18,MARL,gneJ12,-1960706630.2177725,-27133052971.985477,-10968810108.92962,2612.344827586207,2,-9822213661.916977,-277997050.6164309,-2214969651.3122764,{},"{'episode_reward': [-10888859337.459352, -1960706630.2177725, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484], 'episode_lengths': [3013, 2134, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791], 'policy_gneJ12_reward': [-1506401446.589891, -277997050.6164309, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245], 'policy_light1_reward': [-9382457890.869427, -1682709579.601341, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382]}","{'mean_env_wait_ms': 13.307012364251795, 'mean_processing_ms': 2.8311056653669464, 'mean_inference_ms': 1.8609983344180154}",{},0,76000,"{'sample_time_ms': 72342.225, 'sample_throughput': 55.293, 'learn_time_ms': 16867.25, 'learn_throughput': 237.146}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 64688308355072.0, 'policy_loss': -0.006387790635926649, 'vf_loss': 64688308355072.0, 'vf_explained_var': 3.5390258e-08, 'kl': 0.015493907209020108, 'entropy': 1.1641609445214272, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 1923946110779392.0, 'policy_loss': 0.0015978219453245401, 'vf_loss': 1923946110779392.0, 'vf_explained_var': 5.5879354e-08, 'kl': 0.018893769549322315, 'entropy': 0.6546802837401628, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 76000, 'num_steps_trained': 76000}",False,29,19,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-08-09,1615763289,89.02557396888733,1683.491605758667,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1683.491605758667,0,19,"{'cpu_util_percent': 27.544354838709676, 'ram_util_percent': 56.0}"
37,18,MARL,light1,-1960706630.2177725,-27133052971.985477,-10968810108.92962,2612.344827586207,2,-17310839310.06847,-1682709579.601341,-8753840457.617336,{},"{'episode_reward': [-10888859337.459352, -1960706630.2177725, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484], 'episode_lengths': [3013, 2134, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791], 'policy_gneJ12_reward': [-1506401446.589891, -277997050.6164309, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245], 'policy_light1_reward': [-9382457890.869427, -1682709579.601341, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382]}","{'mean_env_wait_ms': 13.307012364251795, 'mean_processing_ms': 2.8311056653669464, 'mean_inference_ms': 1.8609983344180154}",{},0,76000,"{'sample_time_ms': 72342.225, 'sample_throughput': 55.293, 'learn_time_ms': 16867.25, 'learn_throughput': 237.146}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 64688308355072.0, 'policy_loss': -0.006387790635926649, 'vf_loss': 64688308355072.0, 'vf_explained_var': 3.5390258e-08, 'kl': 0.015493907209020108, 'entropy': 1.1641609445214272, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 1923946110779392.0, 'policy_loss': 0.0015978219453245401, 'vf_loss': 1923946110779392.0, 'vf_explained_var': 5.5879354e-08, 'kl': 0.018893769549322315, 'entropy': 0.6546802837401628, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 76000, 'num_steps_trained': 76000}",False,29,19,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-08-09,1615763289,89.02557396888733,1683.491605758667,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1683.491605758667,0,19,"{'cpu_util_percent': 27.544354838709676, 'ram_util_percent': 56.0}"
38,19,MARL,gneJ12,-1960706630.2177725,-27133052971.985477,-10725005933.436382,2626.5333333333333,1,-9822213661.916977,-277997050.6164309,-2157034075.7168255,{},"{'episode_reward': [-3654684844.1324644, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725], 'episode_lengths': [3038, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134], 'policy_gneJ12_reward': [-476902383.44874215, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309], 'policy_light1_reward': [-3177782460.683727, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341]}","{'mean_env_wait_ms': 13.297105661902409, 'mean_processing_ms': 2.8363063651084905, 'mean_inference_ms': 1.8603769693029337}",{},0,80000,"{'sample_time_ms': 71424.789, 'sample_throughput': 56.003, 'learn_time_ms': 16808.583, 'learn_throughput': 237.974}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 52833129988096.0, 'policy_loss': -0.022388355224393308, 'vf_loss': 52833129988096.0, 'vf_explained_var': 2.2351742e-08, 'kl': 0.016707467526430264, 'entropy': 1.2446103692054749, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 1526322018910208.0, 'policy_loss': 0.006545178533997387, 'vf_loss': 1526322018910208.0, 'vf_explained_var': -7.450581e-09, 'kl': 0.01159545844711829, 'entropy': 0.7433041445910931, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 80000, 'num_steps_trained': 80000}",False,30,20,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-09-30,1615763370,80.29863595962524,1763.7902417182922,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1763.7902417182922,0,20,"{'cpu_util_percent': 29.457522123893803, 'ram_util_percent': 56.0}"
39,19,MARL,light1,-1960706630.2177725,-27133052971.985477,-10725005933.436382,2626.5333333333333,1,-17310839310.06847,-1682709579.601341,-8567971857.71955,{},"{'episode_reward': [-3654684844.1324644, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725], 'episode_lengths': [3038, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134], 'policy_gneJ12_reward': [-476902383.44874215, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309], 'policy_light1_reward': [-3177782460.683727, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341]}","{'mean_env_wait_ms': 13.297105661902409, 'mean_processing_ms': 2.8363063651084905, 'mean_inference_ms': 1.8603769693029337}",{},0,80000,"{'sample_time_ms': 71424.789, 'sample_throughput': 56.003, 'learn_time_ms': 16808.583, 'learn_throughput': 237.974}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 52833129988096.0, 'policy_loss': -0.022388355224393308, 'vf_loss': 52833129988096.0, 'vf_explained_var': 2.2351742e-08, 'kl': 0.016707467526430264, 'entropy': 1.2446103692054749, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 1526322018910208.0, 'policy_loss': 0.006545178533997387, 'vf_loss': 1526322018910208.0, 'vf_explained_var': -7.450581e-09, 'kl': 0.01159545844711829, 'entropy': 0.7433041445910931, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 80000, 'num_steps_trained': 80000}",False,30,20,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-09-30,1615763370,80.29863595962524,1763.7902417182922,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1763.7902417182922,0,20,"{'cpu_util_percent': 29.457522123893803, 'ram_util_percent': 56.0}"
40,20,MARL,gneJ12,-1915560191.3538332,-27133052971.985477,-10413614488.465347,2596.84375,2,-9822213661.916977,-204317492.57638025,-2073374549.07309,{},"{'episode_reward': [-9569925436.44581, -1915560191.3538332, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644], 'episode_lengths': [2652, 1651, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038], 'policy_gneJ12_reward': [-1432645806.2577422, -204317492.57638025, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215], 'policy_light1_reward': [-8137279630.1880455, -1711242698.7774525, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727]}","{'mean_env_wait_ms': 13.27749633490906, 'mean_processing_ms': 2.8478083600967863, 'mean_inference_ms': 1.8589811254371575}",{},0,84000,"{'sample_time_ms': 71375.253, 'sample_throughput': 56.042, 'learn_time_ms': 16682.943, 'learn_throughput': 239.766}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 81651074990080.0, 'policy_loss': -0.014635091516538523, 'vf_loss': 81651074990080.0, 'vf_explained_var': -1.8626451e-08, 'kl': 0.01886336348252371, 'entropy': 1.3202362544834614, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 2116144366354432.0, 'policy_loss': -0.009511951502645388, 'vf_loss': 2116144366354432.0, 'vf_explained_var': -4.8428774e-08, 'kl': 0.013933867841842584, 'entropy': 0.7738865595310926, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 84000, 'num_steps_trained': 84000}",False,32,21,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-10-58,1615763458,88.23861002922058,1852.0288517475128,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1852.0288517475128,0,21,"{'cpu_util_percent': 28.84274193548387, 'ram_util_percent': 56.0}"
41,20,MARL,light1,-1915560191.3538332,-27133052971.985477,-10413614488.465347,2596.84375,2,-17310839310.06847,-1682709579.601341,-8340239939.39225,{},"{'episode_reward': [-9569925436.44581, -1915560191.3538332, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644], 'episode_lengths': [2652, 1651, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038], 'policy_gneJ12_reward': [-1432645806.2577422, -204317492.57638025, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215], 'policy_light1_reward': [-8137279630.1880455, -1711242698.7774525, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727]}","{'mean_env_wait_ms': 13.27749633490906, 'mean_processing_ms': 2.8478083600967863, 'mean_inference_ms': 1.8589811254371575}",{},0,84000,"{'sample_time_ms': 71375.253, 'sample_throughput': 56.042, 'learn_time_ms': 16682.943, 'learn_throughput': 239.766}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 81651074990080.0, 'policy_loss': -0.014635091516538523, 'vf_loss': 81651074990080.0, 'vf_explained_var': -1.8626451e-08, 'kl': 0.01886336348252371, 'entropy': 1.3202362544834614, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 2116144366354432.0, 'policy_loss': -0.009511951502645388, 'vf_loss': 2116144366354432.0, 'vf_explained_var': -4.8428774e-08, 'kl': 0.013933867841842584, 'entropy': 0.7738865595310926, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 84000, 'num_steps_trained': 84000}",False,32,21,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-10-58,1615763458,88.23861002922058,1852.0288517475128,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1852.0288517475128,0,21,"{'cpu_util_percent': 28.84274193548387, 'ram_util_percent': 56.0}"
42,21,MARL,gneJ12,-1915560191.3538332,-27133052971.985477,-10336040105.579674,2597.4242424242425,1,-9822213661.916977,-204317492.57638025,-2042970591.245429,{},"{'episode_reward': [-7853659853.238171, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332], 'episode_lengths': [2616, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651], 'policy_gneJ12_reward': [-1070043940.7602806, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025], 'policy_light1_reward': [-6783615912.477901, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525]}","{'mean_env_wait_ms': 13.267908837919492, 'mean_processing_ms': 2.8516462821205057, 'mean_inference_ms': 1.858209495058737}",{},0,88000,"{'sample_time_ms': 69478.809, 'sample_throughput': 57.572, 'learn_time_ms': 16585.878, 'learn_throughput': 241.169}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 98979005595648.0, 'policy_loss': -0.015639868084690534, 'vf_loss': 98979005595648.0, 'vf_explained_var': 1.3038516e-08, 'kl': 0.01238268271117704, 'entropy': 1.4746749103069305, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 3063623895220224.0, 'policy_loss': -0.011697632580762729, 'vf_loss': 3063623895220224.0, 'vf_explained_var': -5.2154064e-08, 'kl': 0.010686998728488106, 'entropy': 0.9911098163574934, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 88000, 'num_steps_trained': 88000}",False,33,22,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-12-20,1615763540,82.1578209400177,1934.1866726875305,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1934.1866726875305,0,22,"{'cpu_util_percent': 29.86173913043478, 'ram_util_percent': 56.00173913043478}"
43,21,MARL,light1,-1915560191.3538332,-27133052971.985477,-10336040105.579674,2597.4242424242425,1,-17310839310.06847,-1682709579.601341,-8293069514.334241,{},"{'episode_reward': [-7853659853.238171, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332], 'episode_lengths': [2616, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651], 'policy_gneJ12_reward': [-1070043940.7602806, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025], 'policy_light1_reward': [-6783615912.477901, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525]}","{'mean_env_wait_ms': 13.267908837919492, 'mean_processing_ms': 2.8516462821205057, 'mean_inference_ms': 1.858209495058737}",{},0,88000,"{'sample_time_ms': 69478.809, 'sample_throughput': 57.572, 'learn_time_ms': 16585.878, 'learn_throughput': 241.169}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 98979005595648.0, 'policy_loss': -0.015639868084690534, 'vf_loss': 98979005595648.0, 'vf_explained_var': 1.3038516e-08, 'kl': 0.01238268271117704, 'entropy': 1.4746749103069305, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 3063623895220224.0, 'policy_loss': -0.011697632580762729, 'vf_loss': 3063623895220224.0, 'vf_explained_var': -5.2154064e-08, 'kl': 0.010686998728488106, 'entropy': 0.9911098163574934, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 88000, 'num_steps_trained': 88000}",False,33,22,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-12-20,1615763540,82.1578209400177,1934.1866726875305,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1934.1866726875305,0,22,"{'cpu_util_percent': 29.86173913043478, 'ram_util_percent': 56.00173913043478}"
44,22,MARL,gneJ12,-1915560191.3538332,-27133052971.985477,-10100179599.32422,2588.057142857143,2,-9822213661.916977,-204317492.57638025,-1968804372.1754997,{},"{'episode_reward': [-8008215387.001425, -4408747105.2170515, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171], 'episode_lengths': [2534, 2333, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616], 'policy_gneJ12_reward': [-1008906093.9309615, -481217421.1123595, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806], 'policy_light1_reward': [-6999309293.070458, -3927529684.1046934, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901]}","{'mean_env_wait_ms': 13.248754804925154, 'mean_processing_ms': 2.8605598799087555, 'mean_inference_ms': 1.8565571443864488}",{},0,92000,"{'sample_time_ms': 69468.333, 'sample_throughput': 57.58, 'learn_time_ms': 16483.085, 'learn_throughput': 242.673}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 41348786814976.0, 'policy_loss': -0.016198960671317764, 'vf_loss': 41348786814976.0, 'vf_explained_var': -4.4703484e-08, 'kl': 0.01514227848383598, 'entropy': 1.2731803990900517, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 2411450136002560.0, 'policy_loss': -0.008133596886182204, 'vf_loss': 2411450136002560.0, 'vf_explained_var': 4.4703484e-08, 'kl': 0.015315924320020713, 'entropy': 0.8517378270626068, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 92000, 'num_steps_trained': 92000}",False,35,23,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-13-48,1615763628,87.95187091827393,2022.1385436058044,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2022.1385436058044,0,23,"{'cpu_util_percent': 27.770731707317072, 'ram_util_percent': 56.0}"
45,22,MARL,light1,-1915560191.3538332,-27133052971.985477,-10100179599.32422,2588.057142857143,2,-17310839310.06847,-1682709579.601341,-8131375227.148717,{},"{'episode_reward': [-8008215387.001425, -4408747105.2170515, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171], 'episode_lengths': [2534, 2333, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616], 'policy_gneJ12_reward': [-1008906093.9309615, -481217421.1123595, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806], 'policy_light1_reward': [-6999309293.070458, -3927529684.1046934, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901]}","{'mean_env_wait_ms': 13.248754804925154, 'mean_processing_ms': 2.8605598799087555, 'mean_inference_ms': 1.8565571443864488}",{},0,92000,"{'sample_time_ms': 69468.333, 'sample_throughput': 57.58, 'learn_time_ms': 16483.085, 'learn_throughput': 242.673}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 41348786814976.0, 'policy_loss': -0.016198960671317764, 'vf_loss': 41348786814976.0, 'vf_explained_var': -4.4703484e-08, 'kl': 0.01514227848383598, 'entropy': 1.2731803990900517, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 2411450136002560.0, 'policy_loss': -0.008133596886182204, 'vf_loss': 2411450136002560.0, 'vf_explained_var': 4.4703484e-08, 'kl': 0.015315924320020713, 'entropy': 0.8517378270626068, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 92000, 'num_steps_trained': 92000}",False,35,23,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-13-48,1615763628,87.95187091827393,2022.1385436058044,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2022.1385436058044,0,23,"{'cpu_util_percent': 27.770731707317072, 'ram_util_percent': 56.0}"
46,23,MARL,gneJ12,-1915560191.3538332,-27133052971.985477,-9810989587.379705,2575.3783783783783,2,-9822213661.916977,-204317492.57638025,-1888131636.603467,{},"{'episode_reward': [-7212760323.329668, -2287568433.3718023, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515], 'episode_lengths': [2106, 2601, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333], 'policy_gneJ12_reward': [-682500657.0706915, -270216871.1150963, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595], 'policy_light1_reward': [-6530259666.258967, -2017351562.2567081, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934]}","{'mean_env_wait_ms': 13.229778004439652, 'mean_processing_ms': 2.870217240443578, 'mean_inference_ms': 1.8548486023669803}",{},0,96000,"{'sample_time_ms': 68999.785, 'sample_throughput': 57.971, 'learn_time_ms': 16494.909, 'learn_throughput': 242.499}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 20909788889088.0, 'policy_loss': -0.01427897607209161, 'vf_loss': 20909788889088.0, 'vf_explained_var': 3.1664968e-08, 'kl': 0.008966388937551528, 'entropy': 1.1499968022108078, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 940039850688512.0, 'policy_loss': -0.00954767144867219, 'vf_loss': 940039850688512.0, 'vf_explained_var': -9.313226e-09, 'kl': 0.014313563442556188, 'entropy': 0.6525784889236093, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 96000, 'num_steps_trained': 96000}",False,37,24,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-15-15,1615763715,87.10176301002502,2109.2403066158295,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2109.2403066158295,0,24,"{'cpu_util_percent': 27.47295081967213, 'ram_util_percent': 56.0}"
47,23,MARL,light1,-1915560191.3538332,-27133052971.985477,-9810989587.379705,2575.3783783783783,2,-17310839310.06847,-1682709579.601341,-7922857950.776236,{},"{'episode_reward': [-7212760323.329668, -2287568433.3718023, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515], 'episode_lengths': [2106, 2601, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333], 'policy_gneJ12_reward': [-682500657.0706915, -270216871.1150963, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595], 'policy_light1_reward': [-6530259666.258967, -2017351562.2567081, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934]}","{'mean_env_wait_ms': 13.229778004439652, 'mean_processing_ms': 2.870217240443578, 'mean_inference_ms': 1.8548486023669803}",{},0,96000,"{'sample_time_ms': 68999.785, 'sample_throughput': 57.971, 'learn_time_ms': 16494.909, 'learn_throughput': 242.499}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 20909788889088.0, 'policy_loss': -0.01427897607209161, 'vf_loss': 20909788889088.0, 'vf_explained_var': 3.1664968e-08, 'kl': 0.008966388937551528, 'entropy': 1.1499968022108078, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 940039850688512.0, 'policy_loss': -0.00954767144867219, 'vf_loss': 940039850688512.0, 'vf_explained_var': -9.313226e-09, 'kl': 0.014313563442556188, 'entropy': 0.6525784889236093, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 96000, 'num_steps_trained': 96000}",False,37,24,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-15-15,1615763715,87.10176301002502,2109.2403066158295,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2109.2403066158295,0,24,"{'cpu_util_percent': 27.47295081967213, 'ram_util_percent': 56.0}"
48,24,MARL,gneJ12,-1915560191.3538332,-27133052971.985477,-9697297104.473145,2579.5,1,-9822213661.916977,-204317492.57638025,-1857132056.3203301,{},"{'episode_reward': [-5490675236.930352, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023], 'episode_lengths': [2732, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601], 'policy_gneJ12_reward': [-710147585.8442818, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963], 'policy_light1_reward': [-4780527651.086061, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081]}","{'mean_env_wait_ms': 13.220302528526735, 'mean_processing_ms': 2.8735757177288734, 'mean_inference_ms': 1.8539691637621056}",{},0,100000,"{'sample_time_ms': 68869.782, 'sample_throughput': 58.081, 'learn_time_ms': 16569.077, 'learn_throughput': 241.414}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 56959864274944.0, 'policy_loss': -0.008962508756667376, 'vf_loss': 56959864274944.0, 'vf_explained_var': -2.2351742e-08, 'kl': 0.018271008360898122, 'entropy': 1.2701942548155785, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 1424002383872000.0, 'policy_loss': -0.012566658901050687, 'vf_loss': 1424002383872000.0, 'vf_explained_var': -7.450581e-09, 'kl': 0.013969849125714973, 'entropy': 0.7245448287576437, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 100000, 'num_steps_trained': 100000}",False,38,25,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-16-36,1615763796,80.87038207054138,2190.110688686371,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2190.110688686371,0,25,"{'cpu_util_percent': 29.487719298245608, 'ram_util_percent': 56.00438596491228}"
49,24,MARL,light1,-1915560191.3538332,-27133052971.985477,-9697297104.473145,2579.5,1,-17310839310.06847,-1682709579.601341,-7840165048.152809,{},"{'episode_reward': [-5490675236.930352, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023], 'episode_lengths': [2732, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601], 'policy_gneJ12_reward': [-710147585.8442818, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963], 'policy_light1_reward': [-4780527651.086061, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081]}","{'mean_env_wait_ms': 13.220302528526735, 'mean_processing_ms': 2.8735757177288734, 'mean_inference_ms': 1.8539691637621056}",{},0,100000,"{'sample_time_ms': 68869.782, 'sample_throughput': 58.081, 'learn_time_ms': 16569.077, 'learn_throughput': 241.414}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 56959864274944.0, 'policy_loss': -0.008962508756667376, 'vf_loss': 56959864274944.0, 'vf_explained_var': -2.2351742e-08, 'kl': 0.018271008360898122, 'entropy': 1.2701942548155785, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 1424002383872000.0, 'policy_loss': -0.012566658901050687, 'vf_loss': 1424002383872000.0, 'vf_explained_var': -7.450581e-09, 'kl': 0.013969849125714973, 'entropy': 0.7245448287576437, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 100000, 'num_steps_trained': 100000}",False,38,25,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-16-36,1615763796,80.87038207054138,2190.110688686371,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2190.110688686371,0,25,"{'cpu_util_percent': 29.487719298245608, 'ram_util_percent': 56.00438596491228}"
50,25,MARL,gneJ12,-1915560191.3538332,-27133052971.985477,-9641040520.483988,2599.775,2,-9822213661.916977,-204317492.57638025,-1819568274.3471336,{},"{'episode_reward': [-6542269844.632774, -10602061004.74721, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352], 'episode_lengths': [2842, 3128, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732], 'policy_gneJ12_reward': [-932143681.752874, -1279569151.959923, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818], 'policy_light1_reward': [-5610126162.879893, -9322491852.787256, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061]}","{'mean_env_wait_ms': 13.202077425723536, 'mean_processing_ms': 2.881375135525064, 'mean_inference_ms': 1.8521978654148996}",{},0,104000,"{'sample_time_ms': 68850.803, 'sample_throughput': 58.097, 'learn_time_ms': 16751.949, 'learn_throughput': 238.778}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 77841719230464.0, 'policy_loss': -0.0034127044636989012, 'vf_loss': 77841719230464.0, 'vf_explained_var': -1.8626451e-09, 'kl': 0.0171998820733279, 'entropy': 1.4395155608654022, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 3265812500578304.0, 'policy_loss': -0.004195399262243882, 'vf_loss': 3265812500578304.0, 'vf_explained_var': -5.2154064e-08, 'kl': 0.008037236530071823, 'entropy': 1.0197494607418776, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 104000, 'num_steps_trained': 104000}",False,40,26,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-18-07,1615763887,90.11736702919006,2280.228055715561,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2280.228055715561,0,26,"{'cpu_util_percent': 28.32142857142857, 'ram_util_percent': 56.041269841269845}"
51,25,MARL,light1,-1915560191.3538332,-27133052971.985477,-9641040520.483988,2599.775,2,-17310839310.06847,-1682709579.601341,-7821472246.136848,{},"{'episode_reward': [-6542269844.632774, -10602061004.74721, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352], 'episode_lengths': [2842, 3128, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732], 'policy_gneJ12_reward': [-932143681.752874, -1279569151.959923, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818], 'policy_light1_reward': [-5610126162.879893, -9322491852.787256, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061]}","{'mean_env_wait_ms': 13.202077425723536, 'mean_processing_ms': 2.881375135525064, 'mean_inference_ms': 1.8521978654148996}",{},0,104000,"{'sample_time_ms': 68850.803, 'sample_throughput': 58.097, 'learn_time_ms': 16751.949, 'learn_throughput': 238.778}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 77841719230464.0, 'policy_loss': -0.0034127044636989012, 'vf_loss': 77841719230464.0, 'vf_explained_var': -1.8626451e-09, 'kl': 0.0171998820733279, 'entropy': 1.4395155608654022, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 3265812500578304.0, 'policy_loss': -0.004195399262243882, 'vf_loss': 3265812500578304.0, 'vf_explained_var': -5.2154064e-08, 'kl': 0.008037236530071823, 'entropy': 1.0197494607418776, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 104000, 'num_steps_trained': 104000}",False,40,26,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-18-07,1615763887,90.11736702919006,2280.228055715561,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2280.228055715561,0,26,"{'cpu_util_percent': 28.32142857142857, 'ram_util_percent': 56.041269841269845}"
52,26,MARL,gneJ12,-1915560191.3538332,-27133052971.985477,-9657452531.066519,2597.609756097561,1,-9822213661.916977,-204317492.57638025,-1848279838.864237,{},"{'episode_reward': [-10313932954.367785, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721], 'episode_lengths': [2511, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128], 'policy_gneJ12_reward': [-2996742419.548364, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923], 'policy_light1_reward': [-7317190534.819452, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256]}","{'mean_env_wait_ms': 13.194105460557576, 'mean_processing_ms': 2.884304116398026, 'mean_inference_ms': 1.8514363060427677}",{},0,108000,"{'sample_time_ms': 68582.442, 'sample_throughput': 58.324, 'learn_time_ms': 16921.929, 'learn_throughput': 236.38}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 524943507324928.0, 'policy_loss': -0.013273504446260631, 'vf_loss': 524943507324928.0, 'vf_explained_var': 7.450581e-09, 'kl': 0.014949535485357046, 'entropy': 1.6150416247546673, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 2716255794495488.0, 'policy_loss': -0.00706007715780288, 'vf_loss': 2716255794495488.0, 'vf_explained_var': 1.3038516e-08, 'kl': 0.01652909247786738, 'entropy': 0.8853044081479311, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 108000, 'num_steps_trained': 108000}",False,41,27,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-19-35,1615763975,88.347571849823,2368.575627565384,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2368.575627565384,0,27,"{'cpu_util_percent': 41.58145161290322, 'ram_util_percent': 56.13790322580647}"
53,26,MARL,light1,-1915560191.3538332,-27133052971.985477,-9657452531.066519,2597.609756097561,1,-17310839310.06847,-1682709579.601341,-7809172692.202276,{},"{'episode_reward': [-10313932954.367785, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721], 'episode_lengths': [2511, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128], 'policy_gneJ12_reward': [-2996742419.548364, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923], 'policy_light1_reward': [-7317190534.819452, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256]}","{'mean_env_wait_ms': 13.194105460557576, 'mean_processing_ms': 2.884304116398026, 'mean_inference_ms': 1.8514363060427677}",{},0,108000,"{'sample_time_ms': 68582.442, 'sample_throughput': 58.324, 'learn_time_ms': 16921.929, 'learn_throughput': 236.38}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 524943507324928.0, 'policy_loss': -0.013273504446260631, 'vf_loss': 524943507324928.0, 'vf_explained_var': 7.450581e-09, 'kl': 0.014949535485357046, 'entropy': 1.6150416247546673, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 2716255794495488.0, 'policy_loss': -0.00706007715780288, 'vf_loss': 2716255794495488.0, 'vf_explained_var': 1.3038516e-08, 'kl': 0.01652909247786738, 'entropy': 0.8853044081479311, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 108000, 'num_steps_trained': 108000}",False,41,27,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-19-35,1615763975,88.347571849823,2368.575627565384,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2368.575627565384,0,27,"{'cpu_util_percent': 41.58145161290322, 'ram_util_percent': 56.13790322580647}"
54,27,MARL,gneJ12,-1915560191.3538332,-27133052971.985477,-9550867206.885677,2608.809523809524,1,-9822213661.916977,-204317492.57638025,-1819296552.2453759,{},"{'episode_reward': [-5180868915.47109, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785], 'episode_lengths': [3068, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511], 'policy_gneJ12_reward': [-630981800.8720468, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364], 'policy_light1_reward': [-4549887114.599059, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452]}","{'mean_env_wait_ms': 13.18691186662635, 'mean_processing_ms': 2.8862703993867065, 'mean_inference_ms': 1.850819182275444}",{},0,112000,"{'sample_time_ms': 69062.005, 'sample_throughput': 57.919, 'learn_time_ms': 17055.656, 'learn_throughput': 234.526}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 87387861549056.0, 'policy_loss': -0.010821098636370152, 'vf_loss': 87387861549056.0, 'vf_explained_var': 7.450581e-09, 'kl': 0.014922715694410726, 'entropy': 1.5428167209029198, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 2809743194193920.0, 'policy_loss': -0.008750242181122303, 'vf_loss': 2809743194193920.0, 'vf_explained_var': 2.6077032e-08, 'kl': 0.011513318386278115, 'entropy': 0.8881073351949453, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 112000, 'num_steps_trained': 112000}",False,42,28,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-21-02,1615764062,87.06851196289062,2455.6441395282745,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2455.6441395282745,0,28,"{'cpu_util_percent': 44.78934426229508, 'ram_util_percent': 56.152459016393465}"
55,27,MARL,light1,-1915560191.3538332,-27133052971.985477,-9550867206.885677,2608.809523809524,1,-17310839310.06847,-1682709579.601341,-7731570654.640297,{},"{'episode_reward': [-5180868915.47109, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785], 'episode_lengths': [3068, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511], 'policy_gneJ12_reward': [-630981800.8720468, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364], 'policy_light1_reward': [-4549887114.599059, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452]}","{'mean_env_wait_ms': 13.18691186662635, 'mean_processing_ms': 2.8862703993867065, 'mean_inference_ms': 1.850819182275444}",{},0,112000,"{'sample_time_ms': 69062.005, 'sample_throughput': 57.919, 'learn_time_ms': 17055.656, 'learn_throughput': 234.526}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 87387861549056.0, 'policy_loss': -0.010821098636370152, 'vf_loss': 87387861549056.0, 'vf_explained_var': 7.450581e-09, 'kl': 0.014922715694410726, 'entropy': 1.5428167209029198, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 2809743194193920.0, 'policy_loss': -0.008750242181122303, 'vf_loss': 2809743194193920.0, 'vf_explained_var': 2.6077032e-08, 'kl': 0.011513318386278115, 'entropy': 0.8881073351949453, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 112000, 'num_steps_trained': 112000}",False,42,28,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-21-02,1615764062,87.06851196289062,2455.6441395282745,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2455.6441395282745,0,28,"{'cpu_util_percent': 44.78934426229508, 'ram_util_percent': 56.152459016393465}"
56,28,MARL,gneJ12,-1915560191.3538332,-27133052971.985477,-9589046352.520088,2630.6363636363635,2,-9822213661.916977,-204317492.57638025,-1804235411.906122,{},"{'episode_reward': [-10675583017.318611, -10106033804.366896, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109], 'episode_lengths': [3090, 3088, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068], 'policy_gneJ12_reward': [-1563238388.204147, -1412664541.3594642, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468], 'policy_light1_reward': [-9112344629.114471, -8693369263.007433, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059]}","{'mean_env_wait_ms': 13.173039010199124, 'mean_processing_ms': 2.891268305195424, 'mean_inference_ms': 1.8495760841594873}",{},0,116000,"{'sample_time_ms': 69050.249, 'sample_throughput': 57.929, 'learn_time_ms': 17226.048, 'learn_throughput': 232.206}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 127309008601088.0, 'policy_loss': -0.004826148098800331, 'vf_loss': 127309008601088.0, 'vf_explained_var': 1.8626451e-09, 'kl': 0.016096251987619326, 'entropy': 1.7096405439078808, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 2997293913473024.0, 'policy_loss': -0.002000524749746546, 'vf_loss': 2997293913473024.0, 'vf_explained_var': 4.656613e-08, 'kl': 0.012712686104350723, 'entropy': 0.920327240601182, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 116000, 'num_steps_trained': 116000}",False,44,29,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-22-33,1615764153,90.61189889907837,2546.256038427353,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2546.256038427353,0,29,"{'cpu_util_percent': 29.751968503937007, 'ram_util_percent': 56.11102362204728}"
57,28,MARL,light1,-1915560191.3538332,-27133052971.985477,-9589046352.520088,2630.6363636363635,2,-17310839310.06847,-1682709579.601341,-7784810940.613962,{},"{'episode_reward': [-10675583017.318611, -10106033804.366896, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109], 'episode_lengths': [3090, 3088, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068], 'policy_gneJ12_reward': [-1563238388.204147, -1412664541.3594642, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468], 'policy_light1_reward': [-9112344629.114471, -8693369263.007433, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059]}","{'mean_env_wait_ms': 13.173039010199124, 'mean_processing_ms': 2.891268305195424, 'mean_inference_ms': 1.8495760841594873}",{},0,116000,"{'sample_time_ms': 69050.249, 'sample_throughput': 57.929, 'learn_time_ms': 17226.048, 'learn_throughput': 232.206}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 127309008601088.0, 'policy_loss': -0.004826148098800331, 'vf_loss': 127309008601088.0, 'vf_explained_var': 1.8626451e-09, 'kl': 0.016096251987619326, 'entropy': 1.7096405439078808, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 2997293913473024.0, 'policy_loss': -0.002000524749746546, 'vf_loss': 2997293913473024.0, 'vf_explained_var': 4.656613e-08, 'kl': 0.012712686104350723, 'entropy': 0.920327240601182, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 116000, 'num_steps_trained': 116000}",False,44,29,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-22-33,1615764153,90.61189889907837,2546.256038427353,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2546.256038427353,0,29,"{'cpu_util_percent': 29.751968503937007, 'ram_util_percent': 56.11102362204728}"
58,29,MARL,gneJ12,-1915560191.3538332,-27133052971.985477,-9655570984.34898,2633.5777777777776,1,-9822213661.916977,-204317492.57638025,-1894638841.4385,{},"{'episode_reward': [-12582654784.8202, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896], 'episode_lengths': [2763, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088], 'policy_gneJ12_reward': [-5872389740.863124, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642], 'policy_light1_reward': [-6710265043.957095, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433]}","{'mean_env_wait_ms': 13.166903270838905, 'mean_processing_ms': 2.8928330921016494, 'mean_inference_ms': 1.8489680952764669}",{},0,120000,"{'sample_time_ms': 69489.183, 'sample_throughput': 57.563, 'learn_time_ms': 17370.72, 'learn_throughput': 230.273}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 2481073720131584.0, 'policy_loss': 0.001522721111541614, 'vf_loss': 2481073720131584.0, 'vf_explained_var': 4.8428774e-08, 'kl': 0.021235391322989017, 'entropy': 2.1351797692477703, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 2768797802954752.0, 'policy_loss': -0.01198459901206661, 'vf_loss': 2768797802954752.0, 'vf_explained_var': 8.940697e-08, 'kl': 0.014346437208587304, 'entropy': 1.0211764108389616, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 120000, 'num_steps_trained': 120000}",False,45,30,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-23-59,1615764239,86.13400387763977,2632.3900423049927,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2632.3900423049927,0,30,"{'cpu_util_percent': 29.313223140495865, 'ram_util_percent': 56.100000000000016}"
59,29,MARL,light1,-1915560191.3538332,-27133052971.985477,-9655570984.34898,2633.5777777777776,1,-17310839310.06847,-1682709579.601341,-7760932142.910477,{},"{'episode_reward': [-12582654784.8202, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896], 'episode_lengths': [2763, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088], 'policy_gneJ12_reward': [-5872389740.863124, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642], 'policy_light1_reward': [-6710265043.957095, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433]}","{'mean_env_wait_ms': 13.166903270838905, 'mean_processing_ms': 2.8928330921016494, 'mean_inference_ms': 1.8489680952764669}",{},0,120000,"{'sample_time_ms': 69489.183, 'sample_throughput': 57.563, 'learn_time_ms': 17370.72, 'learn_throughput': 230.273}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 2481073720131584.0, 'policy_loss': 0.001522721111541614, 'vf_loss': 2481073720131584.0, 'vf_explained_var': 4.8428774e-08, 'kl': 0.021235391322989017, 'entropy': 2.1351797692477703, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 2768797802954752.0, 'policy_loss': -0.01198459901206661, 'vf_loss': 2768797802954752.0, 'vf_explained_var': 8.940697e-08, 'kl': 0.014346437208587304, 'entropy': 1.0211764108389616, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 120000, 'num_steps_trained': 120000}",False,45,30,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-23-59,1615764239,86.13400387763977,2632.3900423049927,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2632.3900423049927,0,30,"{'cpu_util_percent': 29.313223140495865, 'ram_util_percent': 56.100000000000016}"
60,30,MARL,gneJ12,-1915560191.3538332,-27133052971.985477,-9634574235.987856,2635.478260869565,1,-9822213661.916977,-204317492.57638025,-1883298959.206788,{},"{'episode_reward': [-8689720559.73726, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202], 'episode_lengths': [2721, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763], 'policy_gneJ12_reward': [-1373004258.7797358, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124], 'policy_light1_reward': [-7316716300.9575, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095]}","{'mean_env_wait_ms': 13.160617587149284, 'mean_processing_ms': 2.8936102870900715, 'mean_inference_ms': 1.8483297917086947}",{},0,124000,"{'sample_time_ms': 68725.293, 'sample_throughput': 58.203, 'learn_time_ms': 17424.773, 'learn_throughput': 229.558}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 43042857287680.0, 'policy_loss': -0.011834502161946148, 'vf_loss': 43042857287680.0, 'vf_explained_var': -6.3329935e-08, 'kl': 0.011190088363946415, 'entropy': 1.2224872633814812, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 1204972750372864.0, 'policy_loss': -0.008548417739802971, 'vf_loss': 1204972750372864.0, 'vf_explained_var': 0.0, 'kl': 0.013016792421694845, 'entropy': 0.4651650213636458, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 124000, 'num_steps_trained': 124000}",False,46,31,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-25-20,1615764320,81.14574599266052,2713.535788297653,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2713.535788297653,0,31,"{'cpu_util_percent': 29.61842105263158, 'ram_util_percent': 56.105263157894754}"
61,30,MARL,light1,-1915560191.3538332,-27133052971.985477,-9634574235.987856,2635.478260869565,1,-17310839310.06847,-1682709579.601341,-7751275276.781063,{},"{'episode_reward': [-8689720559.73726, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202], 'episode_lengths': [2721, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763], 'policy_gneJ12_reward': [-1373004258.7797358, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124], 'policy_light1_reward': [-7316716300.9575, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095]}","{'mean_env_wait_ms': 13.160617587149284, 'mean_processing_ms': 2.8936102870900715, 'mean_inference_ms': 1.8483297917086947}",{},0,124000,"{'sample_time_ms': 68725.293, 'sample_throughput': 58.203, 'learn_time_ms': 17424.773, 'learn_throughput': 229.558}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 43042857287680.0, 'policy_loss': -0.011834502161946148, 'vf_loss': 43042857287680.0, 'vf_explained_var': -6.3329935e-08, 'kl': 0.011190088363946415, 'entropy': 1.2224872633814812, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 1204972750372864.0, 'policy_loss': -0.008548417739802971, 'vf_loss': 1204972750372864.0, 'vf_explained_var': 0.0, 'kl': 0.013016792421694845, 'entropy': 0.4651650213636458, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 124000, 'num_steps_trained': 124000}",False,46,31,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-25-20,1615764320,81.14574599266052,2713.535788297653,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2713.535788297653,0,31,"{'cpu_util_percent': 29.61842105263158, 'ram_util_percent': 56.105263157894754}"
62,31,MARL,gneJ12,-1915560191.3538332,-27133052971.985477,-9404297379.09961,2640.8541666666665,2,-9822213661.916977,-204317492.57638025,-1827985130.7784154,{},"{'episode_reward': [-2906023956.7307343, -5309835384.609116, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726], 'episode_lengths': [2835, 2694, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721], 'policy_gneJ12_reward': [-404527018.33733475, -707007135.5143712, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358], 'policy_light1_reward': [-2501496938.393397, -4602828249.094738, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575]}","{'mean_env_wait_ms': 13.14784725757643, 'mean_processing_ms': 2.8960009534786533, 'mean_inference_ms': 1.8470452549503538}",{},0,128000,"{'sample_time_ms': 69235.668, 'sample_throughput': 57.774, 'learn_time_ms': 17419.268, 'learn_throughput': 229.631}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 30064135241728.0, 'policy_loss': -0.013711455336306244, 'vf_loss': 30064135241728.0, 'vf_explained_var': 5.9604645e-08, 'kl': 0.012146994456998073, 'entropy': 1.1053639072924852, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 1020263542030336.0, 'policy_loss': -0.008953463577199727, 'vf_loss': 1020263542030336.0, 'vf_explained_var': -4.8428774e-08, 'kl': 0.02003831314505078, 'entropy': 0.41247515846043825, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 128000, 'num_steps_trained': 128000}",False,48,32,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-26-47,1615764407,87.20699691772461,2800.742785215378,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2800.742785215378,0,32,"{'cpu_util_percent': 27.588524590163935, 'ram_util_percent': 56.10245901639346}"
63,31,MARL,light1,-1915560191.3538332,-27133052971.985477,-9404297379.09961,2640.8541666666665,2,-17310839310.06847,-1682709579.601341,-7576312248.32119,{},"{'episode_reward': [-2906023956.7307343, -5309835384.609116, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726], 'episode_lengths': [2835, 2694, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721], 'policy_gneJ12_reward': [-404527018.33733475, -707007135.5143712, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358], 'policy_light1_reward': [-2501496938.393397, -4602828249.094738, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575]}","{'mean_env_wait_ms': 13.14784725757643, 'mean_processing_ms': 2.8960009534786533, 'mean_inference_ms': 1.8470452549503538}",{},0,128000,"{'sample_time_ms': 69235.668, 'sample_throughput': 57.774, 'learn_time_ms': 17419.268, 'learn_throughput': 229.631}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 30064135241728.0, 'policy_loss': -0.013711455336306244, 'vf_loss': 30064135241728.0, 'vf_explained_var': 5.9604645e-08, 'kl': 0.012146994456998073, 'entropy': 1.1053639072924852, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 1020263542030336.0, 'policy_loss': -0.008953463577199727, 'vf_loss': 1020263542030336.0, 'vf_explained_var': -4.8428774e-08, 'kl': 0.02003831314505078, 'entropy': 0.41247515846043825, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 128000, 'num_steps_trained': 128000}",False,48,32,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-26-47,1615764407,87.20699691772461,2800.742785215378,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2800.742785215378,0,32,"{'cpu_util_percent': 27.588524590163935, 'ram_util_percent': 56.10245901639346}"
64,32,MARL,gneJ12,-1915560191.3538332,-27133052971.985477,-9293112630.616331,2650.7551020408164,1,-9822213661.916977,-204317492.57638025,-1800244771.58575,{},"{'episode_reward': [-3956244703.418989, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116], 'episode_lengths': [3126, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694], 'policy_gneJ12_reward': [-468707530.3378017, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712], 'policy_light1_reward': [-3487537173.081193, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738]}","{'mean_env_wait_ms': 13.141736325853383, 'mean_processing_ms': 2.896561886281989, 'mean_inference_ms': 1.8464824341983188}",{},0,132000,"{'sample_time_ms': 68759.826, 'sample_throughput': 58.174, 'learn_time_ms': 17522.41, 'learn_throughput': 228.279}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 15178183409664.0, 'policy_loss': -0.007707311917329207, 'vf_loss': 15178183409664.0, 'vf_explained_var': 5.7742e-08, 'kl': 0.009860407270025462, 'entropy': 1.0079238191246986, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 511239016939520.0, 'policy_loss': -0.008657764876261353, 'vf_loss': 511239016939520.0, 'vf_explained_var': -2.0489097e-08, 'kl': 0.009191843906592112, 'entropy': 0.23386985925026238, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 132000, 'num_steps_trained': 132000}",False,49,33,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-28-12,1615764492,84.22477912902832,2884.967564344406,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2884.967564344406,0,33,"{'cpu_util_percent': 41.932203389830505, 'ram_util_percent': 56.168644067796635}"
65,32,MARL,light1,-1915560191.3538332,-27133052971.985477,-9293112630.616331,2650.7551020408164,1,-17310839310.06847,-1682709579.601341,-7492867859.030578,{},"{'episode_reward': [-3956244703.418989, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116], 'episode_lengths': [3126, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694], 'policy_gneJ12_reward': [-468707530.3378017, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712], 'policy_light1_reward': [-3487537173.081193, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738]}","{'mean_env_wait_ms': 13.141736325853383, 'mean_processing_ms': 2.896561886281989, 'mean_inference_ms': 1.8464824341983188}",{},0,132000,"{'sample_time_ms': 68759.826, 'sample_throughput': 58.174, 'learn_time_ms': 17522.41, 'learn_throughput': 228.279}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 15178183409664.0, 'policy_loss': -0.007707311917329207, 'vf_loss': 15178183409664.0, 'vf_explained_var': 5.7742e-08, 'kl': 0.009860407270025462, 'entropy': 1.0079238191246986, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 511239016939520.0, 'policy_loss': -0.008657764876261353, 'vf_loss': 511239016939520.0, 'vf_explained_var': -2.0489097e-08, 'kl': 0.009191843906592112, 'entropy': 0.23386985925026238, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 132000, 'num_steps_trained': 132000}",False,49,33,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-28-12,1615764492,84.22477912902832,2884.967564344406,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2884.967564344406,0,33,"{'cpu_util_percent': 41.932203389830505, 'ram_util_percent': 56.168644067796635}"
66,33,MARL,gneJ12,-1915560191.3538332,-27133052971.985477,-9127644336.723621,2646.6666666666665,2,-9822213661.916977,-204317492.57638025,-1756469111.6343021,{},"{'episode_reward': [-2723529552.565318, -7423812720.139137, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989], 'episode_lengths': [2717, 2376, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126], 'policy_gneJ12_reward': [-362090789.8832875, -1005840095.7643778, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017], 'policy_light1_reward': [-2361438762.6820273, -6417972624.374755, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193]}","{'mean_env_wait_ms': 13.130307604251026, 'mean_processing_ms': 2.8986831491554637, 'mean_inference_ms': 1.8454995181801443}",{},0,136000,"{'sample_time_ms': 69185.356, 'sample_throughput': 57.816, 'learn_time_ms': 17611.314, 'learn_throughput': 227.127}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 62206619549696.0, 'policy_loss': -0.003972422215156257, 'vf_loss': 62206619549696.0, 'vf_explained_var': 1.3038516e-08, 'kl': 0.018708089322899468, 'entropy': 1.2250139713287354, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1886472080719872.0, 'policy_loss': -0.006722553283907473, 'vf_loss': 1886472080719872.0, 'vf_explained_var': -1.1175871e-08, 'kl': 0.00815424945903942, 'entropy': 0.48745180759578943, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 136000, 'num_steps_trained': 136000}",False,51,34,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-29-44,1615764584,92.24681496620178,2977.214379310608,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2977.214379310608,0,34,"{'cpu_util_percent': 35.682945736434114, 'ram_util_percent': 56.132558139534886}"
67,33,MARL,light1,-1915560191.3538332,-27133052971.985477,-9127644336.723621,2646.6666666666665,2,-17310839310.06847,-1682709579.601341,-7371175225.0893135,{},"{'episode_reward': [-2723529552.565318, -7423812720.139137, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989], 'episode_lengths': [2717, 2376, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126], 'policy_gneJ12_reward': [-362090789.8832875, -1005840095.7643778, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017], 'policy_light1_reward': [-2361438762.6820273, -6417972624.374755, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193]}","{'mean_env_wait_ms': 13.130307604251026, 'mean_processing_ms': 2.8986831491554637, 'mean_inference_ms': 1.8454995181801443}",{},0,136000,"{'sample_time_ms': 69185.356, 'sample_throughput': 57.816, 'learn_time_ms': 17611.314, 'learn_throughput': 227.127}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 62206619549696.0, 'policy_loss': -0.003972422215156257, 'vf_loss': 62206619549696.0, 'vf_explained_var': 1.3038516e-08, 'kl': 0.018708089322899468, 'entropy': 1.2250139713287354, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1886472080719872.0, 'policy_loss': -0.006722553283907473, 'vf_loss': 1886472080719872.0, 'vf_explained_var': -1.1175871e-08, 'kl': 0.00815424945903942, 'entropy': 0.48745180759578943, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 136000, 'num_steps_trained': 136000}",False,51,34,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-29-44,1615764584,92.24681496620178,2977.214379310608,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2977.214379310608,0,34,"{'cpu_util_percent': 35.682945736434114, 'ram_util_percent': 56.132558139534886}"
68,34,MARL,gneJ12,-1899452563.075036,-27133052971.985477,-8988640648.768843,2651.480769230769,1,-9822213661.916977,-204317492.57638025,-1727970185.0239835,{},"{'episode_reward': [-1899452563.075036, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137], 'episode_lengths': [2897, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376], 'policy_gneJ12_reward': [-274524927.8977448, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778], 'policy_light1_reward': [-1624927635.177292, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755]}","{'mean_env_wait_ms': 13.12452371536289, 'mean_processing_ms': 2.8991528383998126, 'mean_inference_ms': 1.8449852330947656}",{},0,140000,"{'sample_time_ms': 69144.825, 'sample_throughput': 57.85, 'learn_time_ms': 17635.575, 'learn_throughput': 226.814}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 28761625493504.0, 'policy_loss': -0.012421468796674162, 'vf_loss': 28761625493504.0, 'vf_explained_var': -9.313226e-09, 'kl': 0.016130561649333686, 'entropy': 1.0212343391031027, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1004016691576832.0, 'policy_loss': -0.00765761433285661, 'vf_loss': 1004016691576832.0, 'vf_explained_var': -8.568168e-08, 'kl': 0.010803734920045827, 'entropy': 0.27062138309702277, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 140000, 'num_steps_trained': 140000}",False,52,35,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-31-05,1615764665,80.70740008354187,3057.92177939415,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3057.92177939415,0,35,"{'cpu_util_percent': 28.643362831858404, 'ram_util_percent': 56.04601769911505}"
69,34,MARL,light1,-1899452563.075036,-27133052971.985477,-8988640648.768843,2651.480769230769,1,-17310839310.06847,-1624927635.177292,-7260670463.744852,{},"{'episode_reward': [-1899452563.075036, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137], 'episode_lengths': [2897, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376], 'policy_gneJ12_reward': [-274524927.8977448, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778], 'policy_light1_reward': [-1624927635.177292, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755]}","{'mean_env_wait_ms': 13.12452371536289, 'mean_processing_ms': 2.8991528383998126, 'mean_inference_ms': 1.8449852330947656}",{},0,140000,"{'sample_time_ms': 69144.825, 'sample_throughput': 57.85, 'learn_time_ms': 17635.575, 'learn_throughput': 226.814}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 28761625493504.0, 'policy_loss': -0.012421468796674162, 'vf_loss': 28761625493504.0, 'vf_explained_var': -9.313226e-09, 'kl': 0.016130561649333686, 'entropy': 1.0212343391031027, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1004016691576832.0, 'policy_loss': -0.00765761433285661, 'vf_loss': 1004016691576832.0, 'vf_explained_var': -8.568168e-08, 'kl': 0.010803734920045827, 'entropy': 0.27062138309702277, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 140000, 'num_steps_trained': 140000}",False,52,35,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-31-05,1615764665,80.70740008354187,3057.92177939415,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3057.92177939415,0,35,"{'cpu_util_percent': 28.643362831858404, 'ram_util_percent': 56.04601769911505}"
70,35,MARL,gneJ12,-1899452563.075036,-27133052971.985477,-8917291045.950068,2658.4074074074074,2,-9822213661.916977,-204317492.57638025,-1695462318.0793848,{},"{'episode_reward': [-6570697919.845422, -7553704825.478482, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036], 'episode_lengths': [2900, 2777, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897], 'policy_gneJ12_reward': [-788659730.0194864, -911855825.020136, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448], 'policy_light1_reward': [-5782038189.825922, -6641849000.458346, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292]}","{'mean_env_wait_ms': 13.113102730203664, 'mean_processing_ms': 2.9011427628778637, 'mean_inference_ms': 1.843937997352655}",{},0,144000,"{'sample_time_ms': 69148.978, 'sample_throughput': 57.846, 'learn_time_ms': 17633.901, 'learn_throughput': 226.836}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 54005647671296.0, 'policy_loss': -0.00972267784527503, 'vf_loss': 54005647671296.0, 'vf_explained_var': 3.1664968e-08, 'kl': 0.012054533974151127, 'entropy': 1.324437402188778, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2020595088752640.0, 'policy_loss': -0.0024039554700721055, 'vf_loss': 2020595088752640.0, 'vf_explained_var': 6.891787e-08, 'kl': 0.009982478193705902, 'entropy': 0.5670547541230917, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 144000, 'num_steps_trained': 144000}",False,54,36,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-32-35,1615764755,90.14172291755676,3148.0635023117065,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3148.0635023117065,0,36,"{'cpu_util_percent': 27.076377952755912, 'ram_util_percent': 56.080314960629956}"
71,35,MARL,light1,-1899452563.075036,-27133052971.985477,-8917291045.950068,2658.4074074074074,2,-17310839310.06847,-1624927635.177292,-7221828727.870678,{},"{'episode_reward': [-6570697919.845422, -7553704825.478482, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036], 'episode_lengths': [2900, 2777, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897], 'policy_gneJ12_reward': [-788659730.0194864, -911855825.020136, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448], 'policy_light1_reward': [-5782038189.825922, -6641849000.458346, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292]}","{'mean_env_wait_ms': 13.113102730203664, 'mean_processing_ms': 2.9011427628778637, 'mean_inference_ms': 1.843937997352655}",{},0,144000,"{'sample_time_ms': 69148.978, 'sample_throughput': 57.846, 'learn_time_ms': 17633.901, 'learn_throughput': 226.836}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 54005647671296.0, 'policy_loss': -0.00972267784527503, 'vf_loss': 54005647671296.0, 'vf_explained_var': 3.1664968e-08, 'kl': 0.012054533974151127, 'entropy': 1.324437402188778, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2020595088752640.0, 'policy_loss': -0.0024039554700721055, 'vf_loss': 2020595088752640.0, 'vf_explained_var': 6.891787e-08, 'kl': 0.009982478193705902, 'entropy': 0.5670547541230917, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 144000, 'num_steps_trained': 144000}",False,54,36,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-32-35,1615764755,90.14172291755676,3148.0635023117065,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3148.0635023117065,0,36,"{'cpu_util_percent': 27.076377952755912, 'ram_util_percent': 56.080314960629956}"
72,36,MARL,gneJ12,-1899452563.075036,-27133052971.985477,-8855430258.610935,2654.181818181818,1,-9822213661.916977,-204317492.57638025,-1677972845.9573789,{},"{'episode_reward': [-5514947742.297844, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482], 'episode_lengths': [2426, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777], 'policy_gneJ12_reward': [-733541351.3690573, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136], 'policy_light1_reward': [-4781406390.928801, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346]}","{'mean_env_wait_ms': 13.10745109493028, 'mean_processing_ms': 2.901584275307538, 'mean_inference_ms': 1.8434064669404613}",{},0,148000,"{'sample_time_ms': 68527.027, 'sample_throughput': 58.371, 'learn_time_ms': 17590.641, 'learn_throughput': 227.394}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 52534431449088.0, 'policy_loss': -0.01496959981159307, 'vf_loss': 52534431449088.0, 'vf_explained_var': 1.8626451e-08, 'kl': 0.008359053506865166, 'entropy': 1.2781043611466885, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2255225914130432.0, 'policy_loss': -0.005525876578758471, 'vf_loss': 2255225914130432.0, 'vf_explained_var': 2.4214387e-08, 'kl': 0.010271378952893429, 'entropy': 0.552220388315618, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 148000, 'num_steps_trained': 148000}",False,55,37,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-33-57,1615764837,81.69587087631226,3229.759373188019,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3229.759373188019,0,37,"{'cpu_util_percent': 29.4921052631579, 'ram_util_percent': 56.07456140350879}"
73,36,MARL,light1,-1899452563.075036,-27133052971.985477,-8855430258.610935,2654.181818181818,1,-17310839310.06847,-1624927635.177292,-7177457412.653552,{},"{'episode_reward': [-5514947742.297844, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482], 'episode_lengths': [2426, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777], 'policy_gneJ12_reward': [-733541351.3690573, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136], 'policy_light1_reward': [-4781406390.928801, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346]}","{'mean_env_wait_ms': 13.10745109493028, 'mean_processing_ms': 2.901584275307538, 'mean_inference_ms': 1.8434064669404613}",{},0,148000,"{'sample_time_ms': 68527.027, 'sample_throughput': 58.371, 'learn_time_ms': 17590.641, 'learn_throughput': 227.394}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 52534431449088.0, 'policy_loss': -0.01496959981159307, 'vf_loss': 52534431449088.0, 'vf_explained_var': 1.8626451e-08, 'kl': 0.008359053506865166, 'entropy': 1.2781043611466885, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2255225914130432.0, 'policy_loss': -0.005525876578758471, 'vf_loss': 2255225914130432.0, 'vf_explained_var': 2.4214387e-08, 'kl': 0.010271378952893429, 'entropy': 0.552220388315618, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 148000, 'num_steps_trained': 148000}",False,55,37,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-33-57,1615764837,81.69587087631226,3229.759373188019,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3229.759373188019,0,37,"{'cpu_util_percent': 29.4921052631579, 'ram_util_percent': 56.07456140350879}"
74,37,MARL,gneJ12,-1899452563.075036,-27133052971.985477,-8903267305.901403,2660.2280701754385,2,-9822213661.916977,-204317492.57638025,-1752788358.0589442,{},"{'episode_reward': [-8492121380.279499, -11945450832.499002, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844], 'episode_lengths': [3089, 2564, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426], 'policy_gneJ12_reward': [-1023784513.7641034, -6596645367.939878, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573], 'policy_light1_reward': [-7468336866.515404, -5348805464.559098, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801]}","{'mean_env_wait_ms': 13.09697725544864, 'mean_processing_ms': 2.9035932246432896, 'mean_inference_ms': 1.8423535495219203}",{},0,152000,"{'sample_time_ms': 69202.955, 'sample_throughput': 57.801, 'learn_time_ms': 17624.234, 'learn_throughput': 226.96}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2515475875495936.0, 'policy_loss': -0.007340866082813591, 'vf_loss': 2515475875495936.0, 'vf_explained_var': 6.3329935e-08, 'kl': 0.01712510061042849, 'entropy': 1.906201794743538, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1841754454097920.0, 'policy_loss': -0.00534355832496658, 'vf_loss': 1841754454097920.0, 'vf_explained_var': -7.8231096e-08, 'kl': 0.009516136618913151, 'entropy': 0.70295156724751, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 152000, 'num_steps_trained': 152000}",False,57,38,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-35-31,1615764931,94.16354370117188,3323.9229168891907,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3323.9229168891907,0,38,"{'cpu_util_percent': 26.759090909090908, 'ram_util_percent': 56.07954545454546}"
75,37,MARL,light1,-1899452563.075036,-27133052971.985477,-8903267305.901403,2660.2280701754385,2,-17310839310.06847,-1624927635.177292,-7150478947.842454,{},"{'episode_reward': [-8492121380.279499, -11945450832.499002, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844], 'episode_lengths': [3089, 2564, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426], 'policy_gneJ12_reward': [-1023784513.7641034, -6596645367.939878, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573], 'policy_light1_reward': [-7468336866.515404, -5348805464.559098, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801]}","{'mean_env_wait_ms': 13.09697725544864, 'mean_processing_ms': 2.9035932246432896, 'mean_inference_ms': 1.8423535495219203}",{},0,152000,"{'sample_time_ms': 69202.955, 'sample_throughput': 57.801, 'learn_time_ms': 17624.234, 'learn_throughput': 226.96}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2515475875495936.0, 'policy_loss': -0.007340866082813591, 'vf_loss': 2515475875495936.0, 'vf_explained_var': 6.3329935e-08, 'kl': 0.01712510061042849, 'entropy': 1.906201794743538, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1841754454097920.0, 'policy_loss': -0.00534355832496658, 'vf_loss': 1841754454097920.0, 'vf_explained_var': -7.8231096e-08, 'kl': 0.009516136618913151, 'entropy': 0.70295156724751, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 152000, 'num_steps_trained': 152000}",False,57,38,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-35-31,1615764931,94.16354370117188,3323.9229168891907,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3323.9229168891907,0,38,"{'cpu_util_percent': 26.759090909090908, 'ram_util_percent': 56.07954545454546}"
76,38,MARL,gneJ12,-1899452563.075036,-27133052971.985477,-8820247575.647335,2654.896551724138,1,-9822213661.916977,-204317492.57638025,-1732193784.1507258,{},"{'episode_reward': [-4088122951.1654634, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002], 'episode_lengths': [2351, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564], 'policy_gneJ12_reward': [-558303071.3822882, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878], 'policy_light1_reward': [-3529819879.7831783, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098]}","{'mean_env_wait_ms': 13.091762293188948, 'mean_processing_ms': 2.904184738029139, 'mean_inference_ms': 1.8418222033197704}",{},0,156000,"{'sample_time_ms': 68383.13, 'sample_throughput': 58.494, 'learn_time_ms': 17604.336, 'learn_throughput': 227.217}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 49071905374208.0, 'policy_loss': -0.002564588619861752, 'vf_loss': 49071905374208.0, 'vf_explained_var': -5.2154064e-08, 'kl': 0.013386329505010508, 'entropy': 1.368188425898552, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1529808202760192.0, 'policy_loss': -0.0047410703846253455, 'vf_loss': 1529808202760192.0, 'vf_explained_var': -3.3527613e-08, 'kl': 0.010737538417743053, 'entropy': 0.39429572969675064, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 156000, 'num_steps_trained': 156000}",False,58,39,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-36-53,1615765013,82.21496725082397,3406.1378841400146,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3406.1378841400146,0,39,"{'cpu_util_percent': 29.35043478260869, 'ram_util_percent': 56.085217391304354}"
77,38,MARL,light1,-1899452563.075036,-27133052971.985477,-8820247575.647335,2654.896551724138,1,-17310839310.06847,-1624927635.177292,-7088053791.496605,{},"{'episode_reward': [-4088122951.1654634, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002], 'episode_lengths': [2351, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564], 'policy_gneJ12_reward': [-558303071.3822882, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878], 'policy_light1_reward': [-3529819879.7831783, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098]}","{'mean_env_wait_ms': 13.091762293188948, 'mean_processing_ms': 2.904184738029139, 'mean_inference_ms': 1.8418222033197704}",{},0,156000,"{'sample_time_ms': 68383.13, 'sample_throughput': 58.494, 'learn_time_ms': 17604.336, 'learn_throughput': 227.217}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 49071905374208.0, 'policy_loss': -0.002564588619861752, 'vf_loss': 49071905374208.0, 'vf_explained_var': -5.2154064e-08, 'kl': 0.013386329505010508, 'entropy': 1.368188425898552, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1529808202760192.0, 'policy_loss': -0.0047410703846253455, 'vf_loss': 1529808202760192.0, 'vf_explained_var': -3.3527613e-08, 'kl': 0.010737538417743053, 'entropy': 0.39429572969675064, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 156000, 'num_steps_trained': 156000}",False,58,39,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-36-53,1615765013,82.21496725082397,3406.1378841400146,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3406.1378841400146,0,39,"{'cpu_util_percent': 29.35043478260869, 'ram_util_percent': 56.085217391304354}"
78,39,MARL,gneJ12,-1586253625.9149873,-27133052971.985477,-8661003637.748867,2649.8333333333335,2,-9822213661.916977,-204317492.57638025,-1694335991.775247,{},"{'episode_reward': [-6499605251.471545, -1586253625.9149873, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634], 'episode_lengths': [2554, 2452, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351], 'policy_gneJ12_reward': [-921056562.963085, -271863462.8096377, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882], 'policy_light1_reward': [-5578548688.508451, -1314390163.1053514, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783]}","{'mean_env_wait_ms': 13.081205647893078, 'mean_processing_ms': 2.906257700600052, 'mean_inference_ms': 1.840745343626561}",{},0,160000,"{'sample_time_ms': 68679.042, 'sample_throughput': 58.242, 'learn_time_ms': 17548.307, 'learn_throughput': 227.942}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 20853705375744.0, 'policy_loss': -0.01552172694937326, 'vf_loss': 20853705375744.0, 'vf_explained_var': 5.5879354e-09, 'kl': 0.012046817762893625, 'entropy': 0.999320175498724, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 562808010833920.0, 'policy_loss': -0.0002509024925529957, 'vf_loss': 562808010833920.0, 'vf_explained_var': 2.4214387e-08, 'kl': 0.008530255814548582, 'entropy': 0.10781220035278238, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 160000, 'num_steps_trained': 160000}",False,60,40,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-38-22,1615765102,88.53290009498596,3494.6707842350006,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3494.6707842350006,0,40,"{'cpu_util_percent': 27.748000000000005, 'ram_util_percent': 56.06480000000002}"
79,39,MARL,light1,-1586253625.9149873,-27133052971.985477,-8661003637.748867,2649.8333333333335,2,-17310839310.06847,-1314390163.1053514,-6966667645.973614,{},"{'episode_reward': [-6499605251.471545, -1586253625.9149873, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634], 'episode_lengths': [2554, 2452, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351], 'policy_gneJ12_reward': [-921056562.963085, -271863462.8096377, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882], 'policy_light1_reward': [-5578548688.508451, -1314390163.1053514, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783]}","{'mean_env_wait_ms': 13.081205647893078, 'mean_processing_ms': 2.906257700600052, 'mean_inference_ms': 1.840745343626561}",{},0,160000,"{'sample_time_ms': 68679.042, 'sample_throughput': 58.242, 'learn_time_ms': 17548.307, 'learn_throughput': 227.942}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 20853705375744.0, 'policy_loss': -0.01552172694937326, 'vf_loss': 20853705375744.0, 'vf_explained_var': 5.5879354e-09, 'kl': 0.012046817762893625, 'entropy': 0.999320175498724, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 562808010833920.0, 'policy_loss': -0.0002509024925529957, 'vf_loss': 562808010833920.0, 'vf_explained_var': 2.4214387e-08, 'kl': 0.008530255814548582, 'entropy': 0.10781220035278238, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 160000, 'num_steps_trained': 160000}",False,60,40,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-38-22,1615765102,88.53290009498596,3494.6707842350006,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3494.6707842350006,0,40,"{'cpu_util_percent': 27.748000000000005, 'ram_util_percent': 56.06480000000002}"
80,40,MARL,gneJ12,-1586253625.9149873,-27133052971.985477,-8521210051.510743,2639.0806451612902,2,-9822213661.916977,-204317492.57638025,-1657658689.1868262,{},"{'episode_reward': [-1801067152.5777302, -6853737776.156333, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873], 'episode_lengths': [1657, 2976, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452], 'policy_gneJ12_reward': [-247339455.04402637, -867339768.0243667, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377], 'policy_light1_reward': [-1553727697.5337029, -5986398008.131959, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514]}","{'mean_env_wait_ms': 13.070895621055886, 'mean_processing_ms': 2.9093397686429916, 'mean_inference_ms': 1.839682550513463}",{},0,164000,"{'sample_time_ms': 69639.025, 'sample_throughput': 57.439, 'learn_time_ms': 17591.462, 'learn_throughput': 227.383}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 57850322485248.0, 'policy_loss': -0.016238215728662908, 'vf_loss': 57850322485248.0, 'vf_explained_var': -1.1175871e-08, 'kl': 0.014553283937857486, 'entropy': 1.3240335918962955, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1549524745060352.0, 'policy_loss': -0.014093431935179979, 'vf_loss': 1549524745060352.0, 'vf_explained_var': -3.3527613e-08, 'kl': 0.01111783305532299, 'entropy': 0.3094065338373184, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 164000, 'num_steps_trained': 164000}",False,62,41,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-39-53,1615765193,91.17164897918701,3585.8424332141876,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3585.8424332141876,0,41,"{'cpu_util_percent': 26.229133858267712, 'ram_util_percent': 55.96535433070867}"
81,40,MARL,light1,-1586253625.9149873,-27133052971.985477,-8521210051.510743,2639.0806451612902,2,-17310839310.06847,-1314390163.1053514,-6863551362.323911,{},"{'episode_reward': [-1801067152.5777302, -6853737776.156333, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873], 'episode_lengths': [1657, 2976, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452], 'policy_gneJ12_reward': [-247339455.04402637, -867339768.0243667, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377], 'policy_light1_reward': [-1553727697.5337029, -5986398008.131959, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514]}","{'mean_env_wait_ms': 13.070895621055886, 'mean_processing_ms': 2.9093397686429916, 'mean_inference_ms': 1.839682550513463}",{},0,164000,"{'sample_time_ms': 69639.025, 'sample_throughput': 57.439, 'learn_time_ms': 17591.462, 'learn_throughput': 227.383}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 57850322485248.0, 'policy_loss': -0.016238215728662908, 'vf_loss': 57850322485248.0, 'vf_explained_var': -1.1175871e-08, 'kl': 0.014553283937857486, 'entropy': 1.3240335918962955, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1549524745060352.0, 'policy_loss': -0.014093431935179979, 'vf_loss': 1549524745060352.0, 'vf_explained_var': -3.3527613e-08, 'kl': 0.01111783305532299, 'entropy': 0.3094065338373184, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 164000, 'num_steps_trained': 164000}",False,62,41,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-39-53,1615765193,91.17164897918701,3585.8424332141876,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3585.8424332141876,0,41,"{'cpu_util_percent': 26.229133858267712, 'ram_util_percent': 55.96535433070867}"
82,41,MARL,gneJ12,-1586253625.9149873,-27133052971.985477,-8508250262.899368,2637.031746031746,1,-9822213661.916977,-204317492.57638025,-1651243762.825433,{},"{'episode_reward': [-7704743368.9942, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333], 'episode_lengths': [2510, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976], 'policy_gneJ12_reward': [-1253518328.4190695, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667], 'policy_light1_reward': [-6451225040.575131, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959]}","{'mean_env_wait_ms': 13.065945086835542, 'mean_processing_ms': 2.9104385157076846, 'mean_inference_ms': 1.839159234216314}",{},0,168000,"{'sample_time_ms': 69207.823, 'sample_throughput': 57.797, 'learn_time_ms': 17680.58, 'learn_throughput': 226.237}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 84916880932864.0, 'policy_loss': -0.011797886807471514, 'vf_loss': 84916880932864.0, 'vf_explained_var': -9.685755e-08, 'kl': 0.015228292875690386, 'entropy': 1.8039835207164288, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2354649852018688.0, 'policy_loss': -0.0062121651717461646, 'vf_loss': 2354649852018688.0, 'vf_explained_var': -1.0058284e-07, 'kl': 0.009932026339811273, 'entropy': 0.6452535707503557, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 168000, 'num_steps_trained': 168000}",False,63,42,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-41-17,1615765277,83.78646564483643,3669.628898859024,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3669.628898859024,0,42,"{'cpu_util_percent': 29.577118644067795, 'ram_util_percent': 55.788135593220325}"
83,41,MARL,light1,-1586253625.9149873,-27133052971.985477,-8508250262.899368,2637.031746031746,1,-17310839310.06847,-1314390163.1053514,-6857006500.073931,{},"{'episode_reward': [-7704743368.9942, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333], 'episode_lengths': [2510, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976], 'policy_gneJ12_reward': [-1253518328.4190695, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667], 'policy_light1_reward': [-6451225040.575131, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959]}","{'mean_env_wait_ms': 13.065945086835542, 'mean_processing_ms': 2.9104385157076846, 'mean_inference_ms': 1.839159234216314}",{},0,168000,"{'sample_time_ms': 69207.823, 'sample_throughput': 57.797, 'learn_time_ms': 17680.58, 'learn_throughput': 226.237}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 84916880932864.0, 'policy_loss': -0.011797886807471514, 'vf_loss': 84916880932864.0, 'vf_explained_var': -9.685755e-08, 'kl': 0.015228292875690386, 'entropy': 1.8039835207164288, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2354649852018688.0, 'policy_loss': -0.0062121651717461646, 'vf_loss': 2354649852018688.0, 'vf_explained_var': -1.0058284e-07, 'kl': 0.009932026339811273, 'entropy': 0.6452535707503557, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 168000, 'num_steps_trained': 168000}",False,63,42,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-41-17,1615765277,83.78646564483643,3669.628898859024,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3669.628898859024,0,42,"{'cpu_util_percent': 29.577118644067795, 'ram_util_percent': 55.788135593220325}"
84,42,MARL,gneJ12,-1586253625.9149873,-27133052971.985477,-8464754491.509172,2630.923076923077,2,-9822213661.916977,-204317492.57638025,-1644263017.2173848,{},"{'episode_reward': [-6768426710.217544, -7420848675.218515, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942], 'episode_lengths': [2663, 2214, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510], 'policy_gneJ12_reward': [-988177609.2836069, -1860561451.8441384, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695], 'policy_light1_reward': [-5780249100.933933, -5560287223.374365, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131]}","{'mean_env_wait_ms': 13.056543425944648, 'mean_processing_ms': 2.9131337578646646, 'mean_inference_ms': 1.8381427847204286}",{},0,172000,"{'sample_time_ms': 69937.156, 'sample_throughput': 57.194, 'learn_time_ms': 17708.456, 'learn_throughput': 225.881}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 357879417143296.0, 'policy_loss': -0.004674596799304709, 'vf_loss': 357879417143296.0, 'vf_explained_var': 4.656613e-08, 'kl': 0.016767827401054092, 'entropy': 1.9396243169903755, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2358051193487360.0, 'policy_loss': 0.00467472686432302, 'vf_loss': 2358051193487360.0, 'vf_explained_var': -1.0430813e-07, 'kl': 0.014495489827822894, 'entropy': 0.630737716332078, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 172000, 'num_steps_trained': 172000}",False,65,43,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-42-49,1615765369,91.79830193519592,3761.42720079422,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3761.42720079422,0,43,"{'cpu_util_percent': 28.61328125, 'ram_util_percent': 55.79921874999998}"
85,42,MARL,light1,-1586253625.9149873,-27133052971.985477,-8464754491.509172,2630.923076923077,2,-17310839310.06847,-1314390163.1053514,-6820491474.291784,{},"{'episode_reward': [-6768426710.217544, -7420848675.218515, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942], 'episode_lengths': [2663, 2214, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510], 'policy_gneJ12_reward': [-988177609.2836069, -1860561451.8441384, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695], 'policy_light1_reward': [-5780249100.933933, -5560287223.374365, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131]}","{'mean_env_wait_ms': 13.056543425944648, 'mean_processing_ms': 2.9131337578646646, 'mean_inference_ms': 1.8381427847204286}",{},0,172000,"{'sample_time_ms': 69937.156, 'sample_throughput': 57.194, 'learn_time_ms': 17708.456, 'learn_throughput': 225.881}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 357879417143296.0, 'policy_loss': -0.004674596799304709, 'vf_loss': 357879417143296.0, 'vf_explained_var': 4.656613e-08, 'kl': 0.016767827401054092, 'entropy': 1.9396243169903755, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2358051193487360.0, 'policy_loss': 0.00467472686432302, 'vf_loss': 2358051193487360.0, 'vf_explained_var': -1.0430813e-07, 'kl': 0.014495489827822894, 'entropy': 0.630737716332078, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 172000, 'num_steps_trained': 172000}",False,65,43,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-42-49,1615765369,91.79830193519592,3761.42720079422,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3761.42720079422,0,43,"{'cpu_util_percent': 28.61328125, 'ram_util_percent': 55.79921874999998}"
86,43,MARL,gneJ12,-1586253625.9149873,-27133052971.985477,-8348089493.505511,2617.507462686567,2,-9822213661.916977,-204317492.57638025,-1612005322.08734,{},"{'episode_reward': [-4625812054.418986, -4487142062.354038, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515], 'episode_lengths': [2352, 2011, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214], 'policy_gneJ12_reward': [-556562328.9997866, -570698131.7220047, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384], 'policy_light1_reward': [-4069249725.4192, -3916443930.6320415, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365]}","{'mean_env_wait_ms': 13.047336569443967, 'mean_processing_ms': 2.9162625392712833, 'mean_inference_ms': 1.837147205891562}",{},0,176000,"{'sample_time_ms': 69615.33, 'sample_throughput': 57.459, 'learn_time_ms': 17716.754, 'learn_throughput': 225.775}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 39576889589760.0, 'policy_loss': -0.008870070683769882, 'vf_loss': 39576889589760.0, 'vf_explained_var': 0.0, 'kl': 0.02101743724779226, 'entropy': 1.2267176322638988, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1528261133729792.0, 'policy_loss': -0.002594856370706111, 'vf_loss': 1528261133729792.0, 'vf_explained_var': -1.0058284e-07, 'kl': 0.013044390841969289, 'entropy': 0.3560022967867553, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 176000, 'num_steps_trained': 176000}",False,67,44,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-44-18,1615765458,89.11138081550598,3850.538581609726,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3850.538581609726,0,44,"{'cpu_util_percent': 27.641600000000004, 'ram_util_percent': 55.802399999999984}"
87,43,MARL,light1,-1586253625.9149873,-27133052971.985477,-8348089493.505511,2617.507462686567,2,-17310839310.06847,-1314390163.1053514,-6736084171.418168,{},"{'episode_reward': [-4625812054.418986, -4487142062.354038, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515], 'episode_lengths': [2352, 2011, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214], 'policy_gneJ12_reward': [-556562328.9997866, -570698131.7220047, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384], 'policy_light1_reward': [-4069249725.4192, -3916443930.6320415, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365]}","{'mean_env_wait_ms': 13.047336569443967, 'mean_processing_ms': 2.9162625392712833, 'mean_inference_ms': 1.837147205891562}",{},0,176000,"{'sample_time_ms': 69615.33, 'sample_throughput': 57.459, 'learn_time_ms': 17716.754, 'learn_throughput': 225.775}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 39576889589760.0, 'policy_loss': -0.008870070683769882, 'vf_loss': 39576889589760.0, 'vf_explained_var': 0.0, 'kl': 0.02101743724779226, 'entropy': 1.2267176322638988, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1528261133729792.0, 'policy_loss': -0.002594856370706111, 'vf_loss': 1528261133729792.0, 'vf_explained_var': -1.0058284e-07, 'kl': 0.013044390841969289, 'entropy': 0.3560022967867553, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 176000, 'num_steps_trained': 176000}",False,67,44,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-44-18,1615765458,89.11138081550598,3850.538581609726,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3850.538581609726,0,44,"{'cpu_util_percent': 27.641600000000004, 'ram_util_percent': 55.802399999999984}"
88,44,MARL,gneJ12,-1586253625.9149873,-27133052971.985477,-8326275908.326707,2613.1911764705883,1,-9822213661.916977,-204317492.57638025,-1600000687.3851502,{},"{'episode_reward': [-6864765701.346848, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038], 'episode_lengths': [2324, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011], 'policy_gneJ12_reward': [-795690162.3384116, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047], 'policy_light1_reward': [-6069075539.008424, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415]}","{'mean_env_wait_ms': 13.042787165298707, 'mean_processing_ms': 2.9174607131756467, 'mean_inference_ms': 1.836657303469355}",{},0,180000,"{'sample_time_ms': 69744.746, 'sample_throughput': 57.352, 'learn_time_ms': 17763.248, 'learn_throughput': 225.184}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 51198465802240.0, 'policy_loss': -0.015287103247828782, 'vf_loss': 51198465802240.0, 'vf_explained_var': -5.5879354e-09, 'kl': 0.007782529784890357, 'entropy': 1.3415877558290958, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2093328736714752.0, 'policy_loss': 0.0028134359745308757, 'vf_loss': 2093328736714752.0, 'vf_explained_var': -1.8626451e-08, 'kl': 0.013304664200404659, 'entropy': 0.34489861968904734, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 180000, 'num_steps_trained': 180000}",False,68,45,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-45-40,1615765540,82.4667398929596,3933.0053215026855,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3933.0053215026855,0,45,"{'cpu_util_percent': 29.58448275862069, 'ram_util_percent': 55.8}"
89,44,MARL,light1,-1586253625.9149873,-27133052971.985477,-8326275908.326707,2613.1911764705883,1,-17310839310.06847,-1314390163.1053514,-6726275220.941554,{},"{'episode_reward': [-6864765701.346848, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038], 'episode_lengths': [2324, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011], 'policy_gneJ12_reward': [-795690162.3384116, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047], 'policy_light1_reward': [-6069075539.008424, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415]}","{'mean_env_wait_ms': 13.042787165298707, 'mean_processing_ms': 2.9174607131756467, 'mean_inference_ms': 1.836657303469355}",{},0,180000,"{'sample_time_ms': 69744.746, 'sample_throughput': 57.352, 'learn_time_ms': 17763.248, 'learn_throughput': 225.184}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 51198465802240.0, 'policy_loss': -0.015287103247828782, 'vf_loss': 51198465802240.0, 'vf_explained_var': -5.5879354e-09, 'kl': 0.007782529784890357, 'entropy': 1.3415877558290958, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2093328736714752.0, 'policy_loss': 0.0028134359745308757, 'vf_loss': 2093328736714752.0, 'vf_explained_var': -1.8626451e-08, 'kl': 0.013304664200404659, 'entropy': 0.34489861968904734, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 180000, 'num_steps_trained': 180000}",False,68,45,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-45-40,1615765540,82.4667398929596,3933.0053215026855,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3933.0053215026855,0,45,"{'cpu_util_percent': 29.58448275862069, 'ram_util_percent': 55.8}"
90,45,MARL,gneJ12,-1586253625.9149873,-27133052971.985477,-8181379312.726749,2604.9714285714285,2,-9822213661.916977,-204317492.57638025,-1566580190.543328,{},"{'episode_reward': [-4870267249.37805, -1639522875.2783349, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848], 'episode_lengths': [2647, 2004, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324], 'policy_gneJ12_reward': [-632681766.332957, -227884829.50978658, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116], 'policy_light1_reward': [-4237585483.045102, -1411638045.7685473, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424]}","{'mean_env_wait_ms': 13.033815124426006, 'mean_processing_ms': 2.9201709424385314, 'mean_inference_ms': 1.8356849177935939}",{},0,184000,"{'sample_time_ms': 69602.084, 'sample_throughput': 57.47, 'learn_time_ms': 17742.879, 'learn_throughput': 225.443}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 54816889896960.0, 'policy_loss': -0.008853078485117294, 'vf_loss': 54816889896960.0, 'vf_explained_var': 1.4901161e-08, 'kl': 0.00970120522833895, 'entropy': 1.2779946513473988, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1718767432237056.0, 'policy_loss': -0.006197827868163586, 'vf_loss': 1718767432237056.0, 'vf_explained_var': 4.656613e-08, 'kl': 0.007416154701786581, 'entropy': 0.1892842010129243, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 184000, 'num_steps_trained': 184000}",False,70,46,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-47-09,1615765629,88.5117437839508,4021.5170652866364,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4021.5170652866364,0,46,"{'cpu_util_percent': 27.900806451612905, 'ram_util_percent': 55.79919354838709}"
91,45,MARL,light1,-1586253625.9149873,-27133052971.985477,-8181379312.726749,2604.9714285714285,2,-17310839310.06847,-1314390163.1053514,-6614799122.183419,{},"{'episode_reward': [-4870267249.37805, -1639522875.2783349, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848], 'episode_lengths': [2647, 2004, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324], 'policy_gneJ12_reward': [-632681766.332957, -227884829.50978658, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116], 'policy_light1_reward': [-4237585483.045102, -1411638045.7685473, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424]}","{'mean_env_wait_ms': 13.033815124426006, 'mean_processing_ms': 2.9201709424385314, 'mean_inference_ms': 1.8356849177935939}",{},0,184000,"{'sample_time_ms': 69602.084, 'sample_throughput': 57.47, 'learn_time_ms': 17742.879, 'learn_throughput': 225.443}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 54816889896960.0, 'policy_loss': -0.008853078485117294, 'vf_loss': 54816889896960.0, 'vf_explained_var': 1.4901161e-08, 'kl': 0.00970120522833895, 'entropy': 1.2779946513473988, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1718767432237056.0, 'policy_loss': -0.006197827868163586, 'vf_loss': 1718767432237056.0, 'vf_explained_var': 4.656613e-08, 'kl': 0.007416154701786581, 'entropy': 0.1892842010129243, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 184000, 'num_steps_trained': 184000}",False,70,46,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-47-09,1615765629,88.5117437839508,4021.5170652866364,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4021.5170652866364,0,46,"{'cpu_util_percent': 27.900806451612905, 'ram_util_percent': 55.79919354838709}"
92,46,MARL,gneJ12,-1586253625.9149873,-27133052971.985477,-8152103316.906155,2595.125,2,-9822213661.916977,-204317492.57638025,-1553365190.2022748,{},"{'episode_reward': [-6708572242.851304, -7546314683.5192585, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349], 'episode_lengths': [1892, 2609, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004], 'policy_gneJ12_reward': [-901426832.7389537, -1280253523.7918642, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658], 'policy_light1_reward': [-5807145410.112333, -6266061159.727385, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473]}","{'mean_env_wait_ms': 13.025324485046049, 'mean_processing_ms': 2.9231562389660253, 'mean_inference_ms': 1.834742395686889}",{},0,188000,"{'sample_time_ms': 70487.271, 'sample_throughput': 56.748, 'learn_time_ms': 17758.58, 'learn_throughput': 225.243}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 95997452877824.0, 'policy_loss': -0.014351343299495056, 'vf_loss': 95997452877824.0, 'vf_explained_var': -7.4505806e-08, 'kl': 0.009907849074807018, 'entropy': 1.8237201012670994, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2404952429297664.0, 'policy_loss': -0.006350045732688159, 'vf_loss': 2404952429297664.0, 'vf_explained_var': 8.009374e-08, 'kl': 0.010591968763037585, 'entropy': 0.599286581389606, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 188000, 'num_steps_trained': 188000}",False,72,47,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-48-40,1615765720,90.70422697067261,4112.221292257309,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4112.221292257309,0,47,"{'cpu_util_percent': 27.79291338582678, 'ram_util_percent': 55.83228346456693}"
93,46,MARL,light1,-1586253625.9149873,-27133052971.985477,-8152103316.906155,2595.125,2,-17310839310.06847,-1314390163.1053514,-6598738126.703876,{},"{'episode_reward': [-6708572242.851304, -7546314683.5192585, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349], 'episode_lengths': [1892, 2609, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004], 'policy_gneJ12_reward': [-901426832.7389537, -1280253523.7918642, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658], 'policy_light1_reward': [-5807145410.112333, -6266061159.727385, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473]}","{'mean_env_wait_ms': 13.025324485046049, 'mean_processing_ms': 2.9231562389660253, 'mean_inference_ms': 1.834742395686889}",{},0,188000,"{'sample_time_ms': 70487.271, 'sample_throughput': 56.748, 'learn_time_ms': 17758.58, 'learn_throughput': 225.243}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 95997452877824.0, 'policy_loss': -0.014351343299495056, 'vf_loss': 95997452877824.0, 'vf_explained_var': -7.4505806e-08, 'kl': 0.009907849074807018, 'entropy': 1.8237201012670994, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2404952429297664.0, 'policy_loss': -0.006350045732688159, 'vf_loss': 2404952429297664.0, 'vf_explained_var': 8.009374e-08, 'kl': 0.010591968763037585, 'entropy': 0.599286581389606, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 188000, 'num_steps_trained': 188000}",False,72,47,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-48-40,1615765720,90.70422697067261,4112.221292257309,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4112.221292257309,0,47,"{'cpu_util_percent': 27.79291338582678, 'ram_util_percent': 55.83228346456693}"
94,47,MARL,gneJ12,-1586253625.9149873,-27133052971.985477,-8121324166.424465,2596.150684931507,1,-9822213661.916977,-204317492.57638025,-1540849389.667095,{},"{'episode_reward': [-5905225331.742798, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585], 'episode_lengths': [2670, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609], 'policy_gneJ12_reward': [-639711751.1341465, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642], 'policy_light1_reward': [-5265513580.608659, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385]}","{'mean_env_wait_ms': 13.021176032591713, 'mean_processing_ms': 2.9242791628600795, 'mean_inference_ms': 1.8342786544658556}",{},0,192000,"{'sample_time_ms': 69346.015, 'sample_throughput': 57.682, 'learn_time_ms': 17740.403, 'learn_throughput': 225.474}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 59098354286592.0, 'policy_loss': -0.010554796434007585, 'vf_loss': 59098354286592.0, 'vf_explained_var': -4.8428774e-08, 'kl': 0.00888196361484006, 'entropy': 1.4853422231972218, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2711891403079680.0, 'policy_loss': -0.0032895248441491276, 'vf_loss': 2711891403079680.0, 'vf_explained_var': -1.1920929e-07, 'kl': 0.014770868205232546, 'entropy': 0.5252287676557899, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 192000, 'num_steps_trained': 192000}",False,73,48,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-50-02,1615765802,82.57022213935852,4194.7915143966675,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4194.7915143966675,0,48,"{'cpu_util_percent': 29.976724137931033, 'ram_util_percent': 55.81724137931034}"
95,47,MARL,light1,-1586253625.9149873,-27133052971.985477,-8121324166.424465,2596.150684931507,1,-17310839310.06847,-1314390163.1053514,-6580474776.757365,{},"{'episode_reward': [-5905225331.742798, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585], 'episode_lengths': [2670, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609], 'policy_gneJ12_reward': [-639711751.1341465, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642], 'policy_light1_reward': [-5265513580.608659, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385]}","{'mean_env_wait_ms': 13.021176032591713, 'mean_processing_ms': 2.9242791628600795, 'mean_inference_ms': 1.8342786544658556}",{},0,192000,"{'sample_time_ms': 69346.015, 'sample_throughput': 57.682, 'learn_time_ms': 17740.403, 'learn_throughput': 225.474}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 59098354286592.0, 'policy_loss': -0.010554796434007585, 'vf_loss': 59098354286592.0, 'vf_explained_var': -4.8428774e-08, 'kl': 0.00888196361484006, 'entropy': 1.4853422231972218, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2711891403079680.0, 'policy_loss': -0.0032895248441491276, 'vf_loss': 2711891403079680.0, 'vf_explained_var': -1.1920929e-07, 'kl': 0.014770868205232546, 'entropy': 0.5252287676557899, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 192000, 'num_steps_trained': 192000}",False,73,48,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-50-02,1615765802,82.57022213935852,4194.7915143966675,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4194.7915143966675,0,48,"{'cpu_util_percent': 29.976724137931033, 'ram_util_percent': 55.81724137931034}"
96,48,MARL,gneJ12,-1586253625.9149873,-27133052971.985477,-8001320011.980724,2577.1315789473683,3,-9822213661.916977,-204317492.57638025,-1504296247.6723435,{},"{'episode_reward': [-8242793270.027031, -4223133343.6774235, -2777730147.84472, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798], 'episode_lengths': [2570, 1660, 2113, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670], 'policy_gneJ12_reward': [-891188399.2217511, -621121382.1755627, -332199596.00286424, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465], 'policy_light1_reward': [-7351604870.805295, -3602011961.5018635, -2445530551.841857, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659]}","{'mean_env_wait_ms': 13.008954202460771, 'mean_processing_ms': 2.929428175725814, 'mean_inference_ms': 1.8329060335707432}",{},0,196000,"{'sample_time_ms': 70636.386, 'sample_throughput': 56.628, 'learn_time_ms': 17731.515, 'learn_throughput': 225.587}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 44569139675136.0, 'policy_loss': -0.009118578207562678, 'vf_loss': 44569139675136.0, 'vf_explained_var': -5.2154064e-08, 'kl': 0.01203964522574097, 'entropy': 0.9679470844566822, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1185444305829888.0, 'policy_loss': -0.003518213576171547, 'vf_loss': 1185444305829888.0, 'vf_explained_var': -3.7252903e-08, 'kl': 0.009213257930241525, 'entropy': 0.20634333812631667, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 196000, 'num_steps_trained': 196000}",False,76,49,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-51-38,1615765898,95.02990007400513,4289.821414470673,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4289.821414470673,0,49,"{'cpu_util_percent': 26.07218045112782, 'ram_util_percent': 55.83759398496242}"
97,48,MARL,light1,-1586253625.9149873,-27133052971.985477,-8001320011.980724,2577.1315789473683,3,-17310839310.06847,-1314390163.1053514,-6497023764.308377,{},"{'episode_reward': [-8242793270.027031, -4223133343.6774235, -2777730147.84472, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798], 'episode_lengths': [2570, 1660, 2113, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670], 'policy_gneJ12_reward': [-891188399.2217511, -621121382.1755627, -332199596.00286424, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465], 'policy_light1_reward': [-7351604870.805295, -3602011961.5018635, -2445530551.841857, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659]}","{'mean_env_wait_ms': 13.008954202460771, 'mean_processing_ms': 2.929428175725814, 'mean_inference_ms': 1.8329060335707432}",{},0,196000,"{'sample_time_ms': 70636.386, 'sample_throughput': 56.628, 'learn_time_ms': 17731.515, 'learn_throughput': 225.587}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 44569139675136.0, 'policy_loss': -0.009118578207562678, 'vf_loss': 44569139675136.0, 'vf_explained_var': -5.2154064e-08, 'kl': 0.01203964522574097, 'entropy': 0.9679470844566822, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1185444305829888.0, 'policy_loss': -0.003518213576171547, 'vf_loss': 1185444305829888.0, 'vf_explained_var': -3.7252903e-08, 'kl': 0.009213257930241525, 'entropy': 0.20634333812631667, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 196000, 'num_steps_trained': 196000}",False,76,49,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-51-38,1615765898,95.02990007400513,4289.821414470673,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4289.821414470673,0,49,"{'cpu_util_percent': 26.07218045112782, 'ram_util_percent': 55.83759398496242}"
98,49,MARL,gneJ12,-1586253625.9149873,-27133052971.985477,-7965852552.8036585,2582.8571428571427,1,-9822213661.916977,-204317492.57638025,-1493483788.3813171,{},"{'episode_reward': [-5270325655.346786, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472], 'episode_lengths': [3018, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113], 'policy_gneJ12_reward': [-671736882.2632983, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424], 'policy_light1_reward': [-4598588773.083479, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857]}","{'mean_env_wait_ms': 13.004986354737513, 'mean_processing_ms': 2.930784495271227, 'mean_inference_ms': 1.832460626412967}",{},0,200000,"{'sample_time_ms': 69935.455, 'sample_throughput': 57.196, 'learn_time_ms': 17775.016, 'learn_throughput': 225.035}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 35807184355328.0, 'policy_loss': -0.015587599948048592, 'vf_loss': 35807184355328.0, 'vf_explained_var': -7.4505806e-08, 'kl': 0.010317919150111265, 'entropy': 1.180663913488388, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1552883615006720.0, 'policy_loss': -0.008577185217291117, 'vf_loss': 1552883615006720.0, 'vf_explained_var': 5.9604645e-08, 'kl': 0.010354466110584326, 'entropy': 0.25554839707911015, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 200000, 'num_steps_trained': 200000}",False,77,50,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-53-00,1615765980,81.95872092247009,4371.780135393143,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4371.780135393143,0,50,"{'cpu_util_percent': 30.066086956521733, 'ram_util_percent': 55.79999999999999}"
99,49,MARL,light1,-1586253625.9149873,-27133052971.985477,-7965852552.8036585,2582.8571428571427,1,-17310839310.06847,-1314390163.1053514,-6472368764.42234,{},"{'episode_reward': [-5270325655.346786, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472], 'episode_lengths': [3018, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113], 'policy_gneJ12_reward': [-671736882.2632983, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424], 'policy_light1_reward': [-4598588773.083479, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857]}","{'mean_env_wait_ms': 13.004986354737513, 'mean_processing_ms': 2.930784495271227, 'mean_inference_ms': 1.832460626412967}",{},0,200000,"{'sample_time_ms': 69935.455, 'sample_throughput': 57.196, 'learn_time_ms': 17775.016, 'learn_throughput': 225.035}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 35807184355328.0, 'policy_loss': -0.015587599948048592, 'vf_loss': 35807184355328.0, 'vf_explained_var': -7.4505806e-08, 'kl': 0.010317919150111265, 'entropy': 1.180663913488388, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1552883615006720.0, 'policy_loss': -0.008577185217291117, 'vf_loss': 1552883615006720.0, 'vf_explained_var': 5.9604645e-08, 'kl': 0.010354466110584326, 'entropy': 0.25554839707911015, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 200000, 'num_steps_trained': 200000}",False,77,50,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-53-00,1615765980,81.95872092247009,4371.780135393143,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4371.780135393143,0,50,"{'cpu_util_percent': 30.066086956521733, 'ram_util_percent': 55.79999999999999}"
100,50,MARL,gneJ12,-1586253625.9149873,-27133052971.985477,-7905130148.660141,2565.6455696202534,2,-9822213661.916977,-204317492.57638025,-1473167265.2210102,{},"{'episode_reward': [-5670063266.560047, -5464571911.70924, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786], 'episode_lengths': [2050, 1756, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018], 'policy_gneJ12_reward': [-678823786.4679896, -703138460.6303816, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983], 'policy_light1_reward': [-4991239480.092057, -4761433451.078865, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479]}","{'mean_env_wait_ms': 12.99719641156893, 'mean_processing_ms': 2.933780730318296, 'mean_inference_ms': 1.8315795397630739}",{},0,204000,"{'sample_time_ms': 69764.219, 'sample_throughput': 57.336, 'learn_time_ms': 17837.094, 'learn_throughput': 224.252}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 69880440029184.0, 'policy_loss': -0.007769937394186854, 'vf_loss': 69880440029184.0, 'vf_explained_var': 0.0, 'kl': 0.008316568928421475, 'entropy': 1.6282798573374748, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2355411608928256.0, 'policy_loss': -0.0015104067424545065, 'vf_loss': 2355411608928256.0, 'vf_explained_var': 1.8626451e-08, 'kl': 0.01220658005331643, 'entropy': 0.41987371165305376, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 204000, 'num_steps_trained': 204000}",False,79,51,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-54-30,1615766070,90.08069086074829,4461.860826253891,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4461.860826253891,0,51,"{'cpu_util_percent': 28.08333333333333, 'ram_util_percent': 55.85238095238094}"
101,50,MARL,light1,-1586253625.9149873,-27133052971.985477,-7905130148.660141,2565.6455696202534,2,-17310839310.06847,-1314390163.1053514,-6431962883.439128,{},"{'episode_reward': [-5670063266.560047, -5464571911.70924, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786], 'episode_lengths': [2050, 1756, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018], 'policy_gneJ12_reward': [-678823786.4679896, -703138460.6303816, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983], 'policy_light1_reward': [-4991239480.092057, -4761433451.078865, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479]}","{'mean_env_wait_ms': 12.99719641156893, 'mean_processing_ms': 2.933780730318296, 'mean_inference_ms': 1.8315795397630739}",{},0,204000,"{'sample_time_ms': 69764.219, 'sample_throughput': 57.336, 'learn_time_ms': 17837.094, 'learn_throughput': 224.252}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 69880440029184.0, 'policy_loss': -0.007769937394186854, 'vf_loss': 69880440029184.0, 'vf_explained_var': 0.0, 'kl': 0.008316568928421475, 'entropy': 1.6282798573374748, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2355411608928256.0, 'policy_loss': -0.0015104067424545065, 'vf_loss': 2355411608928256.0, 'vf_explained_var': 1.8626451e-08, 'kl': 0.01220658005331643, 'entropy': 0.41987371165305376, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 204000, 'num_steps_trained': 204000}",False,79,51,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-54-30,1615766070,90.08069086074829,4461.860826253891,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4461.860826253891,0,51,"{'cpu_util_percent': 28.08333333333333, 'ram_util_percent': 55.85238095238094}"
102,51,MARL,gneJ12,-1586253625.9149873,-27133052971.985477,-7890034798.390619,2563.3333333333335,2,-9822213661.916977,-204317492.57638025,-1462578368.0807292,{},"{'episode_reward': [-5246412218.409226, -9341124707.079725, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924], 'episode_lengths': [2197, 2747, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756], 'policy_gneJ12_reward': [-685997399.8092675, -1402636462.2700272, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816], 'policy_light1_reward': [-4560414818.599954, -7938488244.809711, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865]}","{'mean_env_wait_ms': 12.989710138056353, 'mean_processing_ms': 2.936994627691542, 'mean_inference_ms': 1.8307321722164493}",{},0,208000,"{'sample_time_ms': 70437.086, 'sample_throughput': 56.788, 'learn_time_ms': 17850.305, 'learn_throughput': 224.086}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 106823618920448.0, 'policy_loss': -0.007098679488990456, 'vf_loss': 106823618920448.0, 'vf_explained_var': 4.284084e-08, 'kl': 0.008800513605820015, 'entropy': 1.9813206419348717, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2936185395609600.0, 'policy_loss': -0.00918784560781205, 'vf_loss': 2936185395609600.0, 'vf_explained_var': 8.381903e-08, 'kl': 0.008744426757402834, 'entropy': 0.5134716657921672, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 208000, 'num_steps_trained': 208000}",False,81,52,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-56-00,1615766160,90.6481990814209,4552.509025335312,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4552.509025335312,0,52,"{'cpu_util_percent': 28.124409448818895, 'ram_util_percent': 56.64094488188976}"
103,51,MARL,light1,-1586253625.9149873,-27133052971.985477,-7890034798.390619,2563.3333333333335,2,-17310839310.06847,-1314390163.1053514,-6427456430.309886,{},"{'episode_reward': [-5246412218.409226, -9341124707.079725, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924], 'episode_lengths': [2197, 2747, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756], 'policy_gneJ12_reward': [-685997399.8092675, -1402636462.2700272, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816], 'policy_light1_reward': [-4560414818.599954, -7938488244.809711, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865]}","{'mean_env_wait_ms': 12.989710138056353, 'mean_processing_ms': 2.936994627691542, 'mean_inference_ms': 1.8307321722164493}",{},0,208000,"{'sample_time_ms': 70437.086, 'sample_throughput': 56.788, 'learn_time_ms': 17850.305, 'learn_throughput': 224.086}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 106823618920448.0, 'policy_loss': -0.007098679488990456, 'vf_loss': 106823618920448.0, 'vf_explained_var': 4.284084e-08, 'kl': 0.008800513605820015, 'entropy': 1.9813206419348717, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2936185395609600.0, 'policy_loss': -0.00918784560781205, 'vf_loss': 2936185395609600.0, 'vf_explained_var': 8.381903e-08, 'kl': 0.008744426757402834, 'entropy': 0.5134716657921672, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 208000, 'num_steps_trained': 208000}",False,81,52,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-56-00,1615766160,90.6481990814209,4552.509025335312,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4552.509025335312,0,52,"{'cpu_util_percent': 28.124409448818895, 'ram_util_percent': 56.64094488188976}"
104,52,MARL,gneJ12,-1586253625.9149873,-27133052971.985477,-7870438118.237324,2556.0731707317073,1,-9822213661.916977,-204317492.57638025,-1455149812.0387042,{},"{'episode_reward': [-6283107025.820504, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725], 'episode_lengths': [1968, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747], 'policy_gneJ12_reward': [-853436772.6346331, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272], 'policy_light1_reward': [-5429670253.185883, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711]}","{'mean_env_wait_ms': 12.986049595980672, 'mean_processing_ms': 2.9382971070262807, 'mean_inference_ms': 1.8303111477492127}",{},0,212000,"{'sample_time_ms': 69549.12, 'sample_throughput': 57.513, 'learn_time_ms': 17819.071, 'learn_throughput': 224.479}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 46415855943680.0, 'policy_loss': -0.014477197080850601, 'vf_loss': 46415855943680.0, 'vf_explained_var': 2.6077032e-08, 'kl': 0.009484566689934582, 'entropy': 1.3006374798715115, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1597576927248384.0, 'policy_loss': -0.008473160676658154, 'vf_loss': 1597576927248384.0, 'vf_explained_var': -1.1175871e-07, 'kl': 0.016334681946318597, 'entropy': 0.18746608379296958, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 212000, 'num_steps_trained': 212000}",False,82,53,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-57-23,1615766243,82.60489702224731,4635.113922357559,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4635.113922357559,0,53,"{'cpu_util_percent': 30.09310344827586, 'ram_util_percent': 56.5}"
105,52,MARL,light1,-1586253625.9149873,-27133052971.985477,-7870438118.237324,2556.0731707317073,1,-17310839310.06847,-1314390163.1053514,-6415288306.198619,{},"{'episode_reward': [-6283107025.820504, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725], 'episode_lengths': [1968, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747], 'policy_gneJ12_reward': [-853436772.6346331, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272], 'policy_light1_reward': [-5429670253.185883, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711]}","{'mean_env_wait_ms': 12.986049595980672, 'mean_processing_ms': 2.9382971070262807, 'mean_inference_ms': 1.8303111477492127}",{},0,212000,"{'sample_time_ms': 69549.12, 'sample_throughput': 57.513, 'learn_time_ms': 17819.071, 'learn_throughput': 224.479}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 46415855943680.0, 'policy_loss': -0.014477197080850601, 'vf_loss': 46415855943680.0, 'vf_explained_var': 2.6077032e-08, 'kl': 0.009484566689934582, 'entropy': 1.3006374798715115, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1597576927248384.0, 'policy_loss': -0.008473160676658154, 'vf_loss': 1597576927248384.0, 'vf_explained_var': -1.1175871e-07, 'kl': 0.016334681946318597, 'entropy': 0.18746608379296958, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 212000, 'num_steps_trained': 212000}",False,82,53,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-57-23,1615766243,82.60489702224731,4635.113922357559,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4635.113922357559,0,53,"{'cpu_util_percent': 30.09310344827586, 'ram_util_percent': 56.5}"
106,53,MARL,gneJ12,-1586253625.9149873,-27133052971.985477,-7777405417.727104,2549.7261904761904,2,-9822213661.916977,-204317492.57638025,-1433327314.7924767,{},"{'episode_reward': [-3759207580.5069914, -4166921813.1091886, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504], 'episode_lengths': [2929, 1650, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968], 'policy_gneJ12_reward': [-426818414.7410234, -650391440.6533083, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331], 'policy_light1_reward': [-3332389165.7659717, -3516530372.4558854, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883]}","{'mean_env_wait_ms': 12.979398276695958, 'mean_processing_ms': 2.9411475799261058, 'mean_inference_ms': 1.8295917809024533}",{},0,216000,"{'sample_time_ms': 70186.207, 'sample_throughput': 56.991, 'learn_time_ms': 17872.004, 'learn_throughput': 223.814}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 81673331539968.0, 'policy_loss': -0.0071820810553617775, 'vf_loss': 81673331539968.0, 'vf_explained_var': -3.7252903e-08, 'kl': 0.011501715205668006, 'entropy': 1.5319390147924423, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2145080634769408.0, 'policy_loss': -0.005823748535476625, 'vf_loss': 2145080634769408.0, 'vf_explained_var': -3.7252903e-08, 'kl': 0.007896678653196432, 'entropy': 0.3615034772083163, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 216000, 'num_steps_trained': 216000}",False,84,54,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-58-59,1615766339,96.01129508018494,4731.125217437744,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4731.125217437744,0,54,"{'cpu_util_percent': 36.1089552238806, 'ram_util_percent': 56.75149253731343}"
107,53,MARL,light1,-1586253625.9149873,-27133052971.985477,-7777405417.727104,2549.7261904761904,2,-17310839310.06847,-1314390163.1053514,-6344078102.934626,{},"{'episode_reward': [-3759207580.5069914, -4166921813.1091886, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504], 'episode_lengths': [2929, 1650, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968], 'policy_gneJ12_reward': [-426818414.7410234, -650391440.6533083, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331], 'policy_light1_reward': [-3332389165.7659717, -3516530372.4558854, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883]}","{'mean_env_wait_ms': 12.979398276695958, 'mean_processing_ms': 2.9411475799261058, 'mean_inference_ms': 1.8295917809024533}",{},0,216000,"{'sample_time_ms': 70186.207, 'sample_throughput': 56.991, 'learn_time_ms': 17872.004, 'learn_throughput': 223.814}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 81673331539968.0, 'policy_loss': -0.0071820810553617775, 'vf_loss': 81673331539968.0, 'vf_explained_var': -3.7252903e-08, 'kl': 0.011501715205668006, 'entropy': 1.5319390147924423, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2145080634769408.0, 'policy_loss': -0.005823748535476625, 'vf_loss': 2145080634769408.0, 'vf_explained_var': -3.7252903e-08, 'kl': 0.007896678653196432, 'entropy': 0.3615034772083163, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 216000, 'num_steps_trained': 216000}",False,84,54,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_19-58-59,1615766339,96.01129508018494,4731.125217437744,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4731.125217437744,0,54,"{'cpu_util_percent': 36.1089552238806, 'ram_util_percent': 56.75149253731343}"
108,54,MARL,gneJ12,-1586253625.9149873,-27133052971.985477,-7771589834.719355,2549.7558139534885,2,-9822213661.916977,-204317492.57638025,-1423807666.8473446,{},"{'episode_reward': [-7537937064.694644, -7516733632.093279, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886], 'episode_lengths': [2392, 2710, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650], 'policy_gneJ12_reward': [-1050400689.8544695, -997564216.4491273, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083], 'policy_light1_reward': [-6487536374.840167, -6519169415.644166, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854]}","{'mean_env_wait_ms': 12.973302196903331, 'mean_processing_ms': 2.944149947753366, 'mean_inference_ms': 1.828994823305054}",{},0,220000,"{'sample_time_ms': 71333.519, 'sample_throughput': 56.075, 'learn_time_ms': 18036.623, 'learn_throughput': 221.771}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 78772516028416.0, 'policy_loss': -0.014874926244374365, 'vf_loss': 78772516028416.0, 'vf_explained_var': 1.8626451e-09, 'kl': 0.009470444536418654, 'entropy': 1.6842279694974422, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2552329081454592.0, 'policy_loss': -0.000803779941634275, 'vf_loss': 2552329081454592.0, 'vf_explained_var': -2.2351742e-08, 'kl': 0.014449271780904382, 'entropy': 0.38529304694384336, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 220000, 'num_steps_trained': 220000}",False,86,55,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-00-35,1615766435,95.5857081413269,4826.710925579071,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4826.710925579071,0,55,"{'cpu_util_percent': 36.55373134328359, 'ram_util_percent': 56.850746268656714}"
109,54,MARL,light1,-1586253625.9149873,-27133052971.985477,-7771589834.719355,2549.7558139534885,2,-17310839310.06847,-1314390163.1053514,-6347782167.87201,{},"{'episode_reward': [-7537937064.694644, -7516733632.093279, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886], 'episode_lengths': [2392, 2710, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650], 'policy_gneJ12_reward': [-1050400689.8544695, -997564216.4491273, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083], 'policy_light1_reward': [-6487536374.840167, -6519169415.644166, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854]}","{'mean_env_wait_ms': 12.973302196903331, 'mean_processing_ms': 2.944149947753366, 'mean_inference_ms': 1.828994823305054}",{},0,220000,"{'sample_time_ms': 71333.519, 'sample_throughput': 56.075, 'learn_time_ms': 18036.623, 'learn_throughput': 221.771}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 78772516028416.0, 'policy_loss': -0.014874926244374365, 'vf_loss': 78772516028416.0, 'vf_explained_var': 1.8626451e-09, 'kl': 0.009470444536418654, 'entropy': 1.6842279694974422, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2552329081454592.0, 'policy_loss': -0.000803779941634275, 'vf_loss': 2552329081454592.0, 'vf_explained_var': -2.2351742e-08, 'kl': 0.014449271780904382, 'entropy': 0.38529304694384336, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 220000, 'num_steps_trained': 220000}",False,86,55,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-00-35,1615766435,95.5857081413269,4826.710925579071,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4826.710925579071,0,55,"{'cpu_util_percent': 36.55373134328359, 'ram_util_percent': 56.850746268656714}"
110,55,MARL,gneJ12,-1586253625.9149873,-27133052971.985477,-7785188035.118269,2553.183908045977,1,-9822213661.916977,-204317492.57638025,-1421466470.1406345,{},"{'episode_reward': [-8954633269.42481, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279], 'episode_lengths': [2848, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710], 'policy_gneJ12_reward': [-1220123553.3635688, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273], 'policy_light1_reward': [-7734509716.061251, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166]}","{'mean_env_wait_ms': 12.970514141560438, 'mean_processing_ms': 2.945385025305575, 'mean_inference_ms': 1.828732547457831}",{},0,224000,"{'sample_time_ms': 71212.67, 'sample_throughput': 56.17, 'learn_time_ms': 18153.54, 'learn_throughput': 220.343}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 92870423085056.0, 'policy_loss': -0.014784442610107362, 'vf_loss': 92870423085056.0, 'vf_explained_var': 3.9115548e-08, 'kl': 0.010581450143945403, 'entropy': 2.1331811510026455, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2846664125579264.0, 'policy_loss': 0.0009110990504268557, 'vf_loss': 2846664125579264.0, 'vf_explained_var': -3.7252903e-09, 'kl': 0.010107465830515139, 'entropy': 0.536009949631989, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 224000, 'num_steps_trained': 224000}",False,87,56,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-02-03,1615766523,88.47267603874207,4915.183601617813,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4915.183601617813,0,56,"{'cpu_util_percent': 35.1032, 'ram_util_percent': 57.308}"
111,55,MARL,light1,-1586253625.9149873,-27133052971.985477,-7785188035.118269,2553.183908045977,1,-17310839310.06847,-1314390163.1053514,-6363721564.977634,{},"{'episode_reward': [-8954633269.42481, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279], 'episode_lengths': [2848, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710], 'policy_gneJ12_reward': [-1220123553.3635688, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273], 'policy_light1_reward': [-7734509716.061251, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166]}","{'mean_env_wait_ms': 12.970514141560438, 'mean_processing_ms': 2.945385025305575, 'mean_inference_ms': 1.828732547457831}",{},0,224000,"{'sample_time_ms': 71212.67, 'sample_throughput': 56.17, 'learn_time_ms': 18153.54, 'learn_throughput': 220.343}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 92870423085056.0, 'policy_loss': -0.014784442610107362, 'vf_loss': 92870423085056.0, 'vf_explained_var': 3.9115548e-08, 'kl': 0.010581450143945403, 'entropy': 2.1331811510026455, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2846664125579264.0, 'policy_loss': 0.0009110990504268557, 'vf_loss': 2846664125579264.0, 'vf_explained_var': -3.7252903e-09, 'kl': 0.010107465830515139, 'entropy': 0.536009949631989, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 224000, 'num_steps_trained': 224000}",False,87,56,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-02-03,1615766523,88.47267603874207,4915.183601617813,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4915.183601617813,0,56,"{'cpu_util_percent': 35.1032, 'ram_util_percent': 57.308}"
112,56,MARL,gneJ12,-1586253625.9149873,-27133052971.985477,-7773291030.747317,2553.3146067415732,2,-9822213661.916977,-204317492.57638025,-1412289667.6054244,{},"{'episode_reward': [-7496738079.259743, -7014804601.962027, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481], 'episode_lengths': [2634, 2484, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848], 'policy_gneJ12_reward': [-1138331653.7878678, -887865860.8596783, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688], 'policy_light1_reward': [-6358406425.47188, -6126938741.10234, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251]}","{'mean_env_wait_ms': 12.965294753016844, 'mean_processing_ms': 2.9481702981476037, 'mean_inference_ms': 1.8282761551155937}",{},0,228000,"{'sample_time_ms': 71597.382, 'sample_throughput': 55.868, 'learn_time_ms': 18179.172, 'learn_throughput': 220.032}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 69864496955392.0, 'policy_loss': -0.009872197755612433, 'vf_loss': 69864496955392.0, 'vf_explained_var': 4.8428774e-08, 'kl': 0.0076596305589191616, 'entropy': 1.5711331143975258, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2065000944369664.0, 'policy_loss': -0.00905094260815531, 'vf_loss': 2065000944369664.0, 'vf_explained_var': 5.2154064e-08, 'kl': 0.012328577737207524, 'entropy': 0.2940159998834133, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 228000, 'num_steps_trained': 228000}",False,89,57,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-03-38,1615766618,94.80833601951599,5009.991937637329,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5009.991937637329,0,57,"{'cpu_util_percent': 32.96616541353384, 'ram_util_percent': 57.187218045112786}"
113,56,MARL,light1,-1586253625.9149873,-27133052971.985477,-7773291030.747317,2553.3146067415732,2,-17310839310.06847,-1314390163.1053514,-6361001363.141892,{},"{'episode_reward': [-7496738079.259743, -7014804601.962027, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481], 'episode_lengths': [2634, 2484, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848], 'policy_gneJ12_reward': [-1138331653.7878678, -887865860.8596783, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688], 'policy_light1_reward': [-6358406425.47188, -6126938741.10234, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251]}","{'mean_env_wait_ms': 12.965294753016844, 'mean_processing_ms': 2.9481702981476037, 'mean_inference_ms': 1.8282761551155937}",{},0,228000,"{'sample_time_ms': 71597.382, 'sample_throughput': 55.868, 'learn_time_ms': 18179.172, 'learn_throughput': 220.032}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 69864496955392.0, 'policy_loss': -0.009872197755612433, 'vf_loss': 69864496955392.0, 'vf_explained_var': 4.8428774e-08, 'kl': 0.0076596305589191616, 'entropy': 1.5711331143975258, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2065000944369664.0, 'policy_loss': -0.00905094260815531, 'vf_loss': 2065000944369664.0, 'vf_explained_var': 5.2154064e-08, 'kl': 0.012328577737207524, 'entropy': 0.2940159998834133, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 228000, 'num_steps_trained': 228000}",False,89,57,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-03-38,1615766618,94.80833601951599,5009.991937637329,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5009.991937637329,0,57,"{'cpu_util_percent': 32.96616541353384, 'ram_util_percent': 57.187218045112786}"
114,57,MARL,gneJ12,-1586253625.9149873,-27133052971.985477,-7727422394.812731,2557.4555555555557,1,-9822213661.916977,-204317492.57638025,-1401675533.1213822,{},"{'episode_reward': [-3645113796.6344423, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027], 'episode_lengths': [2926, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484], 'policy_gneJ12_reward': [-457017564.04163146, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783], 'policy_light1_reward': [-3188096232.5928054, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234]}","{'mean_env_wait_ms': 12.962809221294366, 'mean_processing_ms': 2.949323410863489, 'mean_inference_ms': 1.8280544119927873}",{},0,232000,"{'sample_time_ms': 71850.502, 'sample_throughput': 55.671, 'learn_time_ms': 18194.854, 'learn_throughput': 219.842}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 616001958838272.0, 'policy_loss': -0.005299765034578741, 'vf_loss': 616001958838272.0, 'vf_explained_var': -2.9802322e-08, 'kl': 0.012940196378622204, 'entropy': 1.813405405730009, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1479037700538368.0, 'policy_loss': -0.002038787992205471, 'vf_loss': 1479037700538368.0, 'vf_explained_var': 5.401671e-08, 'kl': 0.012664607682381757, 'entropy': 0.2189109066966921, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 232000, 'num_steps_trained': 232000}",False,90,58,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-05-03,1615766703,85.25799202919006,5095.249929666519,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5095.249929666519,0,58,"{'cpu_util_percent': 29.169999999999998, 'ram_util_percent': 57.0}"
115,57,MARL,light1,-1586253625.9149873,-27133052971.985477,-7727422394.812731,2557.4555555555557,1,-17310839310.06847,-1314390163.1053514,-6325746861.691346,{},"{'episode_reward': [-3645113796.6344423, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027], 'episode_lengths': [2926, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484], 'policy_gneJ12_reward': [-457017564.04163146, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783], 'policy_light1_reward': [-3188096232.5928054, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234]}","{'mean_env_wait_ms': 12.962809221294366, 'mean_processing_ms': 2.949323410863489, 'mean_inference_ms': 1.8280544119927873}",{},0,232000,"{'sample_time_ms': 71850.502, 'sample_throughput': 55.671, 'learn_time_ms': 18194.854, 'learn_throughput': 219.842}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 616001958838272.0, 'policy_loss': -0.005299765034578741, 'vf_loss': 616001958838272.0, 'vf_explained_var': -2.9802322e-08, 'kl': 0.012940196378622204, 'entropy': 1.813405405730009, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1479037700538368.0, 'policy_loss': -0.002038787992205471, 'vf_loss': 1479037700538368.0, 'vf_explained_var': 5.401671e-08, 'kl': 0.012664607682381757, 'entropy': 0.2189109066966921, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 232000, 'num_steps_trained': 232000}",False,90,58,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-05-03,1615766703,85.25799202919006,5095.249929666519,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5095.249929666519,0,58,"{'cpu_util_percent': 29.169999999999998, 'ram_util_percent': 57.0}"
116,58,MARL,gneJ12,-1586253625.9149873,-27133052971.985477,-7722154575.411052,2553.1847826086955,2,-9822213661.916977,-204317492.57638025,-1412284670.118009,{},"{'episode_reward': [-8199786561.658592, -6770418843.012492, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423], 'episode_lengths': [2377, 2345, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926], 'policy_gneJ12_reward': [-2845581758.95066, -933809910.981775, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146], 'policy_light1_reward': [-5354204802.707914, -5836608932.030722, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054]}","{'mean_env_wait_ms': 12.957900690290696, 'mean_processing_ms': 2.9518419342917417, 'mean_inference_ms': 1.8276101819186998}",{},0,236000,"{'sample_time_ms': 71336.91, 'sample_throughput': 56.072, 'learn_time_ms': 18208.269, 'learn_throughput': 219.68}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 52754750767104.0, 'policy_loss': -0.011224371526623145, 'vf_loss': 52754750767104.0, 'vf_explained_var': -7.4505806e-08, 'kl': 0.010207246770733036, 'entropy': 1.4181246720254421, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1682895162834944.0, 'policy_loss': -0.013996064095408656, 'vf_loss': 1682895162834944.0, 'vf_explained_var': -5.9604645e-08, 'kl': 0.010616612853482366, 'entropy': 0.11866984108928591, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 236000, 'num_steps_trained': 236000}",False,92,59,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-06-34,1615766794,90.02810621261597,5185.278035879135,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5185.278035879135,0,59,"{'cpu_util_percent': 27.772222222222222, 'ram_util_percent': 57.0}"
117,58,MARL,light1,-1586253625.9149873,-27133052971.985477,-7722154575.411052,2553.1847826086955,2,-17310839310.06847,-1314390163.1053514,-6309869905.29304,{},"{'episode_reward': [-8199786561.658592, -6770418843.012492, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423], 'episode_lengths': [2377, 2345, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926], 'policy_gneJ12_reward': [-2845581758.95066, -933809910.981775, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146], 'policy_light1_reward': [-5354204802.707914, -5836608932.030722, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054]}","{'mean_env_wait_ms': 12.957900690290696, 'mean_processing_ms': 2.9518419342917417, 'mean_inference_ms': 1.8276101819186998}",{},0,236000,"{'sample_time_ms': 71336.91, 'sample_throughput': 56.072, 'learn_time_ms': 18208.269, 'learn_throughput': 219.68}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 52754750767104.0, 'policy_loss': -0.011224371526623145, 'vf_loss': 52754750767104.0, 'vf_explained_var': -7.4505806e-08, 'kl': 0.010207246770733036, 'entropy': 1.4181246720254421, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1682895162834944.0, 'policy_loss': -0.013996064095408656, 'vf_loss': 1682895162834944.0, 'vf_explained_var': -5.9604645e-08, 'kl': 0.010616612853482366, 'entropy': 0.11866984108928591, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 236000, 'num_steps_trained': 236000}",False,92,59,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-06-34,1615766794,90.02810621261597,5185.278035879135,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5185.278035879135,0,59,"{'cpu_util_percent': 27.772222222222222, 'ram_util_percent': 57.0}"
118,59,MARL,gneJ12,-1315300483.4458,-27133052971.985477,-7653263671.19637,2554.7096774193546,1,-9822213661.916977,-204317492.57638025,-1399450340.9313388,{},"{'episode_reward': [-1315300483.4458, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492], 'episode_lengths': [2695, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345], 'policy_gneJ12_reward': [-218692055.75766248, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775], 'policy_light1_reward': [-1096608427.68814, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722]}","{'mean_env_wait_ms': 12.955610758644804, 'mean_processing_ms': 2.952860999740225, 'mean_inference_ms': 1.8273953977677608}",{},0,240000,"{'sample_time_ms': 71697.139, 'sample_throughput': 55.79, 'learn_time_ms': 18229.475, 'learn_throughput': 219.425}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 4319733662875648.0, 'policy_loss': -0.0022728410258423537, 'vf_loss': 4319733662875648.0, 'vf_explained_var': -7.8231096e-08, 'kl': 0.009628058774978854, 'entropy': 2.0790260955691338, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 4561615626174464.0, 'policy_loss': -0.0055977507727220654, 'vf_loss': 4561615626174464.0, 'vf_explained_var': -3.7252903e-08, 'kl': 0.01010619704175042, 'entropy': 0.12513360928278416, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 240000, 'num_steps_trained': 240000}",False,93,60,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-07-59,1615766879,85.7732880115509,5271.051323890686,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5271.051323890686,0,60,"{'cpu_util_percent': 30.3396694214876, 'ram_util_percent': 57.0}"
119,59,MARL,light1,-1315300483.4458,-27133052971.985477,-7653263671.19637,2554.7096774193546,1,-17310839310.06847,-1096608427.68814,-6253813330.265031,{},"{'episode_reward': [-1315300483.4458, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492], 'episode_lengths': [2695, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345], 'policy_gneJ12_reward': [-218692055.75766248, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775], 'policy_light1_reward': [-1096608427.68814, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722]}","{'mean_env_wait_ms': 12.955610758644804, 'mean_processing_ms': 2.952860999740225, 'mean_inference_ms': 1.8273953977677608}",{},0,240000,"{'sample_time_ms': 71697.139, 'sample_throughput': 55.79, 'learn_time_ms': 18229.475, 'learn_throughput': 219.425}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 4319733662875648.0, 'policy_loss': -0.0022728410258423537, 'vf_loss': 4319733662875648.0, 'vf_explained_var': -7.8231096e-08, 'kl': 0.009628058774978854, 'entropy': 2.0790260955691338, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 4561615626174464.0, 'policy_loss': -0.0055977507727220654, 'vf_loss': 4561615626174464.0, 'vf_explained_var': -3.7252903e-08, 'kl': 0.01010619704175042, 'entropy': 0.12513360928278416, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 240000, 'num_steps_trained': 240000}",False,93,60,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-07-59,1615766879,85.7732880115509,5271.051323890686,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5271.051323890686,0,60,"{'cpu_util_percent': 30.3396694214876, 'ram_util_percent': 57.0}"
120,60,MARL,gneJ12,-1315300483.4458,-27133052971.985477,-7737384957.926376,2556.6105263157897,2,-9822213661.916977,-204317492.57638025,-1457215896.4040434,{},"{'episode_reward': [-17386949670.798218, -5911099910.9450655, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458], 'episode_lengths': [2962, 2328, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695], 'policy_gneJ12_reward': [-7498444298.009825, -788184153.7598045, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248], 'policy_light1_reward': [-9888505372.788342, -5122915757.185251, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814]}","{'mean_env_wait_ms': 12.95131383504797, 'mean_processing_ms': 2.955158166055483, 'mean_inference_ms': 1.8270246732015523}",{},0,244000,"{'sample_time_ms': 72143.632, 'sample_throughput': 55.445, 'learn_time_ms': 18274.719, 'learn_throughput': 218.882}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 65755814821888.0, 'policy_loss': -0.009647929211496376, 'vf_loss': 65755814821888.0, 'vf_explained_var': -3.7252903e-08, 'kl': 0.009379464216181077, 'entropy': 1.6099479235708714, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2175580665544704.0, 'policy_loss': 0.005450162338092923, 'vf_loss': 2175580665544704.0, 'vf_explained_var': 6.146729e-08, 'kl': 0.016784633808129, 'entropy': 0.23621217627078295, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 244000, 'num_steps_trained': 244000}",False,95,61,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-09-34,1615766974,94.99838709831238,5366.049710988998,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5366.049710988998,0,61,"{'cpu_util_percent': 34.581203007518795, 'ram_util_percent': 57.35639097744361}"
121,60,MARL,light1,-1315300483.4458,-27133052971.985477,-7737384957.926376,2556.6105263157897,2,-17310839310.06847,-1096608427.68814,-6280169061.522331,{},"{'episode_reward': [-17386949670.798218, -5911099910.9450655, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458], 'episode_lengths': [2962, 2328, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695], 'policy_gneJ12_reward': [-7498444298.009825, -788184153.7598045, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248], 'policy_light1_reward': [-9888505372.788342, -5122915757.185251, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814]}","{'mean_env_wait_ms': 12.95131383504797, 'mean_processing_ms': 2.955158166055483, 'mean_inference_ms': 1.8270246732015523}",{},0,244000,"{'sample_time_ms': 72143.632, 'sample_throughput': 55.445, 'learn_time_ms': 18274.719, 'learn_throughput': 218.882}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 65755814821888.0, 'policy_loss': -0.009647929211496376, 'vf_loss': 65755814821888.0, 'vf_explained_var': -3.7252903e-08, 'kl': 0.009379464216181077, 'entropy': 1.6099479235708714, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2175580665544704.0, 'policy_loss': 0.005450162338092923, 'vf_loss': 2175580665544704.0, 'vf_explained_var': 6.146729e-08, 'kl': 0.016784633808129, 'entropy': 0.23621217627078295, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 244000, 'num_steps_trained': 244000}",False,95,61,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-09-34,1615766974,94.99838709831238,5366.049710988998,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5366.049710988998,0,61,"{'cpu_util_percent': 34.581203007518795, 'ram_util_percent': 57.35639097744361}"
122,61,MARL,gneJ12,-1315300483.4458,-27133052971.985477,-7674686617.175138,2548.175257731959,2,-9822213661.916977,-204317492.57638025,-1439121402.7527552,{},"{'episode_reward': [-6616411430.031185, -2776619432.951309, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655], 'episode_lengths': [2115, 2180, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328], 'policy_gneJ12_reward': [-796605630.7223681, -362660277.91076684, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045], 'policy_light1_reward': [-5819805799.308826, -2413959155.040544, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251]}","{'mean_env_wait_ms': 12.947383251799106, 'mean_processing_ms': 2.9577387122926297, 'mean_inference_ms': 1.8267631023146724}",{},0,248000,"{'sample_time_ms': 72739.38, 'sample_throughput': 54.991, 'learn_time_ms': 18379.706, 'learn_throughput': 217.631}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 45928313323520.0, 'policy_loss': -0.010947663657134399, 'vf_loss': 45928313323520.0, 'vf_explained_var': 7.264316e-08, 'kl': 0.013702760974410921, 'entropy': 1.5428832806646824, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1812011952373760.0, 'policy_loss': -0.0031264539575204253, 'vf_loss': 1812011952373760.0, 'vf_explained_var': 1.1920929e-07, 'kl': 0.013359465709072538, 'entropy': -0.04908363650611136, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 248000, 'num_steps_trained': 248000}",False,97,62,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-11-12,1615767072,97.65500497817993,5463.704715967178,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5463.704715967178,0,62,"{'cpu_util_percent': 35.34233576642335, 'ram_util_percent': 57.329927007299275}"
123,61,MARL,light1,-1315300483.4458,-27133052971.985477,-7674686617.175138,2548.175257731959,2,-17310839310.06847,-1096608427.68814,-6235565214.42238,{},"{'episode_reward': [-6616411430.031185, -2776619432.951309, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655], 'episode_lengths': [2115, 2180, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328], 'policy_gneJ12_reward': [-796605630.7223681, -362660277.91076684, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045], 'policy_light1_reward': [-5819805799.308826, -2413959155.040544, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251]}","{'mean_env_wait_ms': 12.947383251799106, 'mean_processing_ms': 2.9577387122926297, 'mean_inference_ms': 1.8267631023146724}",{},0,248000,"{'sample_time_ms': 72739.38, 'sample_throughput': 54.991, 'learn_time_ms': 18379.706, 'learn_throughput': 217.631}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 45928313323520.0, 'policy_loss': -0.010947663657134399, 'vf_loss': 45928313323520.0, 'vf_explained_var': 7.264316e-08, 'kl': 0.013702760974410921, 'entropy': 1.5428832806646824, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1812011952373760.0, 'policy_loss': -0.0031264539575204253, 'vf_loss': 1812011952373760.0, 'vf_explained_var': 1.1920929e-07, 'kl': 0.013359465709072538, 'entropy': -0.04908363650611136, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 248000, 'num_steps_trained': 248000}",False,97,62,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-11-12,1615767072,97.65500497817993,5463.704715967178,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5463.704715967178,0,62,"{'cpu_util_percent': 35.34233576642335, 'ram_util_percent': 57.329927007299275}"
124,62,MARL,gneJ12,-1315300483.4458,-27133052971.985477,-7643492936.849879,2542.040404040404,2,-9822213661.916977,-204317492.57638025,-1428215501.859833,{},"{'episode_reward': [-7035516897.90606, -5225681984.243652, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309], 'episode_lengths': [2134, 2355, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180], 'policy_gneJ12_reward': [-1094731979.6965852, -703826637.4096254, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684], 'policy_light1_reward': [-5940784918.209476, -4521855346.83403, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544]}","{'mean_env_wait_ms': 12.944312083858842, 'mean_processing_ms': 2.9604975323789615, 'mean_inference_ms': 1.826658545338811}",{},0,252000,"{'sample_time_ms': 74733.394, 'sample_throughput': 53.524, 'learn_time_ms': 18669.367, 'learn_throughput': 214.255}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 85530987200512.0, 'policy_loss': -0.010152523522265255, 'vf_loss': 85530987200512.0, 'vf_explained_var': 3.1664968e-08, 'kl': 0.011990433675237, 'entropy': 1.8894934058189392, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1906828451512320.0, 'policy_loss': 0.005017294024582952, 'vf_loss': 1906828451512320.0, 'vf_explained_var': -9.313226e-08, 'kl': 0.014967613751650788, 'entropy': 0.12757393572246656, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 252000, 'num_steps_trained': 252000}",False,99,63,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-12-58,1615767178,105.441330909729,5569.146046876907,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5569.146046876907,0,63,"{'cpu_util_percent': 45.39115646258504, 'ram_util_percent': 57.4}"
125,62,MARL,light1,-1315300483.4458,-27133052971.985477,-7643492936.849879,2542.040404040404,2,-17310839310.06847,-1096608427.68814,-6215277434.990045,{},"{'episode_reward': [-7035516897.90606, -5225681984.243652, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309], 'episode_lengths': [2134, 2355, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180], 'policy_gneJ12_reward': [-1094731979.6965852, -703826637.4096254, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684], 'policy_light1_reward': [-5940784918.209476, -4521855346.83403, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544]}","{'mean_env_wait_ms': 12.944312083858842, 'mean_processing_ms': 2.9604975323789615, 'mean_inference_ms': 1.826658545338811}",{},0,252000,"{'sample_time_ms': 74733.394, 'sample_throughput': 53.524, 'learn_time_ms': 18669.367, 'learn_throughput': 214.255}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 85530987200512.0, 'policy_loss': -0.010152523522265255, 'vf_loss': 85530987200512.0, 'vf_explained_var': 3.1664968e-08, 'kl': 0.011990433675237, 'entropy': 1.8894934058189392, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1906828451512320.0, 'policy_loss': 0.005017294024582952, 'vf_loss': 1906828451512320.0, 'vf_explained_var': -9.313226e-08, 'kl': 0.014967613751650788, 'entropy': 0.12757393572246656, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 252000, 'num_steps_trained': 252000}",False,99,63,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-12-58,1615767178,105.441330909729,5569.146046876907,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5569.146046876907,0,63,"{'cpu_util_percent': 45.39115646258504, 'ram_util_percent': 57.4}"
126,63,MARL,gneJ12,-1315300483.4458,-27133052971.985477,-7627065495.5465355,2545.34,1,-9822213661.916977,-204317492.57638025,-1420764378.998838,{},"{'episode_reward': [-6000748806.515728, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652], 'episode_lengths': [2872, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355], 'policy_gneJ12_reward': [-683103215.7603076, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254], 'policy_light1_reward': [-5317645590.755413, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403]}","{'mean_env_wait_ms': 12.94294331022688, 'mean_processing_ms': 2.961708619909835, 'mean_inference_ms': 1.8266441683368735}",{},0,256000,"{'sample_time_ms': 74121.743, 'sample_throughput': 53.965, 'learn_time_ms': 18715.749, 'learn_throughput': 213.724}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 51349743861760.0, 'policy_loss': -0.016295977809932083, 'vf_loss': 51349743861760.0, 'vf_explained_var': 5.5879354e-09, 'kl': 0.011088399944128469, 'entropy': 1.6381709203124046, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1920390909657088.0, 'policy_loss': 0.0003433814272284508, 'vf_loss': 1920390909657088.0, 'vf_explained_var': -7.8231096e-08, 'kl': 0.02144225497613661, 'entropy': -0.025793103268370032, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 256000, 'num_steps_trained': 256000}",False,100,64,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-14-28,1615767268,90.35974383354187,5659.505790710449,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5659.505790710449,0,64,"{'cpu_util_percent': 38.49370078740158, 'ram_util_percent': 53.89763779527558}"
127,63,MARL,light1,-1315300483.4458,-27133052971.985477,-7627065495.5465355,2545.34,1,-17310839310.06847,-1096608427.68814,-6206301116.547698,{},"{'episode_reward': [-6000748806.515728, -13116058146.125181, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652], 'episode_lengths': [2872, 3093, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355], 'policy_gneJ12_reward': [-683103215.7603076, -3968399839.5715966, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254], 'policy_light1_reward': [-5317645590.755413, -9147658306.553596, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403]}","{'mean_env_wait_ms': 12.94294331022688, 'mean_processing_ms': 2.961708619909835, 'mean_inference_ms': 1.8266441683368735}",{},0,256000,"{'sample_time_ms': 74121.743, 'sample_throughput': 53.965, 'learn_time_ms': 18715.749, 'learn_throughput': 213.724}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 51349743861760.0, 'policy_loss': -0.016295977809932083, 'vf_loss': 51349743861760.0, 'vf_explained_var': 5.5879354e-09, 'kl': 0.011088399944128469, 'entropy': 1.6381709203124046, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1920390909657088.0, 'policy_loss': 0.0003433814272284508, 'vf_loss': 1920390909657088.0, 'vf_explained_var': -7.8231096e-08, 'kl': 0.02144225497613661, 'entropy': -0.025793103268370032, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 256000, 'num_steps_trained': 256000}",False,100,64,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-14-28,1615767268,90.35974383354187,5659.505790710449,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5659.505790710449,0,64,"{'cpu_util_percent': 38.49370078740158, 'ram_util_percent': 53.89763779527558}"
128,64,MARL,gneJ12,-1315300483.4458,-27133052971.985477,-7574589460.07729,2541.65,1,-9822213661.916977,-204317492.57638025,-1391843881.2037158,{},"{'episode_reward': [-7868454599.200462, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728], 'episode_lengths': [2724, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872], 'policy_gneJ12_reward': [-1076350060.0593877, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076], 'policy_light1_reward': [-6792104539.14109, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413]}","{'mean_env_wait_ms': 12.93262279425356, 'mean_processing_ms': 2.972613068327246, 'mean_inference_ms': 1.8273238725949437}",{},0,260000,"{'sample_time_ms': 73444.628, 'sample_throughput': 54.463, 'learn_time_ms': 18714.633, 'learn_throughput': 213.736}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 42510086242304.0, 'policy_loss': -0.004092851158929989, 'vf_loss': 42510086242304.0, 'vf_explained_var': -3.7252903e-08, 'kl': 0.01050568553910125, 'entropy': 1.4497989602386951, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 1398045816127488.0, 'policy_loss': 0.001045237440848723, 'vf_loss': 1398045816127488.0, 'vf_explained_var': -1.0058284e-07, 'kl': 0.009591279027517885, 'entropy': -0.15858693339396268, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 260000, 'num_steps_trained': 260000}",False,101,65,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-15-57,1615767357,88.80440902709961,5748.310199737549,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5748.310199737549,0,65,"{'cpu_util_percent': 37.671200000000006, 'ram_util_percent': 54.388799999999996}"
129,64,MARL,light1,-1315300483.4458,-27133052971.985477,-7574589460.07729,2541.65,1,-17310839310.06847,-1096608427.68814,-6182745578.873571,{},"{'episode_reward': [-7868454599.200462, -7573132672.541883, -27133052971.985477, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728], 'episode_lengths': [2724, 2299, 2694, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872], 'policy_gneJ12_reward': [-1076350060.0593877, -1556936693.5085864, -9822213661.916977, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076], 'policy_light1_reward': [-6792104539.14109, -6016195979.033288, -17310839310.06847, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413]}","{'mean_env_wait_ms': 12.93262279425356, 'mean_processing_ms': 2.972613068327246, 'mean_inference_ms': 1.8273238725949437}",{},0,260000,"{'sample_time_ms': 73444.628, 'sample_throughput': 54.463, 'learn_time_ms': 18714.633, 'learn_throughput': 213.736}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 42510086242304.0, 'policy_loss': -0.004092851158929989, 'vf_loss': 42510086242304.0, 'vf_explained_var': -3.7252903e-08, 'kl': 0.01050568553910125, 'entropy': 1.4497989602386951, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 1398045816127488.0, 'policy_loss': 0.001045237440848723, 'vf_loss': 1398045816127488.0, 'vf_explained_var': -1.0058284e-07, 'kl': 0.009591279027517885, 'entropy': -0.15858693339396268, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 260000, 'num_steps_trained': 260000}",False,101,65,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-15-57,1615767357,88.80440902709961,5748.310199737549,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5748.310199737549,0,65,"{'cpu_util_percent': 37.671200000000006, 'ram_util_percent': 54.388799999999996}"
130,65,MARL,gneJ12,-1315300483.4458,-21980053370.627327,-7353614699.476445,2548.62,2,-8425206753.36029,-204317492.57638025,-1295113678.437338,{},"{'episode_reward': [-4427252985.2439, -8181456599.1989, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462], 'episode_lengths': [2988, 2702, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724], 'policy_gneJ12_reward': [-570990274.7485429, -1135139804.0392752, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877], 'policy_light1_reward': [-3856262710.4953446, -7046316795.159605, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109]}","{'mean_env_wait_ms': 12.91053522109536, 'mean_processing_ms': 2.989064532245875, 'mean_inference_ms': 1.8260574273295211}",{},0,264000,"{'sample_time_ms': 74641.384, 'sample_throughput': 53.59, 'learn_time_ms': 18720.725, 'learn_throughput': 213.667}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 95945903308800.0, 'policy_loss': -0.01235042605549097, 'vf_loss': 95945903308800.0, 'vf_explained_var': -3.1664968e-08, 'kl': 0.015255096572218463, 'entropy': 2.047810662537813, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 2382635426906112.0, 'policy_loss': -0.009674649336375296, 'vf_loss': 2382635426906112.0, 'vf_explained_var': -3.7252903e-09, 'kl': 0.011302904240437783, 'entropy': 0.15536582376807928, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 264000, 'num_steps_trained': 264000}",False,103,66,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-17-37,1615767457,100.50140595436096,5848.81160569191,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5848.81160569191,0,66,"{'cpu_util_percent': 36.18226950354609, 'ram_util_percent': 54.46382978723404}"
131,65,MARL,light1,-1315300483.4458,-21980053370.627327,-7353614699.476445,2548.62,2,-13580054488.403181,-1096608427.68814,-6058501021.039104,{},"{'episode_reward': [-4427252985.2439, -8181456599.1989, -16539470753.84684, -13186894856.55263, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462], 'episode_lengths': [2988, 2702, 3183, 3067, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724], 'policy_gneJ12_reward': [-570990274.7485429, -1135139804.0392752, -2959416265.443628, -2398622218.9258766, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877], 'policy_light1_reward': [-3856262710.4953446, -7046316795.159605, -13580054488.403181, -10788272637.626764, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109]}","{'mean_env_wait_ms': 12.91053522109536, 'mean_processing_ms': 2.989064532245875, 'mean_inference_ms': 1.8260574273295211}",{},0,264000,"{'sample_time_ms': 74641.384, 'sample_throughput': 53.59, 'learn_time_ms': 18720.725, 'learn_throughput': 213.667}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 95945903308800.0, 'policy_loss': -0.01235042605549097, 'vf_loss': 95945903308800.0, 'vf_explained_var': -3.1664968e-08, 'kl': 0.015255096572218463, 'entropy': 2.047810662537813, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 2382635426906112.0, 'policy_loss': -0.009674649336375296, 'vf_loss': 2382635426906112.0, 'vf_explained_var': -3.7252903e-09, 'kl': 0.011302904240437783, 'entropy': 0.15536582376807928, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 264000, 'num_steps_trained': 264000}",False,103,66,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-17-37,1615767457,100.50140595436096,5848.81160569191,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5848.81160569191,0,66,"{'cpu_util_percent': 36.18226950354609, 'ram_util_percent': 54.46382978723404}"
132,66,MARL,gneJ12,-1315300483.4458,-21980053370.627327,-7191499984.9435005,2532.05,2,-8425206753.36029,-204317492.57638025,-1260417849.9423292,{},"{'episode_reward': [-7574828048.050996, -5940066109.053961, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989], 'episode_lengths': [2679, 1914, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702], 'policy_gneJ12_reward': [-1112862332.4575703, -775593302.4110138, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752], 'policy_light1_reward': [-6461965715.593427, -5164472806.642955, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605]}","{'mean_env_wait_ms': 12.890359127212623, 'mean_processing_ms': 3.001244474033361, 'mean_inference_ms': 1.8245046613071207}",{},0,268000,"{'sample_time_ms': 74432.163, 'sample_throughput': 53.74, 'learn_time_ms': 18837.668, 'learn_throughput': 212.341}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 79770949779456.0, 'policy_loss': -0.013078240619506687, 'vf_loss': 79770949779456.0, 'vf_explained_var': -2.2351742e-08, 'kl': 0.00948586624872405, 'entropy': 1.9555719271302223, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 2403557517033472.0, 'policy_loss': -0.00951099256053567, 'vf_loss': 2403557517033472.0, 'vf_explained_var': -1.4901161e-08, 'kl': 0.009564612118992954, 'entropy': 0.12816134869353846, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 268000, 'num_steps_trained': 268000}",False,105,67,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-19-11,1615767551,93.88543391227722,5942.697039604187,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5942.697039604187,0,67,"{'cpu_util_percent': 30.867938931297708, 'ram_util_percent': 54.48167938931298}"
133,66,MARL,light1,-1315300483.4458,-21980053370.627327,-7191499984.9435005,2532.05,2,-13554846617.26706,-1096608427.68814,-5931082135.001168,{},"{'episode_reward': [-7574828048.050996, -5940066109.053961, -15953140273.844273, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989], 'episode_lengths': [2679, 1914, 2493, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702], 'policy_gneJ12_reward': [-1112862332.4575703, -775593302.4110138, -3516172434.210055, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752], 'policy_light1_reward': [-6461965715.593427, -5164472806.642955, -12436967839.634207, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605]}","{'mean_env_wait_ms': 12.890359127212623, 'mean_processing_ms': 3.001244474033361, 'mean_inference_ms': 1.8245046613071207}",{},0,268000,"{'sample_time_ms': 74432.163, 'sample_throughput': 53.74, 'learn_time_ms': 18837.668, 'learn_throughput': 212.341}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 79770949779456.0, 'policy_loss': -0.013078240619506687, 'vf_loss': 79770949779456.0, 'vf_explained_var': -2.2351742e-08, 'kl': 0.00948586624872405, 'entropy': 1.9555719271302223, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 2403557517033472.0, 'policy_loss': -0.00951099256053567, 'vf_loss': 2403557517033472.0, 'vf_explained_var': -1.4901161e-08, 'kl': 0.009564612118992954, 'entropy': 0.12816134869353846, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 268000, 'num_steps_trained': 268000}",False,105,67,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-19-11,1615767551,93.88543391227722,5942.697039604187,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5942.697039604187,0,67,"{'cpu_util_percent': 30.867938931297708, 'ram_util_percent': 54.48167938931298}"
134,67,MARL,gneJ12,-1315300483.4458,-21980053370.627327,-7059003930.294999,2529.87,1,-8425206753.36029,-204317492.57638025,-1228752494.3680391,{},"{'episode_reward': [-2703534808.9941096, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961], 'episode_lengths': [2275, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914], 'policy_gneJ12_reward': [-349636876.7810691, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138], 'policy_light1_reward': [-2353897932.213037, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955]}","{'mean_env_wait_ms': 12.884320238152082, 'mean_processing_ms': 3.0040736556382193, 'mean_inference_ms': 1.8241144854235538}",{},0,272000,"{'sample_time_ms': 74710.913, 'sample_throughput': 53.54, 'learn_time_ms': 19034.184, 'learn_throughput': 210.148}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 34787325181952.0, 'policy_loss': -0.012153883872088045, 'vf_loss': 34787325181952.0, 'vf_explained_var': 2.2351742e-08, 'kl': 0.006504202763608191, 'entropy': 1.3898078612983227, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 1317634618425344.0, 'policy_loss': -0.007810319628333673, 'vf_loss': 1317634618425344.0, 'vf_explained_var': 7.0780516e-08, 'kl': 0.00997316977736773, 'entropy': -0.1894237205851823, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 272000, 'num_steps_trained': 272000}",False,106,68,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-20-41,1615767641,90.01146101951599,6032.708500623703,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6032.708500623703,0,68,"{'cpu_util_percent': 42.395275590551186, 'ram_util_percent': 55.11732283464568}"
135,67,MARL,light1,-1315300483.4458,-21980053370.627327,-7059003930.294999,2529.87,1,-13554846617.26706,-1096608427.68814,-5830251435.926957,{},"{'episode_reward': [-2703534808.9941096, -6512142718.846902, -14004353940.529661, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961], 'episode_lengths': [2275, 2744, 2517, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914], 'policy_gneJ12_reward': [-349636876.7810691, -1085759341.428287, -2705122702.2816195, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138], 'policy_light1_reward': [-2353897932.213037, -5426383377.418624, -11299231238.24798, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955]}","{'mean_env_wait_ms': 12.884320238152082, 'mean_processing_ms': 3.0040736556382193, 'mean_inference_ms': 1.8241144854235538}",{},0,272000,"{'sample_time_ms': 74710.913, 'sample_throughput': 53.54, 'learn_time_ms': 19034.184, 'learn_throughput': 210.148}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 34787325181952.0, 'policy_loss': -0.012153883872088045, 'vf_loss': 34787325181952.0, 'vf_explained_var': 2.2351742e-08, 'kl': 0.006504202763608191, 'entropy': 1.3898078612983227, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 1317634618425344.0, 'policy_loss': -0.007810319628333673, 'vf_loss': 1317634618425344.0, 'vf_explained_var': 7.0780516e-08, 'kl': 0.00997316977736773, 'entropy': -0.1894237205851823, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 272000, 'num_steps_trained': 272000}",False,106,68,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-20-41,1615767641,90.01146101951599,6032.708500623703,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6032.708500623703,0,68,"{'cpu_util_percent': 42.395275590551186, 'ram_util_percent': 55.11732283464568}"
136,68,MARL,gneJ12,-1315300483.4458,-21980053370.627327,-6969349081.710043,2520.49,2,-8425206753.36029,-204317492.57638025,-1205331679.518077,{},"{'episode_reward': [-6065111337.691192, -5485900463.189604, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096], 'episode_lengths': [2425, 1898, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275], 'policy_gneJ12_reward': [-761524246.5342321, -687276312.1794814, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691], 'policy_light1_reward': [-5303587091.156957, -4798624151.010112, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037]}","{'mean_env_wait_ms': 12.872742889484915, 'mean_processing_ms': 3.0110909646861073, 'mean_inference_ms': 1.823520677778641}",{},0,276000,"{'sample_time_ms': 74886.321, 'sample_throughput': 53.414, 'learn_time_ms': 19043.591, 'learn_throughput': 210.044}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 44005772558336.0, 'policy_loss': -0.00720266392454505, 'vf_loss': 44005772558336.0, 'vf_explained_var': 9.313226e-09, 'kl': 0.008355593730811961, 'entropy': 1.4098109416663647, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 1403629741277184.0, 'policy_loss': 0.0012059462314937264, 'vf_loss': 1403629741277184.0, 'vf_explained_var': -5.5879354e-08, 'kl': 0.010801994321809616, 'entropy': -0.32676317309960723, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 276000, 'num_steps_trained': 276000}",False,108,69,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-22-13,1615767733,91.87663269042969,6124.585133314133,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6124.585133314133,0,69,"{'cpu_util_percent': 32.5968992248062, 'ram_util_percent': 56.20620155038759}"
137,68,MARL,light1,-1315300483.4458,-21980053370.627327,-6969349081.710043,2520.49,2,-13554846617.26706,-1096608427.68814,-5764017402.191961,{},"{'episode_reward': [-6065111337.691192, -5485900463.189604, -16896639612.819538, -6448153420.684994, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096], 'episode_lengths': [2425, 1898, 2236, 2134, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275], 'policy_gneJ12_reward': [-761524246.5342321, -687276312.1794814, -4833371426.223814, -1096274904.8789558, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691], 'policy_light1_reward': [-5303587091.156957, -4798624151.010112, -12063268186.595642, -5351878515.806033, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037]}","{'mean_env_wait_ms': 12.872742889484915, 'mean_processing_ms': 3.0110909646861073, 'mean_inference_ms': 1.823520677778641}",{},0,276000,"{'sample_time_ms': 74886.321, 'sample_throughput': 53.414, 'learn_time_ms': 19043.591, 'learn_throughput': 210.044}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 44005772558336.0, 'policy_loss': -0.00720266392454505, 'vf_loss': 44005772558336.0, 'vf_explained_var': 9.313226e-09, 'kl': 0.008355593730811961, 'entropy': 1.4098109416663647, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 1403629741277184.0, 'policy_loss': 0.0012059462314937264, 'vf_loss': 1403629741277184.0, 'vf_explained_var': -5.5879354e-08, 'kl': 0.010801994321809616, 'entropy': -0.32676317309960723, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 276000, 'num_steps_trained': 276000}",False,108,69,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-22-13,1615767733,91.87663269042969,6124.585133314133,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6124.585133314133,0,69,"{'cpu_util_percent': 32.5968992248062, 'ram_util_percent': 56.20620155038759}"
138,69,MARL,gneJ12,-1315300483.4458,-21980053370.627327,-6798774002.523914,2529.7,2,-8425206753.36029,-204317492.57638025,-1152629813.1148908,{},"{'episode_reward': [-1591354789.775153, -4695930325.11669, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604], 'episode_lengths': [3032, 2259, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898], 'policy_gneJ12_reward': [-225405444.27957696, -434054246.504577, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814], 'policy_light1_reward': [-1365949345.495577, -4261876078.6121125, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112]}","{'mean_env_wait_ms': 12.864437188399457, 'mean_processing_ms': 3.015999928574063, 'mean_inference_ms': 1.8233472296793385}",{},0,280000,"{'sample_time_ms': 75334.764, 'sample_throughput': 53.096, 'learn_time_ms': 19048.285, 'learn_throughput': 209.993}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 26891413028864.0, 'policy_loss': -0.01502190125756897, 'vf_loss': 26891413028864.0, 'vf_explained_var': -5.9604645e-08, 'kl': 0.007675863242184278, 'entropy': 1.4449814781546593, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 1246425637715968.0, 'policy_loss': 0.0034901869657915086, 'vf_loss': 1246425637715968.0, 'vf_explained_var': -7.4505806e-08, 'kl': 0.008055967795371544, 'entropy': -0.2983706290833652, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 280000, 'num_steps_trained': 280000}",False,110,70,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-23-44,1615767824,90.30436611175537,6214.889499425888,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6214.889499425888,0,70,"{'cpu_util_percent': 29.647619047619045, 'ram_util_percent': 56.222222222222236}"
139,69,MARL,light1,-1315300483.4458,-21980053370.627327,-6798774002.523914,2529.7,2,-13554846617.26706,-1096608427.68814,-5646144189.409023,{},"{'episode_reward': [-1591354789.775153, -4695930325.11669, -10346649032.078262, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604], 'episode_lengths': [3032, 2259, 2387, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898], 'policy_gneJ12_reward': [-225405444.27957696, -434054246.504577, -1644564145.4169137, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814], 'policy_light1_reward': [-1365949345.495577, -4261876078.6121125, -8702084886.661364, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112]}","{'mean_env_wait_ms': 12.864437188399457, 'mean_processing_ms': 3.015999928574063, 'mean_inference_ms': 1.8233472296793385}",{},0,280000,"{'sample_time_ms': 75334.764, 'sample_throughput': 53.096, 'learn_time_ms': 19048.285, 'learn_throughput': 209.993}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 26891413028864.0, 'policy_loss': -0.01502190125756897, 'vf_loss': 26891413028864.0, 'vf_explained_var': -5.9604645e-08, 'kl': 0.007675863242184278, 'entropy': 1.4449814781546593, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 1246425637715968.0, 'policy_loss': 0.0034901869657915086, 'vf_loss': 1246425637715968.0, 'vf_explained_var': -7.4505806e-08, 'kl': 0.008055967795371544, 'entropy': -0.2983706290833652, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 280000, 'num_steps_trained': 280000}",False,110,70,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-23-44,1615767824,90.30436611175537,6214.889499425888,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6214.889499425888,0,70,"{'cpu_util_percent': 29.647619047619045, 'ram_util_percent': 56.222222222222236}"
140,70,MARL,gneJ12,-1315300483.4458,-21980053370.627327,-6779772694.667113,2531.47,1,-8425206753.36029,-204317492.57638025,-1146500702.0821059,{},"{'episode_reward': [-8446518246.398142, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669], 'episode_lengths': [2564, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259], 'policy_gneJ12_reward': [-1031653042.1384119, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577], 'policy_light1_reward': [-7414865204.259722, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125]}","{'mean_env_wait_ms': 12.861388421652814, 'mean_processing_ms': 3.0172136310782447, 'mean_inference_ms': 1.823321332573783}",{},0,284000,"{'sample_time_ms': 74411.358, 'sample_throughput': 53.755, 'learn_time_ms': 19016.292, 'learn_throughput': 210.346}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 98621875552256.0, 'policy_loss': -0.013255572121124715, 'vf_loss': 98621875552256.0, 'vf_explained_var': 6.891787e-08, 'kl': 0.013711765306652524, 'entropy': 2.381118558347225, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 2846138168246272.0, 'policy_loss': -0.004052081028930843, 'vf_loss': 2846138168246272.0, 'vf_explained_var': -8.568168e-08, 'kl': 0.01044826421275502, 'entropy': 0.08397109975339845, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 284000, 'num_steps_trained': 284000}",False,111,71,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-25-09,1615767909,85.44380807876587,6300.333307504654,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6300.333307504654,0,71,"{'cpu_util_percent': 30.210833333333333, 'ram_util_percent': 56.210000000000015}"
141,70,MARL,light1,-1315300483.4458,-21980053370.627327,-6779772694.667113,2531.47,1,-13554846617.26706,-1096608427.68814,-5633271992.585006,{},"{'episode_reward': [-8446518246.398142, -3687500179.839026, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669], 'episode_lengths': [2564, 2564, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259], 'policy_gneJ12_reward': [-1031653042.1384119, -536462358.0920263, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577], 'policy_light1_reward': [-7414865204.259722, -3151037821.747003, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125]}","{'mean_env_wait_ms': 12.861388421652814, 'mean_processing_ms': 3.0172136310782447, 'mean_inference_ms': 1.823321332573783}",{},0,284000,"{'sample_time_ms': 74411.358, 'sample_throughput': 53.755, 'learn_time_ms': 19016.292, 'learn_throughput': 210.346}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 98621875552256.0, 'policy_loss': -0.013255572121124715, 'vf_loss': 98621875552256.0, 'vf_explained_var': 6.891787e-08, 'kl': 0.013711765306652524, 'entropy': 2.381118558347225, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 2846138168246272.0, 'policy_loss': -0.004052081028930843, 'vf_loss': 2846138168246272.0, 'vf_explained_var': -8.568168e-08, 'kl': 0.01044826421275502, 'entropy': 0.08397109975339845, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 284000, 'num_steps_trained': 284000}",False,111,71,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-25-09,1615767909,85.44380807876587,6300.333307504654,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6300.333307504654,0,71,"{'cpu_util_percent': 30.210833333333333, 'ram_util_percent': 56.210000000000015}"
142,71,MARL,gneJ12,-1315300483.4458,-21980053370.627327,-6825923826.857321,2536.79,1,-8425206753.36029,-204317492.57638025,-1155695267.1395485,{},"{'episode_reward': [-8302613398.859735, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142], 'episode_lengths': [3096, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564], 'policy_gneJ12_reward': [-1455918863.8362937, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119], 'policy_light1_reward': [-6846694535.023446, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722]}","{'mean_env_wait_ms': 12.858395842170147, 'mean_processing_ms': 3.0182913623107077, 'mean_inference_ms': 1.8233008687361272}",{},0,288000,"{'sample_time_ms': 73456.4, 'sample_throughput': 54.454, 'learn_time_ms': 18972.154, 'learn_throughput': 210.835}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 89253430951936.0, 'policy_loss': -0.010324117814889178, 'vf_loss': 89253430951936.0, 'vf_explained_var': -7.450581e-09, 'kl': 0.0068119069110252894, 'entropy': 1.9440299347043037, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 2120118909796352.0, 'policy_loss': -0.010240313335089013, 'vf_loss': 2120118909796352.0, 'vf_explained_var': -9.685755e-08, 'kl': 0.009401197617989965, 'entropy': 0.037789591966429725, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 288000, 'num_steps_trained': 288000}",False,112,72,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-26-37,1615767997,87.66436815261841,6387.997675657272,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6387.997675657272,0,72,"{'cpu_util_percent': 38.1508064516129, 'ram_util_percent': 57.24838709677419}"
143,71,MARL,light1,-1315300483.4458,-21980053370.627327,-6825923826.857321,2536.79,1,-13554846617.26706,-1096608427.68814,-5670228559.717771,{},"{'episode_reward': [-8302613398.859735, -12500612671.682323, -4491168260.46376, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142], 'episode_lengths': [3096, 2310, 3070, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564], 'policy_gneJ12_reward': [-1455918863.8362937, -2485825485.4397535, -633971142.2095352, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119], 'policy_light1_reward': [-6846694535.023446, -10014787186.24253, -3857197118.254221, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722]}","{'mean_env_wait_ms': 12.858395842170147, 'mean_processing_ms': 3.0182913623107077, 'mean_inference_ms': 1.8233008687361272}",{},0,288000,"{'sample_time_ms': 73456.4, 'sample_throughput': 54.454, 'learn_time_ms': 18972.154, 'learn_throughput': 210.835}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 89253430951936.0, 'policy_loss': -0.010324117814889178, 'vf_loss': 89253430951936.0, 'vf_explained_var': -7.450581e-09, 'kl': 0.0068119069110252894, 'entropy': 1.9440299347043037, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 2120118909796352.0, 'policy_loss': -0.010240313335089013, 'vf_loss': 2120118909796352.0, 'vf_explained_var': -9.685755e-08, 'kl': 0.009401197617989965, 'entropy': 0.037789591966429725, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 288000, 'num_steps_trained': 288000}",False,112,72,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-26-37,1615767997,87.66436815261841,6387.997675657272,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6387.997675657272,0,72,"{'cpu_util_percent': 38.1508064516129, 'ram_util_percent': 57.24838709677419}"
144,72,MARL,gneJ12,-1315300483.4458,-21980053370.627327,-6797663494.815885,2537.28,2,-8425206753.36029,-204317492.57638025,-1143432837.7560372,{},"{'episode_reward': [-8221406503.277202, -5944341224.725366, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735], 'episode_lengths': [3084, 2345, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096], 'policy_gneJ12_reward': [-1113819654.4707267, -779734034.8274242, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937], 'policy_light1_reward': [-7107586848.806467, -5164607189.897941, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446]}","{'mean_env_wait_ms': 12.854013245716901, 'mean_processing_ms': 3.021757228240006, 'mean_inference_ms': 1.823445361289526}",{},0,292000,"{'sample_time_ms': 72529.278, 'sample_throughput': 55.15, 'learn_time_ms': 18782.483, 'learn_throughput': 212.964}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 86805682978816.0, 'policy_loss': -0.002827491523930803, 'vf_loss': 86805682978816.0, 'vf_explained_var': 3.9115548e-08, 'kl': 0.02076809640857391, 'entropy': 2.0974847972393036, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 2082044083437568.0, 'policy_loss': 0.006563080474734306, 'vf_loss': 2082044083437568.0, 'vf_explained_var': 0.0, 'kl': 0.010752638103440404, 'entropy': 0.05036128654319327, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 292000, 'num_steps_trained': 292000}",False,114,73,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-28-11,1615768091,94.27318406105042,6482.270859718323,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6482.270859718323,0,73,"{'cpu_util_percent': 31.380303030303036, 'ram_util_percent': 57.39166666666666}"
145,72,MARL,light1,-1315300483.4458,-21980053370.627327,-6797663494.815885,2537.28,2,-13554846617.26706,-1096608427.68814,-5654230657.059848,{},"{'episode_reward': [-8221406503.277202, -5944341224.725366, -14109175360.388123, -12713198067.412659, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735], 'episode_lengths': [3084, 2345, 2814, 3036, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096], 'policy_gneJ12_reward': [-1113819654.4707267, -779734034.8274242, -1319660512.3153203, -1574231851.051301, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937], 'policy_light1_reward': [-7107586848.806467, -5164607189.897941, -12789514848.072807, -11138966216.361372, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446]}","{'mean_env_wait_ms': 12.854013245716901, 'mean_processing_ms': 3.021757228240006, 'mean_inference_ms': 1.823445361289526}",{},0,292000,"{'sample_time_ms': 72529.278, 'sample_throughput': 55.15, 'learn_time_ms': 18782.483, 'learn_throughput': 212.964}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 86805682978816.0, 'policy_loss': -0.002827491523930803, 'vf_loss': 86805682978816.0, 'vf_explained_var': 3.9115548e-08, 'kl': 0.02076809640857391, 'entropy': 2.0974847972393036, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 2082044083437568.0, 'policy_loss': 0.006563080474734306, 'vf_loss': 2082044083437568.0, 'vf_explained_var': 0.0, 'kl': 0.010752638103440404, 'entropy': 0.05036128654319327, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 292000, 'num_steps_trained': 292000}",False,114,73,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-28-11,1615768091,94.27318406105042,6482.270859718323,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6482.270859718323,0,73,"{'cpu_util_percent': 31.380303030303036, 'ram_util_percent': 57.39166666666666}"
146,73,MARL,gneJ12,-1315300483.4458,-21980053370.627327,-6675152730.265282,2531.31,2,-8425206753.36029,-204317492.57638025,-1137237350.6848435,{},"{'episode_reward': [-7080522332.803153, -7490774639.937237, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366], 'episode_lengths': [2617, 2636, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345], 'policy_gneJ12_reward': [-1123022594.127025, -1151321062.120209, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242], 'policy_light1_reward': [-5957499738.676131, -6339453577.817024, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941]}","{'mean_env_wait_ms': 12.849479514778203, 'mean_processing_ms': 3.0251857016253756, 'mean_inference_ms': 1.8234251432823063}",{},0,296000,"{'sample_time_ms': 72934.085, 'sample_throughput': 54.844, 'learn_time_ms': 18728.631, 'learn_throughput': 213.577}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 78246991101952.0, 'policy_loss': -0.01137545341043733, 'vf_loss': 78246991101952.0, 'vf_explained_var': 1.3038516e-08, 'kl': 0.007594746275572106, 'entropy': 2.1310204714536667, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 2274600310276096.0, 'policy_loss': -0.003287345462013036, 'vf_loss': 2274600310276096.0, 'vf_explained_var': 4.8428774e-08, 'kl': 0.009358356219308916, 'entropy': 0.008577518165111542, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 296000, 'num_steps_trained': 296000}",False,116,74,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-29-45,1615768185,93.86905908584595,6576.139918804169,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6576.139918804169,0,74,"{'cpu_util_percent': 30.393181818181823, 'ram_util_percent': 57.384848484848476}"
147,73,MARL,light1,-1315300483.4458,-21980053370.627327,-6675152730.265282,2531.31,2,-13554846617.26706,-1096608427.68814,-5537915379.580436,{},"{'episode_reward': [-7080522332.803153, -7490774639.937237, -11552320043.761782, -21980053370.627327, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366], 'episode_lengths': [2617, 2636, 2567, 2700, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345], 'policy_gneJ12_reward': [-1123022594.127025, -1151321062.120209, -1364616194.8083677, -8425206753.36029, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242], 'policy_light1_reward': [-5957499738.676131, -6339453577.817024, -10187703848.953398, -13554846617.26706, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941]}","{'mean_env_wait_ms': 12.849479514778203, 'mean_processing_ms': 3.0251857016253756, 'mean_inference_ms': 1.8234251432823063}",{},0,296000,"{'sample_time_ms': 72934.085, 'sample_throughput': 54.844, 'learn_time_ms': 18728.631, 'learn_throughput': 213.577}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 78246991101952.0, 'policy_loss': -0.01137545341043733, 'vf_loss': 78246991101952.0, 'vf_explained_var': 1.3038516e-08, 'kl': 0.007594746275572106, 'entropy': 2.1310204714536667, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 2274600310276096.0, 'policy_loss': -0.003287345462013036, 'vf_loss': 2274600310276096.0, 'vf_explained_var': 4.8428774e-08, 'kl': 0.009358356219308916, 'entropy': 0.008577518165111542, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 296000, 'num_steps_trained': 296000}",False,116,74,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-29-45,1615768185,93.86905908584595,6576.139918804169,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6576.139918804169,0,74,"{'cpu_util_percent': 30.393181818181823, 'ram_util_percent': 57.384848484848476}"
148,74,MARL,gneJ12,-1315300483.4458,-17386949670.798218,-6417796781.069952,2514.9,2,-7498444298.009825,-204317492.57638025,-1049569676.5177605,{},"{'episode_reward': [-3170367800.87661, -4626410693.9797, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237], 'episode_lengths': [2001, 1625, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636], 'policy_gneJ12_reward': [-405328183.0917163, -617727348.3686336, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209], 'policy_light1_reward': [-2765039617.7848887, -4008683345.611068, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024]}","{'mean_env_wait_ms': 12.84164196413265, 'mean_processing_ms': 3.027398595084263, 'mean_inference_ms': 1.8228127376476735}",{},0,300000,"{'sample_time_ms': 73528.456, 'sample_throughput': 54.401, 'learn_time_ms': 18596.482, 'learn_throughput': 215.094}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 46140139110400.0, 'policy_loss': -0.014198831369867548, 'vf_loss': 46140139110400.0, 'vf_explained_var': -5.5879354e-09, 'kl': 0.006719676406646613, 'entropy': 1.6401488967239857, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 1428197199577088.0, 'policy_loss': -0.004264229559339583, 'vf_loss': 1428197199577088.0, 'vf_explained_var': -8.940697e-08, 'kl': 0.010638707251928281, 'entropy': -0.193185827229172, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 300000, 'num_steps_trained': 300000}",False,118,75,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-31-19,1615768279,93.42556500434875,6669.5654838085175,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6669.5654838085175,0,75,"{'cpu_util_percent': 27.220610687022898, 'ram_util_percent': 57.316793893129784}"
149,74,MARL,light1,-1315300483.4458,-17386949670.798218,-6417796781.069952,2514.9,2,-10052251779.643225,-1096608427.68814,-5368227104.552192,{},"{'episode_reward': [-3170367800.87661, -4626410693.9797, -11590580769.094769, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237], 'episode_lengths': [2001, 1625, 2748, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636], 'policy_gneJ12_reward': [-405328183.0917163, -617727348.3686336, -1538328989.4515386, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209], 'policy_light1_reward': [-2765039617.7848887, -4008683345.611068, -10052251779.643225, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024]}","{'mean_env_wait_ms': 12.84164196413265, 'mean_processing_ms': 3.027398595084263, 'mean_inference_ms': 1.8228127376476735}",{},0,300000,"{'sample_time_ms': 73528.456, 'sample_throughput': 54.401, 'learn_time_ms': 18596.482, 'learn_throughput': 215.094}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 46140139110400.0, 'policy_loss': -0.014198831369867548, 'vf_loss': 46140139110400.0, 'vf_explained_var': -5.5879354e-09, 'kl': 0.006719676406646613, 'entropy': 1.6401488967239857, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 1428197199577088.0, 'policy_loss': -0.004264229559339583, 'vf_loss': 1428197199577088.0, 'vf_explained_var': -8.940697e-08, 'kl': 0.010638707251928281, 'entropy': -0.193185827229172, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 300000, 'num_steps_trained': 300000}",False,118,75,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-31-19,1615768279,93.42556500434875,6669.5654838085175,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6669.5654838085175,0,75,"{'cpu_util_percent': 27.220610687022898, 'ram_util_percent': 57.316793893129784}"
150,75,MARL,gneJ12,-1315300483.4458,-17386949670.798218,-6334064327.92047,2513.03,1,-7498444298.009825,-204317492.57638025,-1038701552.2528007,{},"{'episode_reward': [-3217335454.1464415, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797], 'episode_lengths': [2561, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625], 'policy_gneJ12_reward': [-451516562.9555719, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336], 'policy_light1_reward': [-2765818891.190869, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068]}","{'mean_env_wait_ms': 12.8372540193873, 'mean_processing_ms': 3.0291285482894934, 'mean_inference_ms': 1.822385076496962}",{},0,304000,"{'sample_time_ms': 71871.812, 'sample_throughput': 55.655, 'learn_time_ms': 18558.077, 'learn_throughput': 215.54}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 42223136014336.0, 'policy_loss': -0.009574210678692907, 'vf_loss': 42223136014336.0, 'vf_explained_var': -2.6077032e-08, 'kl': 0.006060356965463143, 'entropy': 1.5938300229609013, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 1451792609050624.0, 'policy_loss': 0.0025529493286740035, 'vf_loss': 1451792609050624.0, 'vf_explained_var': 1.8626451e-08, 'kl': 0.014122122622211464, 'entropy': -0.21452631219290197, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 304000, 'num_steps_trained': 304000}",False,119,76,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-32-42,1615768362,83.55125498771667,6753.116738796234,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6753.116738796234,0,76,"{'cpu_util_percent': 31.345762711864417, 'ram_util_percent': 57.3237288135593}"
151,75,MARL,light1,-1315300483.4458,-17386949670.798218,-6334064327.92047,2513.03,1,-9888505372.788342,-1096608427.68814,-5295362775.667668,{},"{'episode_reward': [-3217335454.1464415, -6661114249.465764, -9183084791.211535, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797], 'episode_lengths': [2561, 2020, 1993, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625], 'policy_gneJ12_reward': [-451516562.9555719, -897009640.7584012, -1191479521.3522346, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336], 'policy_light1_reward': [-2765818891.190869, -5764104608.707362, -7991605269.859306, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068]}","{'mean_env_wait_ms': 12.8372540193873, 'mean_processing_ms': 3.0291285482894934, 'mean_inference_ms': 1.822385076496962}",{},0,304000,"{'sample_time_ms': 71871.812, 'sample_throughput': 55.655, 'learn_time_ms': 18558.077, 'learn_throughput': 215.54}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 42223136014336.0, 'policy_loss': -0.009574210678692907, 'vf_loss': 42223136014336.0, 'vf_explained_var': -2.6077032e-08, 'kl': 0.006060356965463143, 'entropy': 1.5938300229609013, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 1451792609050624.0, 'policy_loss': 0.0025529493286740035, 'vf_loss': 1451792609050624.0, 'vf_explained_var': 1.8626451e-08, 'kl': 0.014122122622211464, 'entropy': -0.21452631219290197, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 304000, 'num_steps_trained': 304000}",False,119,76,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-32-42,1615768362,83.55125498771667,6753.116738796234,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6753.116738796234,0,76,"{'cpu_util_percent': 31.345762711864417, 'ram_util_percent': 57.3237288135593}"
152,76,MARL,gneJ12,-1315300483.4458,-17386949670.798218,-6317842422.39877,2529.37,2,-7498444298.009825,-204317492.57638025,-1036384857.3866358,{},"{'episode_reward': [-7106079911.804898, -7115928576.702338, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415], 'episode_lengths': [2616, 3031, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561], 'policy_gneJ12_reward': [-936024770.8268768, -920794904.6672612, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719], 'policy_light1_reward': [-6170055140.978042, -6195133672.035079, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869]}","{'mean_env_wait_ms': 12.828531264987955, 'mean_processing_ms': 3.031800817395271, 'mean_inference_ms': 1.821502485888505}",{},0,308000,"{'sample_time_ms': 71824.487, 'sample_throughput': 55.691, 'learn_time_ms': 18436.63, 'learn_throughput': 216.959}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 61737275490304.0, 'policy_loss': -0.009998176450608298, 'vf_loss': 61737275490304.0, 'vf_explained_var': -7.450581e-09, 'kl': 0.008521530602592975, 'entropy': 1.9372548498213291, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 1805441893924864.0, 'policy_loss': -0.002346273889997974, 'vf_loss': 1805441893924864.0, 'vf_explained_var': 1.3038516e-08, 'kl': 0.011478644264570903, 'entropy': -0.09679653542116284, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 308000, 'num_steps_trained': 308000}",False,121,77,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-34-15,1615768455,92.19736814498901,6845.314106941223,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6845.314106941223,0,77,"{'cpu_util_percent': 28.39612403100775, 'ram_util_percent': 57.3984496124031}"
153,76,MARL,light1,-1315300483.4458,-17386949670.798218,-6317842422.39877,2529.37,2,-9888505372.788342,-1096608427.68814,-5281457565.012134,{},"{'episode_reward': [-7106079911.804898, -7115928576.702338, -10378892983.977835, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415], 'episode_lengths': [2616, 3031, 3081, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561], 'policy_gneJ12_reward': [-936024770.8268768, -920794904.6672612, -1239135682.6786587, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719], 'policy_light1_reward': [-6170055140.978042, -6195133672.035079, -9139757301.299171, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869]}","{'mean_env_wait_ms': 12.828531264987955, 'mean_processing_ms': 3.031800817395271, 'mean_inference_ms': 1.821502485888505}",{},0,308000,"{'sample_time_ms': 71824.487, 'sample_throughput': 55.691, 'learn_time_ms': 18436.63, 'learn_throughput': 216.959}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 61737275490304.0, 'policy_loss': -0.009998176450608298, 'vf_loss': 61737275490304.0, 'vf_explained_var': -7.450581e-09, 'kl': 0.008521530602592975, 'entropy': 1.9372548498213291, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 1805441893924864.0, 'policy_loss': -0.002346273889997974, 'vf_loss': 1805441893924864.0, 'vf_explained_var': 1.3038516e-08, 'kl': 0.011478644264570903, 'entropy': -0.09679653542116284, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 308000, 'num_steps_trained': 308000}",False,121,77,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-34-15,1615768455,92.19736814498901,6845.314106941223,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6845.314106941223,0,77,"{'cpu_util_percent': 28.39612403100775, 'ram_util_percent': 57.3984496124031}"
154,77,MARL,gneJ12,-1315300483.4458,-17386949670.798218,-6291142056.166035,2527.13,1,-7498444298.009825,-204317492.57638025,-1039015216.2696911,{},"{'episode_reward': [-7708856360.70432, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338], 'episode_lengths': [2857, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031], 'policy_gneJ12_reward': [-1502171570.9841983, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612], 'policy_light1_reward': [-6206684789.720108, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079]}","{'mean_env_wait_ms': 12.824764847229865, 'mean_processing_ms': 3.033715388752101, 'mean_inference_ms': 1.8211708962940352}",{},0,312000,"{'sample_time_ms': 72059.289, 'sample_throughput': 55.51, 'learn_time_ms': 18322.103, 'learn_throughput': 218.316}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 146004921024512.0, 'policy_loss': -0.0008242411131504923, 'vf_loss': 146004921024512.0, 'vf_explained_var': 2.9802322e-08, 'kl': 0.005828721703437623, 'entropy': 3.012347735464573, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 2496974863466496.0, 'policy_loss': -0.004344504530308768, 'vf_loss': 2496974863466496.0, 'vf_explained_var': -7.450581e-09, 'kl': 0.005908794006245444, 'entropy': 0.2133152934256941, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 312000, 'num_steps_trained': 312000}",False,122,78,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-35-46,1615768546,91.21315217018127,6936.527259111404,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6936.527259111404,0,78,"{'cpu_util_percent': 35.682031249999994, 'ram_util_percent': 57.39296874999998}"
155,77,MARL,light1,-1315300483.4458,-17386949670.798218,-6291142056.166035,2527.13,1,-9888505372.788342,-1096608427.68814,-5252126839.896342,{},"{'episode_reward': [-7708856360.70432, -8865851373.405058, -2381148663.4006, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338], 'episode_lengths': [2857, 2524, 2521, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031], 'policy_gneJ12_reward': [-1502171570.9841983, -982423528.2750291, -311659252.60711795, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612], 'policy_light1_reward': [-6206684789.720108, -7883427845.130044, -2069489410.7934828, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079]}","{'mean_env_wait_ms': 12.824764847229865, 'mean_processing_ms': 3.033715388752101, 'mean_inference_ms': 1.8211708962940352}",{},0,312000,"{'sample_time_ms': 72059.289, 'sample_throughput': 55.51, 'learn_time_ms': 18322.103, 'learn_throughput': 218.316}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 146004921024512.0, 'policy_loss': -0.0008242411131504923, 'vf_loss': 146004921024512.0, 'vf_explained_var': 2.9802322e-08, 'kl': 0.005828721703437623, 'entropy': 3.012347735464573, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 2496974863466496.0, 'policy_loss': -0.004344504530308768, 'vf_loss': 2496974863466496.0, 'vf_explained_var': -7.450581e-09, 'kl': 0.005908794006245444, 'entropy': 0.2133152934256941, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 312000, 'num_steps_trained': 312000}",False,122,78,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-35-46,1615768546,91.21315217018127,6936.527259111404,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6936.527259111404,0,78,"{'cpu_util_percent': 35.682031249999994, 'ram_util_percent': 57.39296874999998}"
156,78,MARL,gneJ12,-1315300483.4458,-17386949670.798218,-6322915812.369961,2531.63,2,-7498444298.009825,-204317492.57638025,-1047744103.061275,{},"{'episode_reward': [-8354700353.578763, -6069675303.6194105, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432], 'episode_lengths': [3036, 2459, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857], 'policy_gneJ12_reward': [-1283205721.9964898, -883765738.0440688, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983], 'policy_light1_reward': [-7071494631.582267, -5185909565.575363, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108]}","{'mean_env_wait_ms': 12.81827035172076, 'mean_processing_ms': 3.0364499289911633, 'mean_inference_ms': 1.820655146313952}",{},0,316000,"{'sample_time_ms': 72144.598, 'sample_throughput': 55.444, 'learn_time_ms': 18428.878, 'learn_throughput': 217.051}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 62607803023360.0, 'policy_loss': -0.006487681821454316, 'vf_loss': 62607803023360.0, 'vf_explained_var': 1.4901161e-08, 'kl': 0.0055434470195905305, 'entropy': 2.052094392478466, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 1897863474839552.0, 'policy_loss': -0.00226849177852273, 'vf_loss': 1897863474839552.0, 'vf_explained_var': 5.5879354e-08, 'kl': 0.012181528974906541, 'entropy': -0.015561569554847665, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 316000, 'num_steps_trained': 316000}",False,124,79,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-37-20,1615768640,93.79700779914856,7030.324266910553,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7030.324266910553,0,79,"{'cpu_util_percent': 35.425000000000004, 'ram_util_percent': 57.390151515151516}"
157,78,MARL,light1,-1315300483.4458,-17386949670.798218,-6322915812.369961,2531.63,2,-9888505372.788342,-1096608427.68814,-5275171709.308682,{},"{'episode_reward': [-8354700353.578763, -6069675303.6194105, -10716238761.282564, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432], 'episode_lengths': [3036, 2459, 2547, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857], 'policy_gneJ12_reward': [-1283205721.9964898, -883765738.0440688, -2107559441.6996064, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983], 'policy_light1_reward': [-7071494631.582267, -5185909565.575363, -8608679319.582975, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108]}","{'mean_env_wait_ms': 12.81827035172076, 'mean_processing_ms': 3.0364499289911633, 'mean_inference_ms': 1.820655146313952}",{},0,316000,"{'sample_time_ms': 72144.598, 'sample_throughput': 55.444, 'learn_time_ms': 18428.878, 'learn_throughput': 217.051}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 62607803023360.0, 'policy_loss': -0.006487681821454316, 'vf_loss': 62607803023360.0, 'vf_explained_var': 1.4901161e-08, 'kl': 0.0055434470195905305, 'entropy': 2.052094392478466, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 1897863474839552.0, 'policy_loss': -0.00226849177852273, 'vf_loss': 1897863474839552.0, 'vf_explained_var': 5.5879354e-08, 'kl': 0.012181528974906541, 'entropy': -0.015561569554847665, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 316000, 'num_steps_trained': 316000}",False,124,79,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-37-20,1615768640,93.79700779914856,7030.324266910553,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7030.324266910553,0,79,"{'cpu_util_percent': 35.425000000000004, 'ram_util_percent': 57.390151515151516}"
158,79,MARL,gneJ12,-1315300483.4458,-17386949670.798218,-6259040594.827682,2535.27,1,-7498444298.009825,-204317492.57638025,-1032250629.1805382,{},"{'episode_reward': [-4328717007.054848, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105], 'episode_lengths': [2911, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459], 'policy_gneJ12_reward': [-558212053.625892, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688], 'policy_light1_reward': [-3770504953.428948, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363]}","{'mean_env_wait_ms': 12.815326614014174, 'mean_processing_ms': 3.0372861373981666, 'mean_inference_ms': 1.820469213220954}",{},0,320000,"{'sample_time_ms': 71890.296, 'sample_throughput': 55.64, 'learn_time_ms': 18455.662, 'learn_throughput': 216.736}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 60265890316288.0, 'policy_loss': -0.0052631240541813895, 'vf_loss': 60265890316288.0, 'vf_explained_var': -5.9604645e-08, 'kl': 0.013104306912282482, 'entropy': 1.8617324568331242, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 1445801337290752.0, 'policy_loss': -0.002602805820060894, 'vf_loss': 1445801337290752.0, 'vf_explained_var': 2.7939677e-08, 'kl': 0.010331736717489548, 'entropy': -0.18576976261101663, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 320000, 'num_steps_trained': 320000}",False,125,80,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-38-48,1615768728,88.02981400489807,7118.354080915451,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7118.354080915451,0,80,"{'cpu_util_percent': 33.58709677419355, 'ram_util_percent': 57.47016129032256}"
159,79,MARL,light1,-1315300483.4458,-17386949670.798218,-6259040594.827682,2535.27,1,-9888505372.788342,-1096608427.68814,-5226789965.647143,{},"{'episode_reward': [-4328717007.054848, -8356529264.006624, -8368769981.406484, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105], 'episode_lengths': [2911, 2478, 2791, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459], 'policy_gneJ12_reward': [-558212053.625892, -1095315147.044081, -1159982255.9001245, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688], 'policy_light1_reward': [-3770504953.428948, -7261214116.962533, -7208787725.506382, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363]}","{'mean_env_wait_ms': 12.815326614014174, 'mean_processing_ms': 3.0372861373981666, 'mean_inference_ms': 1.820469213220954}",{},0,320000,"{'sample_time_ms': 71890.296, 'sample_throughput': 55.64, 'learn_time_ms': 18455.662, 'learn_throughput': 216.736}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 60265890316288.0, 'policy_loss': -0.0052631240541813895, 'vf_loss': 60265890316288.0, 'vf_explained_var': -5.9604645e-08, 'kl': 0.013104306912282482, 'entropy': 1.8617324568331242, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 1445801337290752.0, 'policy_loss': -0.002602805820060894, 'vf_loss': 1445801337290752.0, 'vf_explained_var': 2.7939677e-08, 'kl': 0.010331736717489548, 'entropy': -0.18576976261101663, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 320000, 'num_steps_trained': 320000}",False,125,80,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-38-48,1615768728,88.02981400489807,7118.354080915451,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7118.354080915451,0,80,"{'cpu_util_percent': 33.58709677419355, 'ram_util_percent': 57.47016129032256}"
160,80,MARL,gneJ12,-1315300483.4458,-17386949670.798218,-6208230500.757434,2533.77,2,-7498444298.009825,-204317492.57638025,-1027715546.4190906,{},"{'episode_reward': [-7483375421.8671055, -4160914416.5211897, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848], 'episode_lengths': [2433, 2686, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911], 'policy_gneJ12_reward': [-1272097290.541829, -529691836.25762975, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892], 'policy_light1_reward': [-6211278131.325276, -3631222580.263557, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948]}","{'mean_env_wait_ms': 12.809794386626356, 'mean_processing_ms': 3.039751860230999, 'mean_inference_ms': 1.820156231235984}",{},0,324000,"{'sample_time_ms': 72551.948, 'sample_throughput': 55.133, 'learn_time_ms': 18413.026, 'learn_throughput': 217.238}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 58080381632512.0, 'policy_loss': -0.005979333072900772, 'vf_loss': 58080381632512.0, 'vf_explained_var': 3.5390258e-08, 'kl': 0.00573904778866563, 'entropy': 1.8423053547739983, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 1419750299140096.0, 'policy_loss': -0.0029149123874958605, 'vf_loss': 1419750299140096.0, 'vf_explained_var': -7.8231096e-08, 'kl': 0.022099879599409178, 'entropy': -0.20284924865700305, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 324000, 'num_steps_trained': 324000}",False,127,81,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-40-20,1615768820,91.63517808914185,7209.989259004593,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7209.989259004593,0,81,"{'cpu_util_percent': 28.329457364341085, 'ram_util_percent': 57.39302325581396}"
161,80,MARL,light1,-1315300483.4458,-17386949670.798218,-6208230500.757434,2533.77,2,-9888505372.788342,-1096608427.68814,-5180514954.338342,{},"{'episode_reward': [-7483375421.8671055, -4160914416.5211897, -10888859337.459352, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848], 'episode_lengths': [2433, 2686, 3013, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911], 'policy_gneJ12_reward': [-1272097290.541829, -529691836.25762975, -1506401446.589891, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892], 'policy_light1_reward': [-6211278131.325276, -3631222580.263557, -9382457890.869427, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948]}","{'mean_env_wait_ms': 12.809794386626356, 'mean_processing_ms': 3.039751860230999, 'mean_inference_ms': 1.820156231235984}",{},0,324000,"{'sample_time_ms': 72551.948, 'sample_throughput': 55.133, 'learn_time_ms': 18413.026, 'learn_throughput': 217.238}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 58080381632512.0, 'policy_loss': -0.005979333072900772, 'vf_loss': 58080381632512.0, 'vf_explained_var': 3.5390258e-08, 'kl': 0.00573904778866563, 'entropy': 1.8423053547739983, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 1419750299140096.0, 'policy_loss': -0.0029149123874958605, 'vf_loss': 1419750299140096.0, 'vf_explained_var': -7.8231096e-08, 'kl': 0.022099879599409178, 'entropy': -0.20284924865700305, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 324000, 'num_steps_trained': 324000}",False,127,81,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-40-20,1615768820,91.63517808914185,7209.989259004593,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7209.989259004593,0,81,"{'cpu_util_percent': 28.329457364341085, 'ram_util_percent': 57.39302325581396}"
162,81,MARL,gneJ12,-1315300483.4458,-17386949670.798218,-6156118173.104788,2525.35,1,-7498444298.009825,-204317492.57638025,-1020867083.4496589,{},"{'episode_reward': [-5677626572.194818, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897], 'episode_lengths': [2171, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686], 'policy_gneJ12_reward': [-821555149.6467173, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975], 'policy_light1_reward': [-4856071422.548111, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557]}","{'mean_env_wait_ms': 12.807762202324902, 'mean_processing_ms': 3.0404953881267547, 'mean_inference_ms': 1.8201115099984162}",{},0,328000,"{'sample_time_ms': 72716.592, 'sample_throughput': 55.008, 'learn_time_ms': 18526.76, 'learn_throughput': 215.904}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 127115937710080.0, 'policy_loss': -0.016352773571270518, 'vf_loss': 127115937710080.0, 'vf_explained_var': 4.8428774e-08, 'kl': 0.009309395543823484, 'entropy': 3.0397877171635628, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 2600263504363520.0, 'policy_loss': -0.005136703548487276, 'vf_loss': 2600263504363520.0, 'vf_explained_var': -5.5879354e-08, 'kl': 0.004911166146484902, 'entropy': 0.236967699136585, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 328000, 'num_steps_trained': 328000}",False,128,82,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-41-50,1615768910,90.44801211357117,7300.437271118164,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7300.437271118164,0,82,"{'cpu_util_percent': 39.11746031746032, 'ram_util_percent': 57.56111111111112}"
163,81,MARL,light1,-1315300483.4458,-17386949670.798218,-6156118173.104788,2525.35,1,-9888505372.788342,-1096608427.68814,-5135251089.6551285,{},"{'episode_reward': [-5677626572.194818, -1960706630.2177725, -3654684844.1324644, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897], 'episode_lengths': [2171, 2134, 3038, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686], 'policy_gneJ12_reward': [-821555149.6467173, -277997050.6164309, -476902383.44874215, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975], 'policy_light1_reward': [-4856071422.548111, -1682709579.601341, -3177782460.683727, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557]}","{'mean_env_wait_ms': 12.807762202324902, 'mean_processing_ms': 3.0404953881267547, 'mean_inference_ms': 1.8201115099984162}",{},0,328000,"{'sample_time_ms': 72716.592, 'sample_throughput': 55.008, 'learn_time_ms': 18526.76, 'learn_throughput': 215.904}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 127115937710080.0, 'policy_loss': -0.016352773571270518, 'vf_loss': 127115937710080.0, 'vf_explained_var': 4.8428774e-08, 'kl': 0.009309395543823484, 'entropy': 3.0397877171635628, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 2600263504363520.0, 'policy_loss': -0.005136703548487276, 'vf_loss': 2600263504363520.0, 'vf_explained_var': -5.5879354e-08, 'kl': 0.004911166146484902, 'entropy': 0.236967699136585, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 328000, 'num_steps_trained': 328000}",False,128,82,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-41-50,1615768910,90.44801211357117,7300.437271118164,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7300.437271118164,0,82,"{'cpu_util_percent': 39.11746031746032, 'ram_util_percent': 57.56111111111112}"
164,82,MARL,gneJ12,-1315300483.4458,-17386949670.798218,-6243098707.568118,2524.37,2,-7498444298.009825,-204317492.57638025,-1038278402.2435455,{},"{'episode_reward': [-6683306484.712456, -7630138435.970684, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818], 'episode_lengths': [2274, 2800, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171], 'policy_gneJ12_reward': [-1206011770.415046, -1290019543.0388026, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173], 'policy_light1_reward': [-5477294714.2974, -6340118892.931869, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111]}","{'mean_env_wait_ms': 12.804207562916224, 'mean_processing_ms': 3.0429640565939673, 'mean_inference_ms': 1.8201112937814015}",{},0,332000,"{'sample_time_ms': 73299.063, 'sample_throughput': 54.571, 'learn_time_ms': 18546.531, 'learn_throughput': 215.674}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 86161964531712.0, 'policy_loss': -0.011135492182802409, 'vf_loss': 86161964531712.0, 'vf_explained_var': -2.9802322e-08, 'kl': 0.005775169636763167, 'entropy': 2.3994656950235367, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 1934192459907072.0, 'policy_loss': -0.0013555476034525782, 'vf_loss': 1934192459907072.0, 'vf_explained_var': -8.568168e-08, 'kl': 0.01310112202190794, 'entropy': 0.15480630472302437, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 332000, 'num_steps_trained': 332000}",False,130,83,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-43-31,1615769011,100.29570722579956,7400.732978343964,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7400.732978343964,0,83,"{'cpu_util_percent': 33.242553191489364, 'ram_util_percent': 57.44042553191487}"
165,82,MARL,light1,-1315300483.4458,-17386949670.798218,-6243098707.568118,2524.37,2,-9888505372.788342,-1096608427.68814,-5204820305.32457,{},"{'episode_reward': [-6683306484.712456, -7630138435.970684, -9569925436.44581, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818], 'episode_lengths': [2274, 2800, 2652, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171], 'policy_gneJ12_reward': [-1206011770.415046, -1290019543.0388026, -1432645806.2577422, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173], 'policy_light1_reward': [-5477294714.2974, -6340118892.931869, -8137279630.1880455, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111]}","{'mean_env_wait_ms': 12.804207562916224, 'mean_processing_ms': 3.0429640565939673, 'mean_inference_ms': 1.8201112937814015}",{},0,332000,"{'sample_time_ms': 73299.063, 'sample_throughput': 54.571, 'learn_time_ms': 18546.531, 'learn_throughput': 215.674}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 86161964531712.0, 'policy_loss': -0.011135492182802409, 'vf_loss': 86161964531712.0, 'vf_explained_var': -2.9802322e-08, 'kl': 0.005775169636763167, 'entropy': 2.3994656950235367, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 1934192459907072.0, 'policy_loss': -0.0013555476034525782, 'vf_loss': 1934192459907072.0, 'vf_explained_var': -8.568168e-08, 'kl': 0.01310112202190794, 'entropy': 0.15480630472302437, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 332000, 'num_steps_trained': 332000}",False,130,83,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-43-31,1615769011,100.29570722579956,7400.732978343964,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7400.732978343964,0,83,"{'cpu_util_percent': 33.242553191489364, 'ram_util_percent': 57.44042553191487}"
166,83,MARL,gneJ12,-1315300483.4458,-17386949670.798218,-6208106542.518995,2519.77,1,-7498444298.009825,-204317492.57638025,-1031990833.4462723,{},"{'episode_reward': [-6070708931.53347, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684], 'episode_lengths': [2192, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800], 'policy_gneJ12_reward': [-803888926.5304034, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026], 'policy_light1_reward': [-5266820005.003068, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869]}","{'mean_env_wait_ms': 12.802885823431422, 'mean_processing_ms': 3.044023472759628, 'mean_inference_ms': 1.8201744831377542}",{},0,336000,"{'sample_time_ms': 72465.834, 'sample_throughput': 55.198, 'learn_time_ms': 18541.983, 'learn_throughput': 215.727}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 64126006853632.0, 'policy_loss': -0.01282524349517189, 'vf_loss': 64126006853632.0, 'vf_explained_var': -7.0780516e-08, 'kl': 0.007655092114873696, 'entropy': 2.129344020038843, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 2252647696433152.0, 'policy_loss': -0.004842458467464894, 'vf_loss': 2252647696433152.0, 'vf_explained_var': -1.8626451e-08, 'kl': 0.009852788658463396, 'entropy': 0.04501376539701596, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 336000, 'num_steps_trained': 336000}",False,131,84,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-44-56,1615769096,85.49064588546753,7486.223624229431,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7486.223624229431,0,84,"{'cpu_util_percent': 31.348333333333336, 'ram_util_percent': 57.399999999999984}"
167,83,MARL,light1,-1315300483.4458,-17386949670.798218,-6208106542.518995,2519.77,1,-9888505372.788342,-1096608427.68814,-5176115709.072721,{},"{'episode_reward': [-6070708931.53347, -1915560191.3538332, -7853659853.238171, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684], 'episode_lengths': [2192, 1651, 2616, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800], 'policy_gneJ12_reward': [-803888926.5304034, -204317492.57638025, -1070043940.7602806, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026], 'policy_light1_reward': [-5266820005.003068, -1711242698.7774525, -6783615912.477901, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869]}","{'mean_env_wait_ms': 12.802885823431422, 'mean_processing_ms': 3.044023472759628, 'mean_inference_ms': 1.8201744831377542}",{},0,336000,"{'sample_time_ms': 72465.834, 'sample_throughput': 55.198, 'learn_time_ms': 18541.983, 'learn_throughput': 215.727}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 64126006853632.0, 'policy_loss': -0.01282524349517189, 'vf_loss': 64126006853632.0, 'vf_explained_var': -7.0780516e-08, 'kl': 0.007655092114873696, 'entropy': 2.129344020038843, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 2252647696433152.0, 'policy_loss': -0.004842458467464894, 'vf_loss': 2252647696433152.0, 'vf_explained_var': -1.8626451e-08, 'kl': 0.009852788658463396, 'entropy': 0.04501376539701596, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 336000, 'num_steps_trained': 336000}",False,131,84,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-44-56,1615769096,85.49064588546753,7486.223624229431,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7486.223624229431,0,84,"{'cpu_util_percent': 31.348333333333336, 'ram_util_percent': 57.399999999999984}"
168,84,MARL,gneJ12,-1315300483.4458,-17386949670.798218,-6205523208.532601,2525.12,2,-7498444298.009825,-218692055.75766248,-1032174724.4352626,{},"{'episode_reward': [-6936272776.055735, -2574613869.8970795, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684, -6070708931.53347], 'episode_lengths': [2795, 2007, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800, 2192], 'policy_gneJ12_reward': [-950879460.0400009, -341871072.1957007, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026, -803888926.5304034], 'policy_light1_reward': [-5985393316.015743, -2232742797.701376, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869, -5266820005.003068]}","{'mean_env_wait_ms': 12.800394953565783, 'mean_processing_ms': 3.046759235592345, 'mean_inference_ms': 1.8203267993382772}",{},0,340000,"{'sample_time_ms': 72182.466, 'sample_throughput': 55.415, 'learn_time_ms': 18533.396, 'learn_throughput': 215.827}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 72561084989440.0, 'policy_loss': -0.005816923949168995, 'vf_loss': 72561084989440.0, 'vf_explained_var': 5.2154064e-08, 'kl': 0.017630780988838524, 'entropy': 2.031896725296974, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 1358425644597248.0, 'policy_loss': 0.003433538367971778, 'vf_loss': 1358425644597248.0, 'vf_explained_var': 6.146729e-08, 'kl': 0.012800528216757812, 'entropy': -0.12183130800258368, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 340000, 'num_steps_trained': 340000}",False,133,85,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-46-27,1615769187,90.50617980957031,7576.7298040390015,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7576.7298040390015,0,85,"{'cpu_util_percent': 27.98425196850393, 'ram_util_percent': 57.39999999999996}"
169,84,MARL,light1,-1315300483.4458,-17386949670.798218,-6205523208.532601,2525.12,2,-9888505372.788342,-1096608427.68814,-5173348484.097339,{},"{'episode_reward': [-6936272776.055735, -2574613869.8970795, -8008215387.001425, -4408747105.2170515, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684, -6070708931.53347], 'episode_lengths': [2795, 2007, 2534, 2333, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800, 2192], 'policy_gneJ12_reward': [-950879460.0400009, -341871072.1957007, -1008906093.9309615, -481217421.1123595, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026, -803888926.5304034], 'policy_light1_reward': [-5985393316.015743, -2232742797.701376, -6999309293.070458, -3927529684.1046934, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869, -5266820005.003068]}","{'mean_env_wait_ms': 12.800394953565783, 'mean_processing_ms': 3.046759235592345, 'mean_inference_ms': 1.8203267993382772}",{},0,340000,"{'sample_time_ms': 72182.466, 'sample_throughput': 55.415, 'learn_time_ms': 18533.396, 'learn_throughput': 215.827}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 72561084989440.0, 'policy_loss': -0.005816923949168995, 'vf_loss': 72561084989440.0, 'vf_explained_var': 5.2154064e-08, 'kl': 0.017630780988838524, 'entropy': 2.031896725296974, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 1358425644597248.0, 'policy_loss': 0.003433538367971778, 'vf_loss': 1358425644597248.0, 'vf_explained_var': 6.146729e-08, 'kl': 0.012800528216757812, 'entropy': -0.12183130800258368, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 340000, 'num_steps_trained': 340000}",False,133,85,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-46-27,1615769187,90.50617980957031,7576.7298040390015,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7576.7298040390015,0,85,"{'cpu_util_percent': 27.98425196850393, 'ram_util_percent': 57.39999999999996}"
170,85,MARL,gneJ12,-1315300483.4458,-17386949670.798218,-6230671192.900337,2527.39,2,-7498444298.009825,-218692055.75766248,-1061445958.4366566,{},"{'episode_reward': [-6468401173.607675, -8463359755.384176, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684, -6070708931.53347, -6936272776.055735, -2574613869.8970795], 'episode_lengths': [2224, 2870, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800, 2192, 2795, 2007], 'policy_gneJ12_reward': [-1134764913.3763525, -3282482001.8063774, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026, -803888926.5304034, -950879460.0400009, -341871072.1957007], 'policy_light1_reward': [-5333636260.231334, -5180877753.577805, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869, -5266820005.003068, -5985393316.015743, -2232742797.701376]}","{'mean_env_wait_ms': 12.798830613116925, 'mean_processing_ms': 3.049434675416145, 'mean_inference_ms': 1.8206000203255908}",{},0,344000,"{'sample_time_ms': 73268.488, 'sample_throughput': 54.594, 'learn_time_ms': 18545.158, 'learn_throughput': 215.69}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 861269340979200.0, 'policy_loss': 0.05096835867152549, 'vf_loss': 861269340979200.0, 'vf_explained_var': 3.3527613e-08, 'kl': 0.12963920331094414, 'entropy': 3.0975064262747765, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 1789006866022400.0, 'policy_loss': 0.0060905442805960774, 'vf_loss': 1789006866022400.0, 'vf_explained_var': 5.401671e-08, 'kl': 0.014743524632649496, 'entropy': 0.2788256206549704, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 344000, 'num_steps_trained': 344000}",False,135,86,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-48-01,1615769281,94.52787613868713,7671.257680177689,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7671.257680177689,0,86,"{'cpu_util_percent': 28.53533834586466, 'ram_util_percent': 57.39999999999999}"
171,85,MARL,light1,-1315300483.4458,-17386949670.798218,-6230671192.900337,2527.39,2,-9888505372.788342,-1096608427.68814,-5169225234.463678,{},"{'episode_reward': [-6468401173.607675, -8463359755.384176, -7212760323.329668, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684, -6070708931.53347, -6936272776.055735, -2574613869.8970795], 'episode_lengths': [2224, 2870, 2106, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800, 2192, 2795, 2007], 'policy_gneJ12_reward': [-1134764913.3763525, -3282482001.8063774, -682500657.0706915, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026, -803888926.5304034, -950879460.0400009, -341871072.1957007], 'policy_light1_reward': [-5333636260.231334, -5180877753.577805, -6530259666.258967, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869, -5266820005.003068, -5985393316.015743, -2232742797.701376]}","{'mean_env_wait_ms': 12.798830613116925, 'mean_processing_ms': 3.049434675416145, 'mean_inference_ms': 1.8206000203255908}",{},0,344000,"{'sample_time_ms': 73268.488, 'sample_throughput': 54.594, 'learn_time_ms': 18545.158, 'learn_throughput': 215.69}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 861269340979200.0, 'policy_loss': 0.05096835867152549, 'vf_loss': 861269340979200.0, 'vf_explained_var': 3.3527613e-08, 'kl': 0.12963920331094414, 'entropy': 3.0975064262747765, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 1789006866022400.0, 'policy_loss': 0.0060905442805960774, 'vf_loss': 1789006866022400.0, 'vf_explained_var': 5.401671e-08, 'kl': 0.014743524632649496, 'entropy': 0.2788256206549704, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 344000, 'num_steps_trained': 344000}",False,135,86,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-48-01,1615769281,94.52787613868713,7671.257680177689,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7671.257680177689,0,86,"{'cpu_util_percent': 28.53533834586466, 'ram_util_percent': 57.39999999999999}"
172,86,MARL,gneJ12,-1315300483.4458,-17386949670.798218,-6285559639.328783,2533.31,1,-7498444298.009825,-218692055.75766248,-1127784557.357402,{},"{'episode_reward': [-12701604966.174381, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684, -6070708931.53347, -6936272776.055735, -2574613869.8970795, -6468401173.607675, -8463359755.384176], 'episode_lengths': [2698, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800, 2192, 2795, 2007, 2224, 2870], 'policy_gneJ12_reward': [-7316360549.145228, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026, -803888926.5304034, -950879460.0400009, -341871072.1957007, -1134764913.3763525, -3282482001.8063774], 'policy_light1_reward': [-5385244417.029186, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869, -5266820005.003068, -5985393316.015743, -2232742797.701376, -5333636260.231334, -5180877753.577805]}","{'mean_env_wait_ms': 12.79853163614693, 'mean_processing_ms': 3.050356839652725, 'mean_inference_ms': 1.8207793950551312}",{},0,348000,"{'sample_time_ms': 73111.52, 'sample_throughput': 54.711, 'learn_time_ms': 18611.375, 'learn_throughput': 214.922}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 3.4171875000000003, 'cur_lr': 0.001, 'total_loss': 5475782042320896.0, 'policy_loss': -0.0050285479228477925, 'vf_loss': 5475782042320896.0, 'vf_explained_var': -1.4901161e-08, 'kl': 0.006901253313117195, 'entropy': 3.236610636115074, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 2916870638272512.0, 'policy_loss': 0.002330462302779779, 'vf_loss': 2916870638272512.0, 'vf_explained_var': -4.8428774e-08, 'kl': 0.01742295964504592, 'entropy': 0.3154363054782152, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 348000, 'num_steps_trained': 348000}",False,136,87,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-49-33,1615769373,91.29032611846924,7762.548006296158,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7762.548006296158,0,87,"{'cpu_util_percent': 30.31640625, 'ram_util_percent': 57.40156249999998}"
173,86,MARL,light1,-1315300483.4458,-17386949670.798218,-6285559639.328783,2533.31,1,-9888505372.788342,-1096608427.68814,-5157775081.97138,{},"{'episode_reward': [-12701604966.174381, -2287568433.3718023, -5490675236.930352, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684, -6070708931.53347, -6936272776.055735, -2574613869.8970795, -6468401173.607675, -8463359755.384176], 'episode_lengths': [2698, 2601, 2732, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800, 2192, 2795, 2007, 2224, 2870], 'policy_gneJ12_reward': [-7316360549.145228, -270216871.1150963, -710147585.8442818, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026, -803888926.5304034, -950879460.0400009, -341871072.1957007, -1134764913.3763525, -3282482001.8063774], 'policy_light1_reward': [-5385244417.029186, -2017351562.2567081, -4780527651.086061, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869, -5266820005.003068, -5985393316.015743, -2232742797.701376, -5333636260.231334, -5180877753.577805]}","{'mean_env_wait_ms': 12.79853163614693, 'mean_processing_ms': 3.050356839652725, 'mean_inference_ms': 1.8207793950551312}",{},0,348000,"{'sample_time_ms': 73111.52, 'sample_throughput': 54.711, 'learn_time_ms': 18611.375, 'learn_throughput': 214.922}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 3.4171875000000003, 'cur_lr': 0.001, 'total_loss': 5475782042320896.0, 'policy_loss': -0.0050285479228477925, 'vf_loss': 5475782042320896.0, 'vf_explained_var': -1.4901161e-08, 'kl': 0.006901253313117195, 'entropy': 3.236610636115074, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 2916870638272512.0, 'policy_loss': 0.002330462302779779, 'vf_loss': 2916870638272512.0, 'vf_explained_var': -4.8428774e-08, 'kl': 0.01742295964504592, 'entropy': 0.3154363054782152, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 348000, 'num_steps_trained': 348000}",False,136,87,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-49-33,1615769373,91.29032611846924,7762.548006296158,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7762.548006296158,0,87,"{'cpu_util_percent': 30.31640625, 'ram_util_percent': 57.40156249999998}"
174,87,MARL,gneJ12,-1315300483.4458,-17386949670.798218,-6420229833.245993,2534.89,2,-7498444298.009825,-218692055.75766248,-1185433713.211169,{},"{'episode_reward': [-12244819867.677149, -9000443194.345934, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684, -6070708931.53347, -6936272776.055735, -2574613869.8970795, -6468401173.607675, -8463359755.384176, -12701604966.174381], 'episode_lengths': [2919, 2572, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800, 2192, 2795, 2007, 2224, 2870, 2698], 'policy_gneJ12_reward': [-5176951539.625587, -1568328502.710477, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026, -803888926.5304034, -950879460.0400009, -341871072.1957007, -1134764913.3763525, -3282482001.8063774, -7316360549.145228], 'policy_light1_reward': [-7067868328.05152, -7432114691.635461, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869, -5266820005.003068, -5985393316.015743, -2232742797.701376, -5333636260.231334, -5180877753.577805, -5385244417.029186]}","{'mean_env_wait_ms': 12.798234880103493, 'mean_processing_ms': 3.0530065496537606, 'mean_inference_ms': 1.8211634181271992}",{},0,352000,"{'sample_time_ms': 73725.919, 'sample_throughput': 54.255, 'learn_time_ms': 18516.405, 'learn_throughput': 216.025}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 3.4171875000000003, 'cur_lr': 0.001, 'total_loss': 138341713444864.0, 'policy_loss': -0.008879859204171225, 'vf_loss': 138341713444864.0, 'vf_explained_var': 1.1175871e-08, 'kl': 0.004590482782077743, 'entropy': 3.440460316836834, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 2703168290947072.0, 'policy_loss': -0.0062498366460204124, 'vf_loss': 2703168290947072.0, 'vf_explained_var': -1.1175871e-07, 'kl': 0.01021087785193231, 'entropy': 0.20163246942684054, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 352000, 'num_steps_trained': 352000}",False,138,88,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-51-09,1615769469,96.40699124336243,7858.95499753952,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7858.95499753952,0,88,"{'cpu_util_percent': 28.6362962962963, 'ram_util_percent': 57.4}"
175,87,MARL,light1,-1315300483.4458,-17386949670.798218,-6420229833.245993,2534.89,2,-9888505372.788342,-1096608427.68814,-5234796120.034822,{},"{'episode_reward': [-12244819867.677149, -9000443194.345934, -6542269844.632774, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684, -6070708931.53347, -6936272776.055735, -2574613869.8970795, -6468401173.607675, -8463359755.384176, -12701604966.174381], 'episode_lengths': [2919, 2572, 2842, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800, 2192, 2795, 2007, 2224, 2870, 2698], 'policy_gneJ12_reward': [-5176951539.625587, -1568328502.710477, -932143681.752874, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026, -803888926.5304034, -950879460.0400009, -341871072.1957007, -1134764913.3763525, -3282482001.8063774, -7316360549.145228], 'policy_light1_reward': [-7067868328.05152, -7432114691.635461, -5610126162.879893, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869, -5266820005.003068, -5985393316.015743, -2232742797.701376, -5333636260.231334, -5180877753.577805, -5385244417.029186]}","{'mean_env_wait_ms': 12.798234880103493, 'mean_processing_ms': 3.0530065496537606, 'mean_inference_ms': 1.8211634181271992}",{},0,352000,"{'sample_time_ms': 73725.919, 'sample_throughput': 54.255, 'learn_time_ms': 18516.405, 'learn_throughput': 216.025}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 3.4171875000000003, 'cur_lr': 0.001, 'total_loss': 138341713444864.0, 'policy_loss': -0.008879859204171225, 'vf_loss': 138341713444864.0, 'vf_explained_var': 1.1175871e-08, 'kl': 0.004590482782077743, 'entropy': 3.440460316836834, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 2703168290947072.0, 'policy_loss': -0.0062498366460204124, 'vf_loss': 2703168290947072.0, 'vf_explained_var': -1.1175871e-07, 'kl': 0.01021087785193231, 'entropy': 0.20163246942684054, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 352000, 'num_steps_trained': 352000}",False,138,88,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-51-09,1615769469,96.40699124336243,7858.95499753952,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7858.95499753952,0,88,"{'cpu_util_percent': 28.6362962962963, 'ram_util_percent': 57.4}"
176,88,MARL,gneJ12,-1315300483.4458,-17386949670.798218,-6436874205.919299,2535.98,1,-7498444298.009825,-218692055.75766248,-1198768741.5662832,{},"{'episode_reward': [-8206707111.963317, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684, -6070708931.53347, -6936272776.055735, -2574613869.8970795, -6468401173.607675, -8463359755.384176, -12701604966.174381, -12244819867.677149, -9000443194.345934], 'episode_lengths': [2951, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800, 2192, 2795, 2007, 2224, 2870, 2698, 2919, 2572], 'policy_gneJ12_reward': [-2265646517.2642846, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026, -803888926.5304034, -950879460.0400009, -341871072.1957007, -1134764913.3763525, -3282482001.8063774, -7316360549.145228, -5176951539.625587, -1568328502.710477], 'policy_light1_reward': [-5941060594.699041, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869, -5266820005.003068, -5985393316.015743, -2232742797.701376, -5333636260.231334, -5180877753.577805, -5385244417.029186, -7067868328.05152, -7432114691.635461]}","{'mean_env_wait_ms': 12.798375026651756, 'mean_processing_ms': 3.054175361050334, 'mean_inference_ms': 1.8213994778078373}",{},0,356000,"{'sample_time_ms': 73244.647, 'sample_throughput': 54.611, 'learn_time_ms': 18426.437, 'learn_throughput': 217.079}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.7085937500000001, 'cur_lr': 0.001, 'total_loss': 320904312127488.0, 'policy_loss': -0.002421067008981481, 'vf_loss': 320904312127488.0, 'vf_explained_var': 3.3527613e-08, 'kl': 0.004123682119825389, 'entropy': 2.1937554702162743, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 1282339965501440.0, 'policy_loss': -0.0019308376358821988, 'vf_loss': 1282339965501440.0, 'vf_explained_var': -3.7252903e-09, 'kl': 0.013690933817997575, 'entropy': -0.14091630923212506, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 356000, 'num_steps_trained': 356000}",False,139,89,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-52-38,1615769558,88.08474707603455,7947.039744615555,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7947.039744615555,0,89,"{'cpu_util_percent': 30.350819672131145, 'ram_util_percent': 57.30327868852458}"
177,88,MARL,light1,-1315300483.4458,-17386949670.798218,-6436874205.919299,2535.98,1,-9888505372.788342,-1096608427.68814,-5238105464.353014,{},"{'episode_reward': [-8206707111.963317, -10602061004.74721, -10313932954.367785, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684, -6070708931.53347, -6936272776.055735, -2574613869.8970795, -6468401173.607675, -8463359755.384176, -12701604966.174381, -12244819867.677149, -9000443194.345934], 'episode_lengths': [2951, 3128, 2511, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800, 2192, 2795, 2007, 2224, 2870, 2698, 2919, 2572], 'policy_gneJ12_reward': [-2265646517.2642846, -1279569151.959923, -2996742419.548364, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026, -803888926.5304034, -950879460.0400009, -341871072.1957007, -1134764913.3763525, -3282482001.8063774, -7316360549.145228, -5176951539.625587, -1568328502.710477], 'policy_light1_reward': [-5941060594.699041, -9322491852.787256, -7317190534.819452, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869, -5266820005.003068, -5985393316.015743, -2232742797.701376, -5333636260.231334, -5180877753.577805, -5385244417.029186, -7067868328.05152, -7432114691.635461]}","{'mean_env_wait_ms': 12.798375026651756, 'mean_processing_ms': 3.054175361050334, 'mean_inference_ms': 1.8213994778078373}",{},0,356000,"{'sample_time_ms': 73244.647, 'sample_throughput': 54.611, 'learn_time_ms': 18426.437, 'learn_throughput': 217.079}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.7085937500000001, 'cur_lr': 0.001, 'total_loss': 320904312127488.0, 'policy_loss': -0.002421067008981481, 'vf_loss': 320904312127488.0, 'vf_explained_var': 3.3527613e-08, 'kl': 0.004123682119825389, 'entropy': 2.1937554702162743, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 1282339965501440.0, 'policy_loss': -0.0019308376358821988, 'vf_loss': 1282339965501440.0, 'vf_explained_var': -3.7252903e-09, 'kl': 0.013690933817997575, 'entropy': -0.14091630923212506, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 356000, 'num_steps_trained': 356000}",False,139,89,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-52-38,1615769558,88.08474707603455,7947.039744615555,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7947.039744615555,0,89,"{'cpu_util_percent': 30.350819672131145, 'ram_util_percent': 57.30327868852458}"
178,89,MARL,gneJ12,-1315300483.4458,-17386949670.798218,-6269593232.064938,2532.28,2,-7498444298.009825,-165400704.76507056,-1160775941.9486432,{},"{'episode_reward': [-1659633049.9500484, -2528263523.7289243, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684, -6070708931.53347, -6936272776.055735, -2574613869.8970795, -6468401173.607675, -8463359755.384176, -12701604966.174381, -12244819867.677149, -9000443194.345934, -8206707111.963317], 'episode_lengths': [2703, 2566, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800, 2192, 2795, 2007, 2224, 2870, 2698, 2919, 2572, 2951], 'policy_gneJ12_reward': [-165400704.76507056, -311630904.97922, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026, -803888926.5304034, -950879460.0400009, -341871072.1957007, -1134764913.3763525, -3282482001.8063774, -7316360549.145228, -5176951539.625587, -1568328502.710477, -2265646517.2642846], 'policy_light1_reward': [-1494232345.1849825, -2216632618.749702, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869, -5266820005.003068, -5985393316.015743, -2232742797.701376, -5333636260.231334, -5180877753.577805, -5385244417.029186, -7067868328.05152, -7432114691.635461, -5941060594.699041]}","{'mean_env_wait_ms': 12.798434470689973, 'mean_processing_ms': 3.0569438477348494, 'mean_inference_ms': 1.8218678634979337}",{},0,360000,"{'sample_time_ms': 73664.227, 'sample_throughput': 54.3, 'learn_time_ms': 18407.394, 'learn_throughput': 217.304}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.8542968750000001, 'cur_lr': 0.001, 'total_loss': 12865831518208.0, 'policy_loss': -0.010435051779495552, 'vf_loss': 12865831518208.0, 'vf_explained_var': -7.4505806e-08, 'kl': 0.014318744273623452, 'entropy': 1.085559993982315, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 442196951564288.0, 'policy_loss': -0.002399885735940188, 'vf_loss': 442196951564288.0, 'vf_explained_var': 3.3527613e-08, 'kl': 0.014717924786964431, 'entropy': -0.5891568744555116, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 360000, 'num_steps_trained': 360000}",False,141,90,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-54-10,1615769650,92.03505682945251,8039.074801445007,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8039.074801445007,0,90,"{'cpu_util_percent': 35.26, 'ram_util_percent': 57.381538461538454}"
179,89,MARL,light1,-1315300483.4458,-17386949670.798218,-6269593232.064938,2532.28,2,-9888505372.788342,-1096608427.68814,-5108817290.116293,{},"{'episode_reward': [-1659633049.9500484, -2528263523.7289243, -5180868915.47109, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684, -6070708931.53347, -6936272776.055735, -2574613869.8970795, -6468401173.607675, -8463359755.384176, -12701604966.174381, -12244819867.677149, -9000443194.345934, -8206707111.963317], 'episode_lengths': [2703, 2566, 3068, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800, 2192, 2795, 2007, 2224, 2870, 2698, 2919, 2572, 2951], 'policy_gneJ12_reward': [-165400704.76507056, -311630904.97922, -630981800.8720468, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026, -803888926.5304034, -950879460.0400009, -341871072.1957007, -1134764913.3763525, -3282482001.8063774, -7316360549.145228, -5176951539.625587, -1568328502.710477, -2265646517.2642846], 'policy_light1_reward': [-1494232345.1849825, -2216632618.749702, -4549887114.599059, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869, -5266820005.003068, -5985393316.015743, -2232742797.701376, -5333636260.231334, -5180877753.577805, -5385244417.029186, -7067868328.05152, -7432114691.635461, -5941060594.699041]}","{'mean_env_wait_ms': 12.798434470689973, 'mean_processing_ms': 3.0569438477348494, 'mean_inference_ms': 1.8218678634979337}",{},0,360000,"{'sample_time_ms': 73664.227, 'sample_throughput': 54.3, 'learn_time_ms': 18407.394, 'learn_throughput': 217.304}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.8542968750000001, 'cur_lr': 0.001, 'total_loss': 12865831518208.0, 'policy_loss': -0.010435051779495552, 'vf_loss': 12865831518208.0, 'vf_explained_var': -7.4505806e-08, 'kl': 0.014318744273623452, 'entropy': 1.085559993982315, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 442196951564288.0, 'policy_loss': -0.002399885735940188, 'vf_loss': 442196951564288.0, 'vf_explained_var': 3.3527613e-08, 'kl': 0.014717924786964431, 'entropy': -0.5891568744555116, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 360000, 'num_steps_trained': 360000}",False,141,90,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-54-10,1615769650,92.03505682945251,8039.074801445007,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8039.074801445007,0,90,"{'cpu_util_percent': 35.26, 'ram_util_percent': 57.381538461538454}"
180,90,MARL,gneJ12,-1315300483.4458,-17386949670.798218,-6293683768.528887,2531.27,1,-7498444298.009825,-165400704.76507056,-1165189812.6167371,{},"{'episode_reward': [-7589922561.865974, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684, -6070708931.53347, -6936272776.055735, -2574613869.8970795, -6468401173.607675, -8463359755.384176, -12701604966.174381, -12244819867.677149, -9000443194.345934, -8206707111.963317, -1659633049.9500484, -2528263523.7289243], 'episode_lengths': [2967, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800, 2192, 2795, 2007, 2224, 2870, 2698, 2919, 2572, 2951, 2703, 2566], 'policy_gneJ12_reward': [-1072368867.6814501, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026, -803888926.5304034, -950879460.0400009, -341871072.1957007, -1134764913.3763525, -3282482001.8063774, -7316360549.145228, -5176951539.625587, -1568328502.710477, -2265646517.2642846, -165400704.76507056, -311630904.97922], 'policy_light1_reward': [-6517553694.184532, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869, -5266820005.003068, -5985393316.015743, -2232742797.701376, -5333636260.231334, -5180877753.577805, -5385244417.029186, -7067868328.05152, -7432114691.635461, -5941060594.699041, -1494232345.1849825, -2216632618.749702]}","{'mean_env_wait_ms': 12.798194220628497, 'mean_processing_ms': 3.058716201165804, 'mean_inference_ms': 1.82204169209212}",{},0,364000,"{'sample_time_ms': 73057.87, 'sample_throughput': 54.751, 'learn_time_ms': 18497.199, 'learn_throughput': 216.249}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.8542968750000001, 'cur_lr': 0.001, 'total_loss': 89813080604672.0, 'policy_loss': 0.0024436708772554994, 'vf_loss': 89813080604672.0, 'vf_explained_var': -1.0058284e-07, 'kl': 0.020201321196509525, 'entropy': 2.6849792897701263, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 1930899121766400.0, 'policy_loss': -0.002331517549464479, 'vf_loss': 1930899121766400.0, 'vf_explained_var': 5.7742e-08, 'kl': 0.009745789211592637, 'entropy': 0.1715713059529662, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 364000, 'num_steps_trained': 364000}",False,142,91,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-55-36,1615769736,86.4691412448883,8125.543942689896,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8125.543942689896,0,91,"{'cpu_util_percent': 32.95619834710744, 'ram_util_percent': 57.38595041322313}"
181,90,MARL,light1,-1315300483.4458,-17386949670.798218,-6293683768.528887,2531.27,1,-9888505372.788342,-1096608427.68814,-5128493955.912148,{},"{'episode_reward': [-7589922561.865974, -10675583017.318611, -10106033804.366896, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684, -6070708931.53347, -6936272776.055735, -2574613869.8970795, -6468401173.607675, -8463359755.384176, -12701604966.174381, -12244819867.677149, -9000443194.345934, -8206707111.963317, -1659633049.9500484, -2528263523.7289243], 'episode_lengths': [2967, 3090, 3088, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800, 2192, 2795, 2007, 2224, 2870, 2698, 2919, 2572, 2951, 2703, 2566], 'policy_gneJ12_reward': [-1072368867.6814501, -1563238388.204147, -1412664541.3594642, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026, -803888926.5304034, -950879460.0400009, -341871072.1957007, -1134764913.3763525, -3282482001.8063774, -7316360549.145228, -5176951539.625587, -1568328502.710477, -2265646517.2642846, -165400704.76507056, -311630904.97922], 'policy_light1_reward': [-6517553694.184532, -9112344629.114471, -8693369263.007433, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869, -5266820005.003068, -5985393316.015743, -2232742797.701376, -5333636260.231334, -5180877753.577805, -5385244417.029186, -7067868328.05152, -7432114691.635461, -5941060594.699041, -1494232345.1849825, -2216632618.749702]}","{'mean_env_wait_ms': 12.798194220628497, 'mean_processing_ms': 3.058716201165804, 'mean_inference_ms': 1.82204169209212}",{},0,364000,"{'sample_time_ms': 73057.87, 'sample_throughput': 54.751, 'learn_time_ms': 18497.199, 'learn_throughput': 216.249}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.8542968750000001, 'cur_lr': 0.001, 'total_loss': 89813080604672.0, 'policy_loss': 0.0024436708772554994, 'vf_loss': 89813080604672.0, 'vf_explained_var': -1.0058284e-07, 'kl': 0.020201321196509525, 'entropy': 2.6849792897701263, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 1930899121766400.0, 'policy_loss': -0.002331517549464479, 'vf_loss': 1930899121766400.0, 'vf_explained_var': 5.7742e-08, 'kl': 0.009745789211592637, 'entropy': 0.1715713059529662, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 364000, 'num_steps_trained': 364000}",False,142,91,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-55-36,1615769736,86.4691412448883,8125.543942689896,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8125.543942689896,0,91,"{'cpu_util_percent': 32.95619834710744, 'ram_util_percent': 57.38595041322313}"
182,91,MARL,gneJ12,-1315300483.4458,-17386949670.798218,-6209794514.346457,2515.86,2,-7498444298.009825,-165400704.76507056,-1154075168.1595056,{},"{'episode_reward': [-6057734575.553119, -6334956827.889362, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684, -6070708931.53347, -6936272776.055735, -2574613869.8970795, -6468401173.607675, -8463359755.384176, -12701604966.174381, -12244819867.677149, -9000443194.345934, -8206707111.963317, -1659633049.9500484, -2528263523.7289243, -7589922561.865974], 'episode_lengths': [2313, 2324, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800, 2192, 2795, 2007, 2224, 2870, 2698, 2919, 2572, 2951, 2703, 2566, 2967], 'policy_gneJ12_reward': [-1148384911.8856974, -716053571.9547592, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026, -803888926.5304034, -950879460.0400009, -341871072.1957007, -1134764913.3763525, -3282482001.8063774, -7316360549.145228, -5176951539.625587, -1568328502.710477, -2265646517.2642846, -165400704.76507056, -311630904.97922, -1072368867.6814501], 'policy_light1_reward': [-4909349663.667417, -5618903255.934609, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869, -5266820005.003068, -5985393316.015743, -2232742797.701376, -5333636260.231334, -5180877753.577805, -5385244417.029186, -7067868328.05152, -7432114691.635461, -5941060594.699041, -1494232345.1849825, -2216632618.749702, -6517553694.184532]}","{'mean_env_wait_ms': 12.797979301437836, 'mean_processing_ms': 3.061838751683091, 'mean_inference_ms': 1.8224484564219623}",{},0,368000,"{'sample_time_ms': 73592.76, 'sample_throughput': 54.353, 'learn_time_ms': 18416.526, 'learn_throughput': 217.196}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.2814453125, 'cur_lr': 0.001, 'total_loss': 77606662176768.0, 'policy_loss': -0.011200925684534013, 'vf_loss': 77606662176768.0, 'vf_explained_var': -5.2154064e-08, 'kl': 0.013119940966134891, 'entropy': 2.425977274775505, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 2299683317743616.0, 'policy_loss': -0.0012516324350144714, 'vf_loss': 2299683317743616.0, 'vf_explained_var': -5.2154064e-08, 'kl': 0.013057856071100105, 'entropy': 0.000981187477009371, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 368000, 'num_steps_trained': 368000}",False,144,92,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-57-11,1615769831,94.98975896835327,8220.533701658249,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8220.533701658249,0,92,"{'cpu_util_percent': 34.950746268656715, 'ram_util_percent': 57.399253731343286}"
183,91,MARL,light1,-1315300483.4458,-17386949670.798218,-6209794514.346457,2515.86,2,-9888505372.788342,-1096608427.68814,-5055719346.18695,{},"{'episode_reward': [-6057734575.553119, -6334956827.889362, -12582654784.8202, -8689720559.73726, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684, -6070708931.53347, -6936272776.055735, -2574613869.8970795, -6468401173.607675, -8463359755.384176, -12701604966.174381, -12244819867.677149, -9000443194.345934, -8206707111.963317, -1659633049.9500484, -2528263523.7289243, -7589922561.865974], 'episode_lengths': [2313, 2324, 2763, 2721, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800, 2192, 2795, 2007, 2224, 2870, 2698, 2919, 2572, 2951, 2703, 2566, 2967], 'policy_gneJ12_reward': [-1148384911.8856974, -716053571.9547592, -5872389740.863124, -1373004258.7797358, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026, -803888926.5304034, -950879460.0400009, -341871072.1957007, -1134764913.3763525, -3282482001.8063774, -7316360549.145228, -5176951539.625587, -1568328502.710477, -2265646517.2642846, -165400704.76507056, -311630904.97922, -1072368867.6814501], 'policy_light1_reward': [-4909349663.667417, -5618903255.934609, -6710265043.957095, -7316716300.9575, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869, -5266820005.003068, -5985393316.015743, -2232742797.701376, -5333636260.231334, -5180877753.577805, -5385244417.029186, -7067868328.05152, -7432114691.635461, -5941060594.699041, -1494232345.1849825, -2216632618.749702, -6517553694.184532]}","{'mean_env_wait_ms': 12.797979301437836, 'mean_processing_ms': 3.061838751683091, 'mean_inference_ms': 1.8224484564219623}",{},0,368000,"{'sample_time_ms': 73592.76, 'sample_throughput': 54.353, 'learn_time_ms': 18416.526, 'learn_throughput': 217.196}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.2814453125, 'cur_lr': 0.001, 'total_loss': 77606662176768.0, 'policy_loss': -0.011200925684534013, 'vf_loss': 77606662176768.0, 'vf_explained_var': -5.2154064e-08, 'kl': 0.013119940966134891, 'entropy': 2.425977274775505, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 2299683317743616.0, 'policy_loss': -0.0012516324350144714, 'vf_loss': 2299683317743616.0, 'vf_explained_var': -5.2154064e-08, 'kl': 0.013057856071100105, 'entropy': 0.000981187477009371, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 368000, 'num_steps_trained': 368000}",False,144,92,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-57-11,1615769831,94.98975896835327,8220.533701658249,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8220.533701658249,0,92,"{'cpu_util_percent': 34.950746268656715, 'ram_util_percent': 57.399253731343286}"
184,92,MARL,gneJ12,-1315300483.4458,-17386949670.798218,-6094643694.871978,2506.31,2,-7498444298.009825,-165400704.76507056,-1094975029.28839,{},"{'episode_reward': [-5136317389.903228, -4620976007.206353, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684, -6070708931.53347, -6936272776.055735, -2574613869.8970795, -6468401173.607675, -8463359755.384176, -12701604966.174381, -12244819867.677149, -9000443194.345934, -8206707111.963317, -1659633049.9500484, -2528263523.7289243, -7589922561.865974, -6057734575.553119, -6334956827.889362], 'episode_lengths': [1830, 2699, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800, 2192, 2795, 2007, 2224, 2870, 2698, 2919, 2572, 2951, 2703, 2566, 2967, 2313, 2324], 'policy_gneJ12_reward': [-793789030.2022485, -541591082.3290467, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026, -803888926.5304034, -950879460.0400009, -341871072.1957007, -1134764913.3763525, -3282482001.8063774, -7316360549.145228, -5176951539.625587, -1568328502.710477, -2265646517.2642846, -165400704.76507056, -311630904.97922, -1072368867.6814501, -1148384911.8856974, -716053571.9547592], 'policy_light1_reward': [-4342528359.700975, -4079384924.8773026, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869, -5266820005.003068, -5985393316.015743, -2232742797.701376, -5333636260.231334, -5180877753.577805, -5385244417.029186, -7067868328.05152, -7432114691.635461, -5941060594.699041, -1494232345.1849825, -2216632618.749702, -6517553694.184532, -4909349663.667417, -5618903255.934609]}","{'mean_env_wait_ms': 12.797738130519479, 'mean_processing_ms': 3.066554866397581, 'mean_inference_ms': 1.8229496048914315}",{},0,372000,"{'sample_time_ms': 73917.298, 'sample_throughput': 54.115, 'learn_time_ms': 18387.771, 'learn_throughput': 217.536}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.2814453125, 'cur_lr': 0.001, 'total_loss': 49754856226816.0, 'policy_loss': -0.018320715869776905, 'vf_loss': 49754856226816.0, 'vf_explained_var': -8.940697e-08, 'kl': 0.011199068030691706, 'entropy': 1.9809390343725681, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 1359996201730048.0, 'policy_loss': -0.00038965666317380965, 'vf_loss': 1359996201730048.0, 'vf_explained_var': -1.8626451e-08, 'kl': 0.014817655537626706, 'entropy': -0.23713510390371084, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 372000, 'num_steps_trained': 372000}",False,146,93,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-58-55,1615769935,103.25374722480774,8323.787448883057,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8323.787448883057,0,93,"{'cpu_util_percent': 34.97986111111111, 'ram_util_percent': 57.18819444444445}"
185,92,MARL,light1,-1315300483.4458,-17386949670.798218,-6094643694.871978,2506.31,2,-9888505372.788342,-1096608427.68814,-4999668665.583587,{},"{'episode_reward': [-5136317389.903228, -4620976007.206353, -2906023956.7307343, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684, -6070708931.53347, -6936272776.055735, -2574613869.8970795, -6468401173.607675, -8463359755.384176, -12701604966.174381, -12244819867.677149, -9000443194.345934, -8206707111.963317, -1659633049.9500484, -2528263523.7289243, -7589922561.865974, -6057734575.553119, -6334956827.889362], 'episode_lengths': [1830, 2699, 2835, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800, 2192, 2795, 2007, 2224, 2870, 2698, 2919, 2572, 2951, 2703, 2566, 2967, 2313, 2324], 'policy_gneJ12_reward': [-793789030.2022485, -541591082.3290467, -404527018.33733475, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026, -803888926.5304034, -950879460.0400009, -341871072.1957007, -1134764913.3763525, -3282482001.8063774, -7316360549.145228, -5176951539.625587, -1568328502.710477, -2265646517.2642846, -165400704.76507056, -311630904.97922, -1072368867.6814501, -1148384911.8856974, -716053571.9547592], 'policy_light1_reward': [-4342528359.700975, -4079384924.8773026, -2501496938.393397, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869, -5266820005.003068, -5985393316.015743, -2232742797.701376, -5333636260.231334, -5180877753.577805, -5385244417.029186, -7067868328.05152, -7432114691.635461, -5941060594.699041, -1494232345.1849825, -2216632618.749702, -6517553694.184532, -4909349663.667417, -5618903255.934609]}","{'mean_env_wait_ms': 12.797738130519479, 'mean_processing_ms': 3.066554866397581, 'mean_inference_ms': 1.8229496048914315}",{},0,372000,"{'sample_time_ms': 73917.298, 'sample_throughput': 54.115, 'learn_time_ms': 18387.771, 'learn_throughput': 217.536}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.2814453125, 'cur_lr': 0.001, 'total_loss': 49754856226816.0, 'policy_loss': -0.018320715869776905, 'vf_loss': 49754856226816.0, 'vf_explained_var': -8.940697e-08, 'kl': 0.011199068030691706, 'entropy': 1.9809390343725681, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 1359996201730048.0, 'policy_loss': -0.00038965666317380965, 'vf_loss': 1359996201730048.0, 'vf_explained_var': -1.8626451e-08, 'kl': 0.014817655537626706, 'entropy': -0.23713510390371084, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 372000, 'num_steps_trained': 372000}",False,146,93,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_20-58-55,1615769935,103.25374722480774,8323.787448883057,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8323.787448883057,0,93,"{'cpu_util_percent': 34.97986111111111, 'ram_util_percent': 57.18819444444445}"
186,93,MARL,gneJ12,-1315300483.4458,-17386949670.798218,-6108835852.506954,2507.57,1,-7498444298.009825,-165400704.76507056,-1096350099.8270543,{},"{'episode_reward': [-4325239720.228492, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684, -6070708931.53347, -6936272776.055735, -2574613869.8970795, -6468401173.607675, -8463359755.384176, -12701604966.174381, -12244819867.677149, -9000443194.345934, -8206707111.963317, -1659633049.9500484, -2528263523.7289243, -7589922561.865974, -6057734575.553119, -6334956827.889362, -5136317389.903228, -4620976007.206353], 'episode_lengths': [2961, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800, 2192, 2795, 2007, 2224, 2870, 2698, 2919, 2572, 2951, 2703, 2566, 2967, 2313, 2324, 1830, 2699], 'policy_gneJ12_reward': [-542034072.2037843, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026, -803888926.5304034, -950879460.0400009, -341871072.1957007, -1134764913.3763525, -3282482001.8063774, -7316360549.145228, -5176951539.625587, -1568328502.710477, -2265646517.2642846, -165400704.76507056, -311630904.97922, -1072368867.6814501, -1148384911.8856974, -716053571.9547592, -793789030.2022485, -541591082.3290467], 'policy_light1_reward': [-3783205648.024708, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869, -5266820005.003068, -5985393316.015743, -2232742797.701376, -5333636260.231334, -5180877753.577805, -5385244417.029186, -7067868328.05152, -7432114691.635461, -5941060594.699041, -1494232345.1849825, -2216632618.749702, -6517553694.184532, -4909349663.667417, -5618903255.934609, -4342528359.700975, -4079384924.8773026]}","{'mean_env_wait_ms': 12.797961722542446, 'mean_processing_ms': 3.068735455794108, 'mean_inference_ms': 1.823241174065324}",{},0,376000,"{'sample_time_ms': 73968.559, 'sample_throughput': 54.077, 'learn_time_ms': 18571.261, 'learn_throughput': 215.387}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.2814453125, 'cur_lr': 0.001, 'total_loss': 61694013210624.0, 'policy_loss': -0.00372575776418671, 'vf_loss': 61694013210624.0, 'vf_explained_var': 3.7252903e-09, 'kl': 0.019934101408580318, 'entropy': 1.9574716910719872, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 1356651294621696.0, 'policy_loss': 0.0011142650910187513, 'vf_loss': 1356651294621696.0, 'vf_explained_var': 7.450581e-09, 'kl': 0.0155711367551703, 'entropy': -0.2572820873465389, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 376000, 'num_steps_trained': 376000}",False,147,94,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_21-00-23,1615770023,87.83894515037537,8411.626394033432,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8411.626394033432,0,94,"{'cpu_util_percent': 37.54112903225807, 'ram_util_percent': 57.16129032258065}"
187,93,MARL,light1,-1315300483.4458,-17386949670.798218,-6108835852.506954,2507.57,1,-9888505372.788342,-1096608427.68814,-5012485752.6799,{},"{'episode_reward': [-4325239720.228492, -5309835384.609116, -3956244703.418989, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684, -6070708931.53347, -6936272776.055735, -2574613869.8970795, -6468401173.607675, -8463359755.384176, -12701604966.174381, -12244819867.677149, -9000443194.345934, -8206707111.963317, -1659633049.9500484, -2528263523.7289243, -7589922561.865974, -6057734575.553119, -6334956827.889362, -5136317389.903228, -4620976007.206353], 'episode_lengths': [2961, 2694, 3126, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800, 2192, 2795, 2007, 2224, 2870, 2698, 2919, 2572, 2951, 2703, 2566, 2967, 2313, 2324, 1830, 2699], 'policy_gneJ12_reward': [-542034072.2037843, -707007135.5143712, -468707530.3378017, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026, -803888926.5304034, -950879460.0400009, -341871072.1957007, -1134764913.3763525, -3282482001.8063774, -7316360549.145228, -5176951539.625587, -1568328502.710477, -2265646517.2642846, -165400704.76507056, -311630904.97922, -1072368867.6814501, -1148384911.8856974, -716053571.9547592, -793789030.2022485, -541591082.3290467], 'policy_light1_reward': [-3783205648.024708, -4602828249.094738, -3487537173.081193, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869, -5266820005.003068, -5985393316.015743, -2232742797.701376, -5333636260.231334, -5180877753.577805, -5385244417.029186, -7067868328.05152, -7432114691.635461, -5941060594.699041, -1494232345.1849825, -2216632618.749702, -6517553694.184532, -4909349663.667417, -5618903255.934609, -4342528359.700975, -4079384924.8773026]}","{'mean_env_wait_ms': 12.797961722542446, 'mean_processing_ms': 3.068735455794108, 'mean_inference_ms': 1.823241174065324}",{},0,376000,"{'sample_time_ms': 73968.559, 'sample_throughput': 54.077, 'learn_time_ms': 18571.261, 'learn_throughput': 215.387}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.2814453125, 'cur_lr': 0.001, 'total_loss': 61694013210624.0, 'policy_loss': -0.00372575776418671, 'vf_loss': 61694013210624.0, 'vf_explained_var': 3.7252903e-09, 'kl': 0.019934101408580318, 'entropy': 1.9574716910719872, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 1356651294621696.0, 'policy_loss': 0.0011142650910187513, 'vf_loss': 1356651294621696.0, 'vf_explained_var': 7.450581e-09, 'kl': 0.0155711367551703, 'entropy': -0.2572820873465389, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 376000, 'num_steps_trained': 376000}",False,147,94,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_21-00-23,1615770023,87.83894515037537,8411.626394033432,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8411.626394033432,0,94,"{'cpu_util_percent': 37.54112903225807, 'ram_util_percent': 57.16129032258065}"
188,94,MARL,gneJ12,-1315300483.4458,-17386949670.798218,-6113154375.423668,2493.41,2,-7498444298.009825,-165400704.76507056,-1098642816.7542455,{},"{'episode_reward': [-6873245446.505015, -2824686933.1944485, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684, -6070708931.53347, -6936272776.055735, -2574613869.8970795, -6468401173.607675, -8463359755.384176, -12701604966.174381, -12244819867.677149, -9000443194.345934, -8206707111.963317, -1659633049.9500484, -2528263523.7289243, -7589922561.865974, -6057734575.553119, -6334956827.889362, -5136317389.903228, -4620976007.206353, -4325239720.228492], 'episode_lengths': [2343, 2061, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800, 2192, 2795, 2007, 2224, 2870, 2698, 2919, 2572, 2951, 2703, 2566, 2967, 2313, 2324, 1830, 2699, 2961], 'policy_gneJ12_reward': [-1102344567.9870872, -302641790.5841828, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026, -803888926.5304034, -950879460.0400009, -341871072.1957007, -1134764913.3763525, -3282482001.8063774, -7316360549.145228, -5176951539.625587, -1568328502.710477, -2265646517.2642846, -165400704.76507056, -311630904.97922, -1072368867.6814501, -1148384911.8856974, -716053571.9547592, -793789030.2022485, -541591082.3290467, -542034072.2037843], 'policy_light1_reward': [-5770900878.517931, -2522045142.6102686, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869, -5266820005.003068, -5985393316.015743, -2232742797.701376, -5333636260.231334, -5180877753.577805, -5385244417.029186, -7067868328.05152, -7432114691.635461, -5941060594.699041, -1494232345.1849825, -2216632618.749702, -6517553694.184532, -4909349663.667417, -5618903255.934609, -4342528359.700975, -4079384924.8773026, -3783205648.024708]}","{'mean_env_wait_ms': 12.798550303437269, 'mean_processing_ms': 3.0735583708885175, 'mean_inference_ms': 1.8238318017338713}",{},0,380000,"{'sample_time_ms': 74446.171, 'sample_throughput': 53.73, 'learn_time_ms': 18586.03, 'learn_throughput': 215.215}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.2814453125, 'cur_lr': 0.001, 'total_loss': 40752636887040.0, 'policy_loss': -0.0074600522057153285, 'vf_loss': 40752636887040.0, 'vf_explained_var': -1.4901161e-08, 'kl': 0.009565391344949603, 'entropy': 1.8121662959456444, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 1050747160494080.0, 'policy_loss': -0.0034559838532004505, 'vf_loss': 1050747160494080.0, 'vf_explained_var': 2.2351742e-08, 'kl': 0.013820307736750692, 'entropy': -0.31376865482889116, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 380000, 'num_steps_trained': 380000}",False,149,95,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_21-01-59,1615770119,95.43012714385986,8507.056521177292,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8507.056521177292,0,95,"{'cpu_util_percent': 34.25373134328358, 'ram_util_percent': 56.80597014925373}"
189,94,MARL,light1,-1315300483.4458,-17386949670.798218,-6113154375.423668,2493.41,2,-9888505372.788342,-1096608427.68814,-5014511558.669423,{},"{'episode_reward': [-6873245446.505015, -2824686933.1944485, -2723529552.565318, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684, -6070708931.53347, -6936272776.055735, -2574613869.8970795, -6468401173.607675, -8463359755.384176, -12701604966.174381, -12244819867.677149, -9000443194.345934, -8206707111.963317, -1659633049.9500484, -2528263523.7289243, -7589922561.865974, -6057734575.553119, -6334956827.889362, -5136317389.903228, -4620976007.206353, -4325239720.228492], 'episode_lengths': [2343, 2061, 2717, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800, 2192, 2795, 2007, 2224, 2870, 2698, 2919, 2572, 2951, 2703, 2566, 2967, 2313, 2324, 1830, 2699, 2961], 'policy_gneJ12_reward': [-1102344567.9870872, -302641790.5841828, -362090789.8832875, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026, -803888926.5304034, -950879460.0400009, -341871072.1957007, -1134764913.3763525, -3282482001.8063774, -7316360549.145228, -5176951539.625587, -1568328502.710477, -2265646517.2642846, -165400704.76507056, -311630904.97922, -1072368867.6814501, -1148384911.8856974, -716053571.9547592, -793789030.2022485, -541591082.3290467, -542034072.2037843], 'policy_light1_reward': [-5770900878.517931, -2522045142.6102686, -2361438762.6820273, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869, -5266820005.003068, -5985393316.015743, -2232742797.701376, -5333636260.231334, -5180877753.577805, -5385244417.029186, -7067868328.05152, -7432114691.635461, -5941060594.699041, -1494232345.1849825, -2216632618.749702, -6517553694.184532, -4909349663.667417, -5618903255.934609, -4342528359.700975, -4079384924.8773026, -3783205648.024708]}","{'mean_env_wait_ms': 12.798550303437269, 'mean_processing_ms': 3.0735583708885175, 'mean_inference_ms': 1.8238318017338713}",{},0,380000,"{'sample_time_ms': 74446.171, 'sample_throughput': 53.73, 'learn_time_ms': 18586.03, 'learn_throughput': 215.215}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.2814453125, 'cur_lr': 0.001, 'total_loss': 40752636887040.0, 'policy_loss': -0.0074600522057153285, 'vf_loss': 40752636887040.0, 'vf_explained_var': -1.4901161e-08, 'kl': 0.009565391344949603, 'entropy': 1.8121662959456444, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 1050747160494080.0, 'policy_loss': -0.0034559838532004505, 'vf_loss': 1050747160494080.0, 'vf_explained_var': 2.2351742e-08, 'kl': 0.013820307736750692, 'entropy': -0.31376865482889116, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 380000, 'num_steps_trained': 380000}",False,149,95,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_21-01-59,1615770119,95.43012714385986,8507.056521177292,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8507.056521177292,0,95,"{'cpu_util_percent': 34.25373134328358, 'ram_util_percent': 56.80597014925373}"
190,95,MARL,gneJ12,-1315300483.4458,-17386949670.798218,-6109250780.213973,2490.25,1,-7498444298.009825,-165400704.76507056,-1098590564.4178631,{},"{'episode_reward': [-2333170031.5958014, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684, -6070708931.53347, -6936272776.055735, -2574613869.8970795, -6468401173.607675, -8463359755.384176, -12701604966.174381, -12244819867.677149, -9000443194.345934, -8206707111.963317, -1659633049.9500484, -2528263523.7289243, -7589922561.865974, -6057734575.553119, -6334956827.889362, -5136317389.903228, -4620976007.206353, -4325239720.228492, -6873245446.505015, -2824686933.1944485], 'episode_lengths': [2401, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800, 2192, 2795, 2007, 2224, 2870, 2698, 2919, 2572, 2951, 2703, 2566, 2967, 2313, 2324, 1830, 2699, 2961, 2343, 2061], 'policy_gneJ12_reward': [-356865556.24507093, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026, -803888926.5304034, -950879460.0400009, -341871072.1957007, -1134764913.3763525, -3282482001.8063774, -7316360549.145228, -5176951539.625587, -1568328502.710477, -2265646517.2642846, -165400704.76507056, -311630904.97922, -1072368867.6814501, -1148384911.8856974, -716053571.9547592, -793789030.2022485, -541591082.3290467, -542034072.2037843, -1102344567.9870872, -302641790.5841828], 'policy_light1_reward': [-1976304475.3507335, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869, -5266820005.003068, -5985393316.015743, -2232742797.701376, -5333636260.231334, -5180877753.577805, -5385244417.029186, -7067868328.05152, -7432114691.635461, -5941060594.699041, -1494232345.1849825, -2216632618.749702, -6517553694.184532, -4909349663.667417, -5618903255.934609, -4342528359.700975, -4079384924.8773026, -3783205648.024708, -5770900878.517931, -2522045142.6102686]}","{'mean_env_wait_ms': 12.798840191920222, 'mean_processing_ms': 3.0757236197402436, 'mean_inference_ms': 1.8240964843362804}",{},0,384000,"{'sample_time_ms': 73522.313, 'sample_throughput': 54.405, 'learn_time_ms': 18648.312, 'learn_throughput': 214.497}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.2814453125, 'cur_lr': 0.001, 'total_loss': 36673927184384.0, 'policy_loss': -0.0011576888209674507, 'vf_loss': 36673927184384.0, 'vf_explained_var': -4.284084e-08, 'kl': 0.01140205560659524, 'entropy': 1.9474220462143421, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 1465553050927104.0, 'policy_loss': 0.0027365085552446544, 'vf_loss': 1465553050927104.0, 'vf_explained_var': 3.7252903e-08, 'kl': 0.011162347858771682, 'entropy': -0.2750522796995938, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 384000, 'num_steps_trained': 384000}",False,150,96,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_21-03-25,1615770205,85.91337609291077,8592.969897270203,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8592.969897270203,0,96,"{'cpu_util_percent': 34.23801652892562, 'ram_util_percent': 56.6396694214876}"
191,95,MARL,light1,-1315300483.4458,-17386949670.798218,-6109250780.213973,2490.25,1,-9888505372.788342,-1096608427.68814,-5010660215.796109,{},"{'episode_reward': [-2333170031.5958014, -7423812720.139137, -1899452563.075036, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684, -6070708931.53347, -6936272776.055735, -2574613869.8970795, -6468401173.607675, -8463359755.384176, -12701604966.174381, -12244819867.677149, -9000443194.345934, -8206707111.963317, -1659633049.9500484, -2528263523.7289243, -7589922561.865974, -6057734575.553119, -6334956827.889362, -5136317389.903228, -4620976007.206353, -4325239720.228492, -6873245446.505015, -2824686933.1944485], 'episode_lengths': [2401, 2376, 2897, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800, 2192, 2795, 2007, 2224, 2870, 2698, 2919, 2572, 2951, 2703, 2566, 2967, 2313, 2324, 1830, 2699, 2961, 2343, 2061], 'policy_gneJ12_reward': [-356865556.24507093, -1005840095.7643778, -274524927.8977448, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026, -803888926.5304034, -950879460.0400009, -341871072.1957007, -1134764913.3763525, -3282482001.8063774, -7316360549.145228, -5176951539.625587, -1568328502.710477, -2265646517.2642846, -165400704.76507056, -311630904.97922, -1072368867.6814501, -1148384911.8856974, -716053571.9547592, -793789030.2022485, -541591082.3290467, -542034072.2037843, -1102344567.9870872, -302641790.5841828], 'policy_light1_reward': [-1976304475.3507335, -6417972624.374755, -1624927635.177292, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869, -5266820005.003068, -5985393316.015743, -2232742797.701376, -5333636260.231334, -5180877753.577805, -5385244417.029186, -7067868328.05152, -7432114691.635461, -5941060594.699041, -1494232345.1849825, -2216632618.749702, -6517553694.184532, -4909349663.667417, -5618903255.934609, -4342528359.700975, -4079384924.8773026, -3783205648.024708, -5770900878.517931, -2522045142.6102686]}","{'mean_env_wait_ms': 12.798840191920222, 'mean_processing_ms': 3.0757236197402436, 'mean_inference_ms': 1.8240964843362804}",{},0,384000,"{'sample_time_ms': 73522.313, 'sample_throughput': 54.405, 'learn_time_ms': 18648.312, 'learn_throughput': 214.497}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.2814453125, 'cur_lr': 0.001, 'total_loss': 36673927184384.0, 'policy_loss': -0.0011576888209674507, 'vf_loss': 36673927184384.0, 'vf_explained_var': -4.284084e-08, 'kl': 0.01140205560659524, 'entropy': 1.9474220462143421, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 1465553050927104.0, 'policy_loss': 0.0027365085552446544, 'vf_loss': 1465553050927104.0, 'vf_explained_var': 3.7252903e-08, 'kl': 0.011162347858771682, 'entropy': -0.2750522796995938, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 384000, 'num_steps_trained': 384000}",False,150,96,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_21-03-25,1615770205,85.91337609291077,8592.969897270203,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8592.969897270203,0,96,"{'cpu_util_percent': 34.23801652892562, 'ram_util_percent': 56.6396694214876}"
192,96,MARL,gneJ12,-1315300483.4458,-17386949670.798218,-6167071971.25797,2493.4,2,-7498444298.009825,-165400704.76507056,-1107171678.9319768,{},"{'episode_reward': [-7312700743.504093, -7792683644.109721, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684, -6070708931.53347, -6936272776.055735, -2574613869.8970795, -6468401173.607675, -8463359755.384176, -12701604966.174381, -12244819867.677149, -9000443194.345934, -8206707111.963317, -1659633049.9500484, -2528263523.7289243, -7589922561.865974, -6057734575.553119, -6334956827.889362, -5136317389.903228, -4620976007.206353, -4325239720.228492, -6873245446.505015, -2824686933.1944485, -2333170031.5958014], 'episode_lengths': [2943, 2645, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800, 2192, 2795, 2007, 2224, 2870, 2698, 2919, 2572, 2951, 2703, 2566, 2967, 2313, 2324, 1830, 2699, 2961, 2343, 2061, 2401], 'policy_gneJ12_reward': [-920551275.3967589, -1217925199.676726, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026, -803888926.5304034, -950879460.0400009, -341871072.1957007, -1134764913.3763525, -3282482001.8063774, -7316360549.145228, -5176951539.625587, -1568328502.710477, -2265646517.2642846, -165400704.76507056, -311630904.97922, -1072368867.6814501, -1148384911.8856974, -716053571.9547592, -793789030.2022485, -541591082.3290467, -542034072.2037843, -1102344567.9870872, -302641790.5841828, -356865556.24507093], 'policy_light1_reward': [-6392149468.107356, -6574758444.43299, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869, -5266820005.003068, -5985393316.015743, -2232742797.701376, -5333636260.231334, -5180877753.577805, -5385244417.029186, -7067868328.05152, -7432114691.635461, -5941060594.699041, -1494232345.1849825, -2216632618.749702, -6517553694.184532, -4909349663.667417, -5618903255.934609, -4342528359.700975, -4079384924.8773026, -3783205648.024708, -5770900878.517931, -2522045142.6102686, -1976304475.3507335]}","{'mean_env_wait_ms': 12.79981062046747, 'mean_processing_ms': 3.0805145459355896, 'mean_inference_ms': 1.8246848791689019}",{},0,388000,"{'sample_time_ms': 74208.484, 'sample_throughput': 53.902, 'learn_time_ms': 18637.777, 'learn_throughput': 214.618}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.2814453125, 'cur_lr': 0.001, 'total_loss': 109632709984256.0, 'policy_loss': -0.005201466483413242, 'vf_loss': 109632709984256.0, 'vf_explained_var': -1.6763806e-08, 'kl': 0.016401190834585577, 'entropy': 3.0337560400366783, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 2535137468219392.0, 'policy_loss': 0.00013451295671984553, 'vf_loss': 2535137468219392.0, 'vf_explained_var': 6.891787e-08, 'kl': 0.014298717025667429, 'entropy': 0.1185459557455033, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 388000, 'num_steps_trained': 388000}",False,152,97,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_21-05-03,1615770303,98.04611372947693,8691.01601099968,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8691.01601099968,0,97,"{'cpu_util_percent': 36.19710144927535, 'ram_util_percent': 57.68768115942029}"
193,96,MARL,light1,-1315300483.4458,-17386949670.798218,-6167071971.25797,2493.4,2,-9888505372.788342,-1096608427.68814,-5059900292.325993,{},"{'episode_reward': [-7312700743.504093, -7792683644.109721, -6570697919.845422, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684, -6070708931.53347, -6936272776.055735, -2574613869.8970795, -6468401173.607675, -8463359755.384176, -12701604966.174381, -12244819867.677149, -9000443194.345934, -8206707111.963317, -1659633049.9500484, -2528263523.7289243, -7589922561.865974, -6057734575.553119, -6334956827.889362, -5136317389.903228, -4620976007.206353, -4325239720.228492, -6873245446.505015, -2824686933.1944485, -2333170031.5958014], 'episode_lengths': [2943, 2645, 2900, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800, 2192, 2795, 2007, 2224, 2870, 2698, 2919, 2572, 2951, 2703, 2566, 2967, 2313, 2324, 1830, 2699, 2961, 2343, 2061, 2401], 'policy_gneJ12_reward': [-920551275.3967589, -1217925199.676726, -788659730.0194864, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026, -803888926.5304034, -950879460.0400009, -341871072.1957007, -1134764913.3763525, -3282482001.8063774, -7316360549.145228, -5176951539.625587, -1568328502.710477, -2265646517.2642846, -165400704.76507056, -311630904.97922, -1072368867.6814501, -1148384911.8856974, -716053571.9547592, -793789030.2022485, -541591082.3290467, -542034072.2037843, -1102344567.9870872, -302641790.5841828, -356865556.24507093], 'policy_light1_reward': [-6392149468.107356, -6574758444.43299, -5782038189.825922, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869, -5266820005.003068, -5985393316.015743, -2232742797.701376, -5333636260.231334, -5180877753.577805, -5385244417.029186, -7067868328.05152, -7432114691.635461, -5941060594.699041, -1494232345.1849825, -2216632618.749702, -6517553694.184532, -4909349663.667417, -5618903255.934609, -4342528359.700975, -4079384924.8773026, -3783205648.024708, -5770900878.517931, -2522045142.6102686, -1976304475.3507335]}","{'mean_env_wait_ms': 12.79981062046747, 'mean_processing_ms': 3.0805145459355896, 'mean_inference_ms': 1.8246848791689019}",{},0,388000,"{'sample_time_ms': 74208.484, 'sample_throughput': 53.902, 'learn_time_ms': 18637.777, 'learn_throughput': 214.618}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.2814453125, 'cur_lr': 0.001, 'total_loss': 109632709984256.0, 'policy_loss': -0.005201466483413242, 'vf_loss': 109632709984256.0, 'vf_explained_var': -1.6763806e-08, 'kl': 0.016401190834585577, 'entropy': 3.0337560400366783, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 2535137468219392.0, 'policy_loss': 0.00013451295671984553, 'vf_loss': 2535137468219392.0, 'vf_explained_var': 6.891787e-08, 'kl': 0.014298717025667429, 'entropy': 0.1185459557455033, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 388000, 'num_steps_trained': 388000}",False,152,97,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_21-05-03,1615770303,98.04611372947693,8691.01601099968,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8691.01601099968,0,97,"{'cpu_util_percent': 36.19710144927535, 'ram_util_percent': 57.68768115942029}"
194,97,MARL,gneJ12,-1315300483.4458,-17386949670.798218,-6184286815.295319,2491.26,1,-7498444298.009825,-165400704.76507056,-1111734300.1370091,{},"{'episode_reward': [-8292182323.580203, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684, -6070708931.53347, -6936272776.055735, -2574613869.8970795, -6468401173.607675, -8463359755.384176, -12701604966.174381, -12244819867.677149, -9000443194.345934, -8206707111.963317, -1659633049.9500484, -2528263523.7289243, -7589922561.865974, -6057734575.553119, -6334956827.889362, -5136317389.903228, -4620976007.206353, -4325239720.228492, -6873245446.505015, -2824686933.1944485, -2333170031.5958014, -7312700743.504093, -7792683644.109721], 'episode_lengths': [2686, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800, 2192, 2795, 2007, 2224, 2870, 2698, 2919, 2572, 2951, 2703, 2566, 2967, 2313, 2324, 1830, 2699, 2961, 2343, 2061, 2401, 2943, 2645], 'policy_gneJ12_reward': [-1244921850.5227094, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026, -803888926.5304034, -950879460.0400009, -341871072.1957007, -1134764913.3763525, -3282482001.8063774, -7316360549.145228, -5176951539.625587, -1568328502.710477, -2265646517.2642846, -165400704.76507056, -311630904.97922, -1072368867.6814501, -1148384911.8856974, -716053571.9547592, -793789030.2022485, -541591082.3290467, -542034072.2037843, -1102344567.9870872, -302641790.5841828, -356865556.24507093, -920551275.3967589, -1217925199.676726], 'policy_light1_reward': [-7047260473.057486, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869, -5266820005.003068, -5985393316.015743, -2232742797.701376, -5333636260.231334, -5180877753.577805, -5385244417.029186, -7067868328.05152, -7432114691.635461, -5941060594.699041, -1494232345.1849825, -2216632618.749702, -6517553694.184532, -4909349663.667417, -5618903255.934609, -4342528359.700975, -4079384924.8773026, -3783205648.024708, -5770900878.517931, -2522045142.6102686, -1976304475.3507335, -6392149468.107356, -6574758444.43299]}","{'mean_env_wait_ms': 12.8005383660524, 'mean_processing_ms': 3.082670560506875, 'mean_inference_ms': 1.8250069925783585}",{},0,392000,"{'sample_time_ms': 73212.514, 'sample_throughput': 54.635, 'learn_time_ms': 18711.245, 'learn_throughput': 213.775}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.2814453125, 'cur_lr': 0.001, 'total_loss': 94230199795712.0, 'policy_loss': -0.0011741801863536239, 'vf_loss': 94230199795712.0, 'vf_explained_var': -8.195639e-08, 'kl': 0.014830749947577715, 'entropy': 3.077134609222412, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 2183458361180160.0, 'policy_loss': -0.00872592322411947, 'vf_loss': 2183458361180160.0, 'vf_explained_var': -1.0430813e-07, 'kl': 0.007051482294627931, 'entropy': 0.17432528198696673, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 392000, 'num_steps_trained': 392000}",False,153,98,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_21-06-30,1615770390,87.18288803100586,8778.198899030685,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8778.198899030685,0,98,"{'cpu_util_percent': 29.52950819672131, 'ram_util_percent': 57.4450819672131}"
195,97,MARL,light1,-1315300483.4458,-17386949670.798218,-6184286815.295319,2491.26,1,-9888505372.788342,-1096608427.68814,-5072552515.158308,{},"{'episode_reward': [-8292182323.580203, -7553704825.478482, -5514947742.297844, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684, -6070708931.53347, -6936272776.055735, -2574613869.8970795, -6468401173.607675, -8463359755.384176, -12701604966.174381, -12244819867.677149, -9000443194.345934, -8206707111.963317, -1659633049.9500484, -2528263523.7289243, -7589922561.865974, -6057734575.553119, -6334956827.889362, -5136317389.903228, -4620976007.206353, -4325239720.228492, -6873245446.505015, -2824686933.1944485, -2333170031.5958014, -7312700743.504093, -7792683644.109721], 'episode_lengths': [2686, 2777, 2426, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800, 2192, 2795, 2007, 2224, 2870, 2698, 2919, 2572, 2951, 2703, 2566, 2967, 2313, 2324, 1830, 2699, 2961, 2343, 2061, 2401, 2943, 2645], 'policy_gneJ12_reward': [-1244921850.5227094, -911855825.020136, -733541351.3690573, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026, -803888926.5304034, -950879460.0400009, -341871072.1957007, -1134764913.3763525, -3282482001.8063774, -7316360549.145228, -5176951539.625587, -1568328502.710477, -2265646517.2642846, -165400704.76507056, -311630904.97922, -1072368867.6814501, -1148384911.8856974, -716053571.9547592, -793789030.2022485, -541591082.3290467, -542034072.2037843, -1102344567.9870872, -302641790.5841828, -356865556.24507093, -920551275.3967589, -1217925199.676726], 'policy_light1_reward': [-7047260473.057486, -6641849000.458346, -4781406390.928801, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869, -5266820005.003068, -5985393316.015743, -2232742797.701376, -5333636260.231334, -5180877753.577805, -5385244417.029186, -7067868328.05152, -7432114691.635461, -5941060594.699041, -1494232345.1849825, -2216632618.749702, -6517553694.184532, -4909349663.667417, -5618903255.934609, -4342528359.700975, -4079384924.8773026, -3783205648.024708, -5770900878.517931, -2522045142.6102686, -1976304475.3507335, -6392149468.107356, -6574758444.43299]}","{'mean_env_wait_ms': 12.8005383660524, 'mean_processing_ms': 3.082670560506875, 'mean_inference_ms': 1.8250069925783585}",{},0,392000,"{'sample_time_ms': 73212.514, 'sample_throughput': 54.635, 'learn_time_ms': 18711.245, 'learn_throughput': 213.775}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.2814453125, 'cur_lr': 0.001, 'total_loss': 94230199795712.0, 'policy_loss': -0.0011741801863536239, 'vf_loss': 94230199795712.0, 'vf_explained_var': -8.195639e-08, 'kl': 0.014830749947577715, 'entropy': 3.077134609222412, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 2183458361180160.0, 'policy_loss': -0.00872592322411947, 'vf_loss': 2183458361180160.0, 'vf_explained_var': -1.0430813e-07, 'kl': 0.007051482294627931, 'entropy': 0.17432528198696673, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 392000, 'num_steps_trained': 392000}",False,153,98,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_21-06-30,1615770390,87.18288803100586,8778.198899030685,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8778.198899030685,0,98,"{'cpu_util_percent': 29.52950819672131, 'ram_util_percent': 57.4450819672131}"
196,98,MARL,gneJ12,-1315300483.4458,-17386949670.798218,-6214058766.245531,2497.18,2,-7498444298.009825,-165400704.76507056,-1136339451.8339891,{},"{'episode_reward': [-8127615644.480545, -7918232018.317077, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684, -6070708931.53347, -6936272776.055735, -2574613869.8970795, -6468401173.607675, -8463359755.384176, -12701604966.174381, -12244819867.677149, -9000443194.345934, -8206707111.963317, -1659633049.9500484, -2528263523.7289243, -7589922561.865974, -6057734575.553119, -6334956827.889362, -5136317389.903228, -4620976007.206353, -4325239720.228492, -6873245446.505015, -2824686933.1944485, -2333170031.5958014, -7312700743.504093, -7792683644.109721, -8292182323.580203], 'episode_lengths': [3162, 2633, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800, 2192, 2795, 2007, 2224, 2870, 2698, 2919, 2572, 2951, 2703, 2566, 2967, 2313, 2324, 1830, 2699, 2961, 2343, 2061, 2401, 2943, 2645, 2686], 'policy_gneJ12_reward': [-1248000442.7544968, -2857911903.3327103, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026, -803888926.5304034, -950879460.0400009, -341871072.1957007, -1134764913.3763525, -3282482001.8063774, -7316360549.145228, -5176951539.625587, -1568328502.710477, -2265646517.2642846, -165400704.76507056, -311630904.97922, -1072368867.6814501, -1148384911.8856974, -716053571.9547592, -793789030.2022485, -541591082.3290467, -542034072.2037843, -1102344567.9870872, -302641790.5841828, -356865556.24507093, -920551275.3967589, -1217925199.676726, -1244921850.5227094], 'policy_light1_reward': [-6879615201.726033, -5060320114.984363, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869, -5266820005.003068, -5985393316.015743, -2232742797.701376, -5333636260.231334, -5180877753.577805, -5385244417.029186, -7067868328.05152, -7432114691.635461, -5941060594.699041, -1494232345.1849825, -2216632618.749702, -6517553694.184532, -4909349663.667417, -5618903255.934609, -4342528359.700975, -4079384924.8773026, -3783205648.024708, -5770900878.517931, -2522045142.6102686, -1976304475.3507335, -6392149468.107356, -6574758444.43299, -7047260473.057486]}","{'mean_env_wait_ms': 12.802241518022578, 'mean_processing_ms': 3.0873952487118625, 'mean_inference_ms': 1.8256728348521947}",{},0,396000,"{'sample_time_ms': 73859.366, 'sample_throughput': 54.157, 'learn_time_ms': 18778.868, 'learn_throughput': 213.005}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.2814453125, 'cur_lr': 0.001, 'total_loss': 609688208015360.0, 'policy_loss': -0.006601917324587703, 'vf_loss': 609688208015360.0, 'vf_explained_var': 7.450581e-09, 'kl': 0.013084905265714042, 'entropy': 2.8597205877304077, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 1704021928706048.0, 'policy_loss': 0.0015984041092451662, 'vf_loss': 1704021928706048.0, 'vf_explained_var': 1.3038516e-08, 'kl': 0.013723683878197335, 'entropy': 0.08734423076384701, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 396000, 'num_steps_trained': 396000}",False,155,99,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_21-08-05,1615770485,95.23007225990295,8873.428971290588,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8873.428971290588,0,99,"{'cpu_util_percent': 30.784328358208956, 'ram_util_percent': 57.745522388059705}"
197,98,MARL,light1,-1315300483.4458,-17386949670.798218,-6214058766.245531,2497.18,2,-9888505372.788342,-1096608427.68814,-5077719314.41154,{},"{'episode_reward': [-8127615644.480545, -7918232018.317077, -8492121380.279499, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684, -6070708931.53347, -6936272776.055735, -2574613869.8970795, -6468401173.607675, -8463359755.384176, -12701604966.174381, -12244819867.677149, -9000443194.345934, -8206707111.963317, -1659633049.9500484, -2528263523.7289243, -7589922561.865974, -6057734575.553119, -6334956827.889362, -5136317389.903228, -4620976007.206353, -4325239720.228492, -6873245446.505015, -2824686933.1944485, -2333170031.5958014, -7312700743.504093, -7792683644.109721, -8292182323.580203], 'episode_lengths': [3162, 2633, 3089, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800, 2192, 2795, 2007, 2224, 2870, 2698, 2919, 2572, 2951, 2703, 2566, 2967, 2313, 2324, 1830, 2699, 2961, 2343, 2061, 2401, 2943, 2645, 2686], 'policy_gneJ12_reward': [-1248000442.7544968, -2857911903.3327103, -1023784513.7641034, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026, -803888926.5304034, -950879460.0400009, -341871072.1957007, -1134764913.3763525, -3282482001.8063774, -7316360549.145228, -5176951539.625587, -1568328502.710477, -2265646517.2642846, -165400704.76507056, -311630904.97922, -1072368867.6814501, -1148384911.8856974, -716053571.9547592, -793789030.2022485, -541591082.3290467, -542034072.2037843, -1102344567.9870872, -302641790.5841828, -356865556.24507093, -920551275.3967589, -1217925199.676726, -1244921850.5227094], 'policy_light1_reward': [-6879615201.726033, -5060320114.984363, -7468336866.515404, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869, -5266820005.003068, -5985393316.015743, -2232742797.701376, -5333636260.231334, -5180877753.577805, -5385244417.029186, -7067868328.05152, -7432114691.635461, -5941060594.699041, -1494232345.1849825, -2216632618.749702, -6517553694.184532, -4909349663.667417, -5618903255.934609, -4342528359.700975, -4079384924.8773026, -3783205648.024708, -5770900878.517931, -2522045142.6102686, -1976304475.3507335, -6392149468.107356, -6574758444.43299, -7047260473.057486]}","{'mean_env_wait_ms': 12.802241518022578, 'mean_processing_ms': 3.0873952487118625, 'mean_inference_ms': 1.8256728348521947}",{},0,396000,"{'sample_time_ms': 73859.366, 'sample_throughput': 54.157, 'learn_time_ms': 18778.868, 'learn_throughput': 213.005}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.2814453125, 'cur_lr': 0.001, 'total_loss': 609688208015360.0, 'policy_loss': -0.006601917324587703, 'vf_loss': 609688208015360.0, 'vf_explained_var': 7.450581e-09, 'kl': 0.013084905265714042, 'entropy': 2.8597205877304077, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 1704021928706048.0, 'policy_loss': 0.0015984041092451662, 'vf_loss': 1704021928706048.0, 'vf_explained_var': 1.3038516e-08, 'kl': 0.013723683878197335, 'entropy': 0.08734423076384701, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 396000, 'num_steps_trained': 396000}",False,155,99,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_21-08-05,1615770485,95.23007225990295,8873.428971290588,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8873.428971290588,0,99,"{'cpu_util_percent': 30.784328358208956, 'ram_util_percent': 57.745522388059705}"
198,99,MARL,gneJ12,-1315300483.4458,-17386949670.798218,-6157924724.2604065,2486.61,1,-7498444298.009825,-165400704.76507056,-1130265990.7512906,{},"{'episode_reward': [-2878717181.767082, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684, -6070708931.53347, -6936272776.055735, -2574613869.8970795, -6468401173.607675, -8463359755.384176, -12701604966.174381, -12244819867.677149, -9000443194.345934, -8206707111.963317, -1659633049.9500484, -2528263523.7289243, -7589922561.865974, -6057734575.553119, -6334956827.889362, -5136317389.903228, -4620976007.206353, -4325239720.228492, -6873245446.505015, -2824686933.1944485, -2333170031.5958014, -7312700743.504093, -7792683644.109721, -8292182323.580203, -8127615644.480545, -7918232018.317077], 'episode_lengths': [2032, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800, 2192, 2795, 2007, 2224, 2870, 2698, 2919, 2572, 2951, 2703, 2566, 2967, 2313, 2324, 1830, 2699, 2961, 2343, 2061, 2401, 2943, 2645, 2686, 3162, 2633], 'policy_gneJ12_reward': [-416438405.49423707, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026, -803888926.5304034, -950879460.0400009, -341871072.1957007, -1134764913.3763525, -3282482001.8063774, -7316360549.145228, -5176951539.625587, -1568328502.710477, -2265646517.2642846, -165400704.76507056, -311630904.97922, -1072368867.6814501, -1148384911.8856974, -716053571.9547592, -793789030.2022485, -541591082.3290467, -542034072.2037843, -1102344567.9870872, -302641790.5841828, -356865556.24507093, -920551275.3967589, -1217925199.676726, -1244921850.5227094, -1248000442.7544968, -2857911903.3327103], 'policy_light1_reward': [-2462278776.272841, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869, -5266820005.003068, -5985393316.015743, -2232742797.701376, -5333636260.231334, -5180877753.577805, -5385244417.029186, -7067868328.05152, -7432114691.635461, -5941060594.699041, -1494232345.1849825, -2216632618.749702, -6517553694.184532, -4909349663.667417, -5618903255.934609, -4342528359.700975, -4079384924.8773026, -3783205648.024708, -5770900878.517931, -2522045142.6102686, -1976304475.3507335, -6392149468.107356, -6574758444.43299, -7047260473.057486, -6879615201.726033, -5060320114.984363]}","{'mean_env_wait_ms': 12.803074973387268, 'mean_processing_ms': 3.089449557435722, 'mean_inference_ms': 1.826025586628023}",{},0,400000,"{'sample_time_ms': 73083.601, 'sample_throughput': 54.732, 'learn_time_ms': 18971.458, 'learn_throughput': 210.843}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.2814453125, 'cur_lr': 0.001, 'total_loss': 63486436048896.0, 'policy_loss': -0.011575669021112844, 'vf_loss': 63486436048896.0, 'vf_explained_var': -2.6077032e-08, 'kl': 0.011393837005016394, 'entropy': 2.0920036658644676, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 1655450361659392.0, 'policy_loss': 0.012387397116981447, 'vf_loss': 1655450361659392.0, 'vf_explained_var': -3.7252903e-08, 'kl': 0.023397665529046208, 'entropy': -0.25983410724438727, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 400000, 'num_steps_trained': 400000}",False,156,100,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_21-09-32,1615770572,86.20480585098267,8959.633777141571,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8959.633777141571,0,100,"{'cpu_util_percent': 33.90330578512397, 'ram_util_percent': 57.594214876033064}"
199,99,MARL,light1,-1315300483.4458,-17386949670.798218,-6157924724.2604065,2486.61,1,-9888505372.788342,-1096608427.68814,-5027658733.509114,{},"{'episode_reward': [-2878717181.767082, -11945450832.499002, -4088122951.1654634, -6499605251.471545, -1586253625.9149873, -1801067152.5777302, -6853737776.156333, -7704743368.9942, -6768426710.217544, -7420848675.218515, -4625812054.418986, -4487142062.354038, -6864765701.346848, -4870267249.37805, -1639522875.2783349, -6708572242.851304, -7546314683.5192585, -5905225331.742798, -8242793270.027031, -4223133343.6774235, -2777730147.84472, -5270325655.346786, -5670063266.560047, -5464571911.70924, -5246412218.409226, -9341124707.079725, -6283107025.820504, -3759207580.5069914, -4166921813.1091886, -7537937064.694644, -7516733632.093279, -8954633269.42481, -7496738079.259743, -7014804601.962027, -3645113796.6344423, -8199786561.658592, -6770418843.012492, -1315300483.4458, -17386949670.798218, -5911099910.9450655, -6616411430.031185, -2776619432.951309, -7035516897.90606, -5225681984.243652, -6000748806.515728, -7868454599.200462, -4427252985.2439, -8181456599.1989, -7574828048.050996, -5940066109.053961, -2703534808.9941096, -6065111337.691192, -5485900463.189604, -1591354789.775153, -4695930325.11669, -8446518246.398142, -8302613398.859735, -8221406503.277202, -5944341224.725366, -7080522332.803153, -7490774639.937237, -3170367800.87661, -4626410693.9797, -3217335454.1464415, -7106079911.804898, -7115928576.702338, -7708856360.70432, -8354700353.578763, -6069675303.6194105, -4328717007.054848, -7483375421.8671055, -4160914416.5211897, -5677626572.194818, -6683306484.712456, -7630138435.970684, -6070708931.53347, -6936272776.055735, -2574613869.8970795, -6468401173.607675, -8463359755.384176, -12701604966.174381, -12244819867.677149, -9000443194.345934, -8206707111.963317, -1659633049.9500484, -2528263523.7289243, -7589922561.865974, -6057734575.553119, -6334956827.889362, -5136317389.903228, -4620976007.206353, -4325239720.228492, -6873245446.505015, -2824686933.1944485, -2333170031.5958014, -7312700743.504093, -7792683644.109721, -8292182323.580203, -8127615644.480545, -7918232018.317077], 'episode_lengths': [2032, 2564, 2351, 2554, 2452, 1657, 2976, 2510, 2663, 2214, 2352, 2011, 2324, 2647, 2004, 1892, 2609, 2670, 2570, 1660, 2113, 3018, 2050, 1756, 2197, 2747, 1968, 2929, 1650, 2392, 2710, 2848, 2634, 2484, 2926, 2377, 2345, 2695, 2962, 2328, 2115, 2180, 2134, 2355, 2872, 2724, 2988, 2702, 2679, 1914, 2275, 2425, 1898, 3032, 2259, 2564, 3096, 3084, 2345, 2617, 2636, 2001, 1625, 2561, 2616, 3031, 2857, 3036, 2459, 2911, 2433, 2686, 2171, 2274, 2800, 2192, 2795, 2007, 2224, 2870, 2698, 2919, 2572, 2951, 2703, 2566, 2967, 2313, 2324, 1830, 2699, 2961, 2343, 2061, 2401, 2943, 2645, 2686, 3162, 2633], 'policy_gneJ12_reward': [-416438405.49423707, -6596645367.939878, -558303071.3822882, -921056562.963085, -271863462.8096377, -247339455.04402637, -867339768.0243667, -1253518328.4190695, -988177609.2836069, -1860561451.8441384, -556562328.9997866, -570698131.7220047, -795690162.3384116, -632681766.332957, -227884829.50978658, -901426832.7389537, -1280253523.7918642, -639711751.1341465, -891188399.2217511, -621121382.1755627, -332199596.00286424, -671736882.2632983, -678823786.4679896, -703138460.6303816, -685997399.8092675, -1402636462.2700272, -853436772.6346331, -426818414.7410234, -650391440.6533083, -1050400689.8544695, -997564216.4491273, -1220123553.3635688, -1138331653.7878678, -887865860.8596783, -457017564.04163146, -2845581758.95066, -933809910.981775, -218692055.75766248, -7498444298.009825, -788184153.7598045, -796605630.7223681, -362660277.91076684, -1094731979.6965852, -703826637.4096254, -683103215.7603076, -1076350060.0593877, -570990274.7485429, -1135139804.0392752, -1112862332.4575703, -775593302.4110138, -349636876.7810691, -761524246.5342321, -687276312.1794814, -225405444.27957696, -434054246.504577, -1031653042.1384119, -1455918863.8362937, -1113819654.4707267, -779734034.8274242, -1123022594.127025, -1151321062.120209, -405328183.0917163, -617727348.3686336, -451516562.9555719, -936024770.8268768, -920794904.6672612, -1502171570.9841983, -1283205721.9964898, -883765738.0440688, -558212053.625892, -1272097290.541829, -529691836.25762975, -821555149.6467173, -1206011770.415046, -1290019543.0388026, -803888926.5304034, -950879460.0400009, -341871072.1957007, -1134764913.3763525, -3282482001.8063774, -7316360549.145228, -5176951539.625587, -1568328502.710477, -2265646517.2642846, -165400704.76507056, -311630904.97922, -1072368867.6814501, -1148384911.8856974, -716053571.9547592, -793789030.2022485, -541591082.3290467, -542034072.2037843, -1102344567.9870872, -302641790.5841828, -356865556.24507093, -920551275.3967589, -1217925199.676726, -1244921850.5227094, -1248000442.7544968, -2857911903.3327103], 'policy_light1_reward': [-2462278776.272841, -5348805464.559098, -3529819879.7831783, -5578548688.508451, -1314390163.1053514, -1553727697.5337029, -5986398008.131959, -6451225040.575131, -5780249100.933933, -5560287223.374365, -4069249725.4192, -3916443930.6320415, -6069075539.008424, -4237585483.045102, -1411638045.7685473, -5807145410.112333, -6266061159.727385, -5265513580.608659, -7351604870.805295, -3602011961.5018635, -2445530551.841857, -4598588773.083479, -4991239480.092057, -4761433451.078865, -4560414818.599954, -7938488244.809711, -5429670253.185883, -3332389165.7659717, -3516530372.4558854, -6487536374.840167, -6519169415.644166, -7734509716.061251, -6358406425.47188, -6126938741.10234, -3188096232.5928054, -5354204802.707914, -5836608932.030722, -1096608427.68814, -9888505372.788342, -5122915757.185251, -5819805799.308826, -2413959155.040544, -5940784918.209476, -4521855346.83403, -5317645590.755413, -6792104539.14109, -3856262710.4953446, -7046316795.159605, -6461965715.593427, -5164472806.642955, -2353897932.213037, -5303587091.156957, -4798624151.010112, -1365949345.495577, -4261876078.6121125, -7414865204.259722, -6846694535.023446, -7107586848.806467, -5164607189.897941, -5957499738.676131, -6339453577.817024, -2765039617.7848887, -4008683345.611068, -2765818891.190869, -6170055140.978042, -6195133672.035079, -6206684789.720108, -7071494631.582267, -5185909565.575363, -3770504953.428948, -6211278131.325276, -3631222580.263557, -4856071422.548111, -5477294714.2974, -6340118892.931869, -5266820005.003068, -5985393316.015743, -2232742797.701376, -5333636260.231334, -5180877753.577805, -5385244417.029186, -7067868328.05152, -7432114691.635461, -5941060594.699041, -1494232345.1849825, -2216632618.749702, -6517553694.184532, -4909349663.667417, -5618903255.934609, -4342528359.700975, -4079384924.8773026, -3783205648.024708, -5770900878.517931, -2522045142.6102686, -1976304475.3507335, -6392149468.107356, -6574758444.43299, -7047260473.057486, -6879615201.726033, -5060320114.984363]}","{'mean_env_wait_ms': 12.803074973387268, 'mean_processing_ms': 3.089449557435722, 'mean_inference_ms': 1.826025586628023}",{},0,400000,"{'sample_time_ms': 73083.601, 'sample_throughput': 54.732, 'learn_time_ms': 18971.458, 'learn_throughput': 210.843}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.2814453125, 'cur_lr': 0.001, 'total_loss': 63486436048896.0, 'policy_loss': -0.011575669021112844, 'vf_loss': 63486436048896.0, 'vf_explained_var': -2.6077032e-08, 'kl': 0.011393837005016394, 'entropy': 2.0920036658644676, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 1655450361659392.0, 'policy_loss': 0.012387397116981447, 'vf_loss': 1655450361659392.0, 'vf_explained_var': -3.7252903e-08, 'kl': 0.023397665529046208, 'entropy': -0.25983410724438727, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 400000, 'num_steps_trained': 400000}",False,156,100,b211fcf3e5904c0a85886c3cfebe9727,2021-03-14_21-09-32,1615770572,86.20480585098267,8959.633777141571,52248,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function train.<locals>.<lambda> at 0x16b4ac4c0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8959.633777141571,0,100,"{'cpu_util_percent': 33.90330578512397, 'ram_util_percent': 57.594214876033064}"
