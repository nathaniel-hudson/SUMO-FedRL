,round,trainer,policy,fed_round,episode_reward_max,episode_reward_min,episode_reward_mean,episode_len_mean,episodes_this_iter,policy_reward_min,policy_reward_max,policy_reward_mean,custom_metrics,hist_stats,sampler_perf,off_policy_estimator,num_healthy_workers,timesteps_total,timers,info,done,episodes_total,training_iteration,experiment_id,date,timestamp,time_this_iter_s,time_total_s,pid,hostname,node_ip,config,time_since_restore,timesteps_since_restore,iterations_since_restore,perf
0,0,MARL,gneJ12,False,-22499901518.185413,-22499901518.185413,-22499901518.185413,3314.0,1,-6015531683.418047,-6015531683.418047,-6015531683.418047,{},"{'episode_reward': [-22499901518.185413], 'episode_lengths': [3314], 'policy_gneJ12_reward': [-6015531683.418047], 'policy_light1_reward': [-16484369834.76737]}","{'mean_env_wait_ms': 14.101288551629946, 'mean_processing_ms': 2.183677672863126, 'mean_inference_ms': 1.8054965256869986}",{},0,4000,"{'sample_time_ms': 72417.189, 'sample_throughput': 55.236, 'learn_time_ms': 17035.968, 'learn_throughput': 234.797}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.2, 'cur_lr': 0.001, 'total_loss': 1590458509688832.0, 'policy_loss': -0.0065246293088421226, 'vf_loss': 1590458509688832.0, 'vf_explained_var': 5.401671e-08, 'kl': 0.018762470019282773, 'entropy': 1.4210735820233822, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.2, 'cur_lr': 0.001, 'total_loss': 1.0271176773337088e+16, 'policy_loss': -0.008542679890524596, 'vf_loss': 1.0271176773337088e+16, 'vf_explained_var': 2.6077032e-08, 'kl': 0.00867910905071767, 'entropy': 1.41866684705019, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 4000, 'num_steps_trained': 4000}",False,1,1,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-30-45,1615735845,89.45211005210876,89.45211005210876,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",89.45211005210876,0,1,"{'cpu_util_percent': 28.52857142857143, 'ram_util_percent': 52.39999999999997}"
1,0,MARL,light1,False,-22499901518.185413,-22499901518.185413,-22499901518.185413,3314.0,1,-16484369834.76737,-16484369834.76737,-16484369834.76737,{},"{'episode_reward': [-22499901518.185413], 'episode_lengths': [3314], 'policy_gneJ12_reward': [-6015531683.418047], 'policy_light1_reward': [-16484369834.76737]}","{'mean_env_wait_ms': 14.101288551629946, 'mean_processing_ms': 2.183677672863126, 'mean_inference_ms': 1.8054965256869986}",{},0,4000,"{'sample_time_ms': 72417.189, 'sample_throughput': 55.236, 'learn_time_ms': 17035.968, 'learn_throughput': 234.797}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.2, 'cur_lr': 0.001, 'total_loss': 1590458509688832.0, 'policy_loss': -0.0065246293088421226, 'vf_loss': 1590458509688832.0, 'vf_explained_var': 5.401671e-08, 'kl': 0.018762470019282773, 'entropy': 1.4210735820233822, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.2, 'cur_lr': 0.001, 'total_loss': 1.0271176773337088e+16, 'policy_loss': -0.008542679890524596, 'vf_loss': 1.0271176773337088e+16, 'vf_explained_var': 2.6077032e-08, 'kl': 0.00867910905071767, 'entropy': 1.41866684705019, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 4000, 'num_steps_trained': 4000}",False,1,1,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-30-45,1615735845,89.45211005210876,89.45211005210876,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",89.45211005210876,0,1,"{'cpu_util_percent': 28.52857142857143, 'ram_util_percent': 52.39999999999997}"
2,1,MARL,gneJ12,False,-19522681691.132637,-22499901518.185413,-21011291604.659027,3156.5,1,-6015531683.418047,-5227995262.474674,-5621763472.946361,{},"{'episode_reward': [-19522681691.132637, -22499901518.185413], 'episode_lengths': [2999, 3314], 'policy_gneJ12_reward': [-5227995262.474674, -6015531683.418047], 'policy_light1_reward': [-14294686428.657932, -16484369834.76737]}","{'mean_env_wait_ms': 13.66321951920477, 'mean_processing_ms': 2.116051081850654, 'mean_inference_ms': 1.8065554903873982}",{},0,8000,"{'sample_time_ms': 68368.566, 'sample_throughput': 58.506, 'learn_time_ms': 17208.93, 'learn_throughput': 232.437}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.2, 'cur_lr': 0.001, 'total_loss': 6876129629569024.0, 'policy_loss': -0.003548729175236076, 'vf_loss': 6876129629569024.0, 'vf_explained_var': -5.2154064e-08, 'kl': 0.020856492905295454, 'entropy': 1.3766059912741184, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.2, 'cur_lr': 0.001, 'total_loss': 1.4772554744987648e+16, 'policy_loss': -0.0017031524621415883, 'vf_loss': 1.4772554744987648e+16, 'vf_explained_var': -8.940697e-08, 'kl': 0.009587877597368788, 'entropy': 1.5185868181288242, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 8000, 'num_steps_trained': 8000}",False,2,2,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-32-07,1615735927,81.70154190063477,171.15365195274353,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",171.15365195274353,0,2,"{'cpu_util_percent': 31.095652173913038, 'ram_util_percent': 52.347826086956516}"
3,1,MARL,light1,False,-19522681691.132637,-22499901518.185413,-21011291604.659027,3156.5,1,-16484369834.76737,-14294686428.657932,-15389528131.71265,{},"{'episode_reward': [-19522681691.132637, -22499901518.185413], 'episode_lengths': [2999, 3314], 'policy_gneJ12_reward': [-5227995262.474674, -6015531683.418047], 'policy_light1_reward': [-14294686428.657932, -16484369834.76737]}","{'mean_env_wait_ms': 13.66321951920477, 'mean_processing_ms': 2.116051081850654, 'mean_inference_ms': 1.8065554903873982}",{},0,8000,"{'sample_time_ms': 68368.566, 'sample_throughput': 58.506, 'learn_time_ms': 17208.93, 'learn_throughput': 232.437}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.2, 'cur_lr': 0.001, 'total_loss': 6876129629569024.0, 'policy_loss': -0.003548729175236076, 'vf_loss': 6876129629569024.0, 'vf_explained_var': -5.2154064e-08, 'kl': 0.020856492905295454, 'entropy': 1.3766059912741184, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.2, 'cur_lr': 0.001, 'total_loss': 1.4772554744987648e+16, 'policy_loss': -0.0017031524621415883, 'vf_loss': 1.4772554744987648e+16, 'vf_explained_var': -8.940697e-08, 'kl': 0.009587877597368788, 'entropy': 1.5185868181288242, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 8000, 'num_steps_trained': 8000}",False,2,2,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-32-07,1615735927,81.70154190063477,171.15365195274353,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",171.15365195274353,0,2,"{'cpu_util_percent': 31.095652173913038, 'ram_util_percent': 52.347826086956516}"
4,2,MARL,gneJ12,False,-17245191149.60162,-36111550162.55191,-23844831130.367897,2903.25,2,-15240038567.286163,-4873195201.312979,-7839190178.622966,{},"{'episode_reward': [-36111550162.55191, -17245191149.60162, -22499901518.185413, -19522681691.132637], 'episode_lengths': [2947, 2353, 3314, 2999], 'policy_gneJ12_reward': [-15240038567.286163, -4873195201.312979, -6015531683.418047, -5227995262.474674], 'policy_light1_reward': [-20871511595.26586, -12371995948.288662, -16484369834.76737, -14294686428.657932]}","{'mean_env_wait_ms': 13.314200048432609, 'mean_processing_ms': 2.3629510868872408, 'mean_inference_ms': 1.8100316984571967}",{},0,12000,"{'sample_time_ms': 69594.378, 'sample_throughput': 57.476, 'learn_time_ms': 17151.922, 'learn_throughput': 233.21}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.30000000000000004, 'cur_lr': 0.001, 'total_loss': 5062818143404032.0, 'policy_loss': -0.009872873866697773, 'vf_loss': 5062818143404032.0, 'vf_explained_var': 2.0489097e-08, 'kl': 0.02044680350809358, 'entropy': 1.3742020949721336, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.2, 'cur_lr': 0.001, 'total_loss': 1.3671861464334336e+16, 'policy_loss': -0.008656458026962355, 'vf_loss': 1.3671861464334336e+16, 'vf_explained_var': 5.2154064e-08, 'kl': 0.016239213582593948, 'entropy': 1.5560286082327366, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 12000, 'num_steps_trained': 12000}",False,4,3,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-33-36,1615736016,89.0836091041565,260.2372610569,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",260.2372610569,0,3,"{'cpu_util_percent': 29.4976, 'ram_util_percent': 52.33919999999999}"
5,2,MARL,light1,False,-17245191149.60162,-36111550162.55191,-23844831130.367897,2903.25,2,-20871511595.26586,-12371995948.288662,-16005640951.744957,{},"{'episode_reward': [-36111550162.55191, -17245191149.60162, -22499901518.185413, -19522681691.132637], 'episode_lengths': [2947, 2353, 3314, 2999], 'policy_gneJ12_reward': [-15240038567.286163, -4873195201.312979, -6015531683.418047, -5227995262.474674], 'policy_light1_reward': [-20871511595.26586, -12371995948.288662, -16484369834.76737, -14294686428.657932]}","{'mean_env_wait_ms': 13.314200048432609, 'mean_processing_ms': 2.3629510868872408, 'mean_inference_ms': 1.8100316984571967}",{},0,12000,"{'sample_time_ms': 69594.378, 'sample_throughput': 57.476, 'learn_time_ms': 17151.922, 'learn_throughput': 233.21}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.30000000000000004, 'cur_lr': 0.001, 'total_loss': 5062818143404032.0, 'policy_loss': -0.009872873866697773, 'vf_loss': 5062818143404032.0, 'vf_explained_var': 2.0489097e-08, 'kl': 0.02044680350809358, 'entropy': 1.3742020949721336, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.2, 'cur_lr': 0.001, 'total_loss': 1.3671861464334336e+16, 'policy_loss': -0.008656458026962355, 'vf_loss': 1.3671861464334336e+16, 'vf_explained_var': 5.2154064e-08, 'kl': 0.016239213582593948, 'entropy': 1.5560286082327366, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 12000, 'num_steps_trained': 12000}",False,4,3,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-33-36,1615736016,89.0836091041565,260.2372610569,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",260.2372610569,0,3,"{'cpu_util_percent': 29.4976, 'ram_util_percent': 52.33919999999999}"
6,3,MARL,gneJ12,False,-15767598036.95368,-36111550162.55191,-22229384511.68505,2892.2,1,-15240038567.286163,-3361593945.652061,-6943670932.028786,{},"{'episode_reward': [-15767598036.95368, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162], 'episode_lengths': [2848, 3314, 2999, 2947, 2353], 'policy_gneJ12_reward': [-3361593945.652061, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979], 'policy_light1_reward': [-12406004091.301584, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662]}","{'mean_env_wait_ms': 13.188366897064924, 'mean_processing_ms': 2.37733395680318, 'mean_inference_ms': 1.8100774960701869}",{},0,16000,"{'sample_time_ms': 67758.831, 'sample_throughput': 59.033, 'learn_time_ms': 17107.187, 'learn_throughput': 233.82}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 586024347500544.0, 'policy_loss': -0.011053346854168922, 'vf_loss': 586024347500544.0, 'vf_explained_var': -8.940697e-08, 'kl': 0.01802778337150812, 'entropy': 1.5167115181684494, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.2, 'cur_lr': 0.001, 'total_loss': 7429801010790400.0, 'policy_loss': -0.009043875703355297, 'vf_loss': 7429801010790400.0, 'vf_explained_var': -1.4901161e-08, 'kl': 0.012454669464204926, 'entropy': 1.5304666683077812, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 16000, 'num_steps_trained': 16000}",False,5,4,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-34-56,1615736096,79.22524499893188,339.4625060558319,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",339.4625060558319,0,4,"{'cpu_util_percent': 30.57567567567568, 'ram_util_percent': 52.37117117117116}"
7,3,MARL,light1,False,-15767598036.95368,-36111550162.55191,-22229384511.68505,2892.2,1,-20871511595.26586,-12371995948.288662,-15285713579.65628,{},"{'episode_reward': [-15767598036.95368, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162], 'episode_lengths': [2848, 3314, 2999, 2947, 2353], 'policy_gneJ12_reward': [-3361593945.652061, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979], 'policy_light1_reward': [-12406004091.301584, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662]}","{'mean_env_wait_ms': 13.188366897064924, 'mean_processing_ms': 2.37733395680318, 'mean_inference_ms': 1.8100774960701869}",{},0,16000,"{'sample_time_ms': 67758.831, 'sample_throughput': 59.033, 'learn_time_ms': 17107.187, 'learn_throughput': 233.82}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 586024347500544.0, 'policy_loss': -0.011053346854168922, 'vf_loss': 586024347500544.0, 'vf_explained_var': -8.940697e-08, 'kl': 0.01802778337150812, 'entropy': 1.5167115181684494, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.2, 'cur_lr': 0.001, 'total_loss': 7429801010790400.0, 'policy_loss': -0.009043875703355297, 'vf_loss': 7429801010790400.0, 'vf_explained_var': -1.4901161e-08, 'kl': 0.012454669464204926, 'entropy': 1.5304666683077812, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 16000, 'num_steps_trained': 16000}",False,5,4,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-34-56,1615736096,79.22524499893188,339.4625060558319,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",339.4625060558319,0,4,"{'cpu_util_percent': 30.57567567567568, 'ram_util_percent': 52.37117117117116}"
8,4,MARL,gneJ12,False,-6816838214.453951,-36111550162.55191,-18123545329.135246,2627.714285714286,2,-15240038567.286163,-1364514198.155023,-5403092743.2087145,{},"{'episode_reward': [-8901056531.067524, -6816838214.453951, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368], 'episode_lengths': [1748, 2185, 3314, 2999, 2947, 2353, 2848], 'policy_gneJ12_reward': [-1738780344.1620493, -1364514198.155023, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061], 'policy_light1_reward': [-7162276186.905483, -5452324016.298927, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584]}","{'mean_env_wait_ms': 12.980626757178543, 'mean_processing_ms': 2.458811408663607, 'mean_inference_ms': 1.808932259766438}",{},0,20000,"{'sample_time_ms': 67756.549, 'sample_throughput': 59.035, 'learn_time_ms': 17038.262, 'learn_throughput': 234.766}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 346667104075776.0, 'policy_loss': 0.0005257372104097158, 'vf_loss': 346667104075776.0, 'vf_explained_var': 0.0, 'kl': 0.034951726120198146, 'entropy': 1.355736631900072, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.2, 'cur_lr': 0.001, 'total_loss': 4952829399662592.0, 'policy_loss': -0.004632084834156558, 'vf_loss': 4952829399662592.0, 'vf_explained_var': -1.1175871e-08, 'kl': 0.021796163549879566, 'entropy': 1.4219346232712269, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 20000, 'num_steps_trained': 20000}",False,7,5,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-36-20,1615736180,84.5103189945221,423.972825050354,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",423.972825050354,0,5,"{'cpu_util_percent': 29.609243697478995, 'ram_util_percent': 52.34789915966386}"
9,4,MARL,light1,False,-6816838214.453951,-36111550162.55191,-18123545329.135246,2627.714285714286,2,-20871511595.26586,-5452324016.298927,-12720452585.926546,{},"{'episode_reward': [-8901056531.067524, -6816838214.453951, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368], 'episode_lengths': [1748, 2185, 3314, 2999, 2947, 2353, 2848], 'policy_gneJ12_reward': [-1738780344.1620493, -1364514198.155023, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061], 'policy_light1_reward': [-7162276186.905483, -5452324016.298927, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584]}","{'mean_env_wait_ms': 12.980626757178543, 'mean_processing_ms': 2.458811408663607, 'mean_inference_ms': 1.808932259766438}",{},0,20000,"{'sample_time_ms': 67756.549, 'sample_throughput': 59.035, 'learn_time_ms': 17038.262, 'learn_throughput': 234.766}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 346667104075776.0, 'policy_loss': 0.0005257372104097158, 'vf_loss': 346667104075776.0, 'vf_explained_var': 0.0, 'kl': 0.034951726120198146, 'entropy': 1.355736631900072, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.2, 'cur_lr': 0.001, 'total_loss': 4952829399662592.0, 'policy_loss': -0.004632084834156558, 'vf_loss': 4952829399662592.0, 'vf_explained_var': -1.1175871e-08, 'kl': 0.021796163549879566, 'entropy': 1.4219346232712269, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 20000, 'num_steps_trained': 20000}",False,7,5,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-36-20,1615736180,84.5103189945221,423.972825050354,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",423.972825050354,0,5,"{'cpu_util_percent': 29.609243697478995, 'ram_util_percent': 52.34789915966386}"
10,5,MARL,gneJ12,True,-6816838214.453951,-36111550162.55191,-17379233668.994694,2651.6666666666665,2,-15240038567.286163,-1364514198.155023,-4813246886.241198,{},"{'episode_reward': [-13014368030.96041, -16533917686.045094, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951], 'episode_lengths': [2920, 2551, 3314, 2999, 2947, 2353, 2848, 1748, 2185], 'policy_gneJ12_reward': [-2352689390.238283, -3144883383.4714975, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023], 'policy_light1_reward': [-10661678640.722157, -13389034302.573643, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927]}","{'mean_env_wait_ms': 12.856280491516083, 'mean_processing_ms': 2.5371795121911136, 'mean_inference_ms': 1.8093932521963754}",{},0,24000,"{'sample_time_ms': 68210.72, 'sample_throughput': 58.642, 'learn_time_ms': 16991.657, 'learn_throughput': 235.41}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 638510668185600.0, 'policy_loss': -0.009681226772954687, 'vf_loss': 638510668185600.0, 'vf_explained_var': -6.7055225e-08, 'kl': 0.01662558580574114, 'entropy': 1.4903664588928223, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.30000000000000004, 'cur_lr': 0.001, 'total_loss': 9195526775898112.0, 'policy_loss': -0.007885440136305988, 'vf_loss': 9195526775898112.0, 'vf_explained_var': 4.284084e-08, 'kl': 0.018718210514634848, 'entropy': 1.426792811602354, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 24000, 'num_steps_trained': 24000}",False,9,6,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-37-48,1615736268,87.24014091491699,511.212965965271,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",511.212965965271,0,6,"{'cpu_util_percent': 29.822131147540983, 'ram_util_percent': 52.39672131147539}"
11,5,MARL,light1,True,-6816838214.453951,-36111550162.55191,-17379233668.994694,2651.6666666666665,2,-20871511595.26586,-5452324016.298927,-12565986782.753513,{},"{'episode_reward': [-13014368030.96041, -16533917686.045094, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951], 'episode_lengths': [2920, 2551, 3314, 2999, 2947, 2353, 2848, 1748, 2185], 'policy_gneJ12_reward': [-2352689390.238283, -3144883383.4714975, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023], 'policy_light1_reward': [-10661678640.722157, -13389034302.573643, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927]}","{'mean_env_wait_ms': 12.856280491516083, 'mean_processing_ms': 2.5371795121911136, 'mean_inference_ms': 1.8093932521963754}",{},0,24000,"{'sample_time_ms': 68210.72, 'sample_throughput': 58.642, 'learn_time_ms': 16991.657, 'learn_throughput': 235.41}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 638510668185600.0, 'policy_loss': -0.009681226772954687, 'vf_loss': 638510668185600.0, 'vf_explained_var': -6.7055225e-08, 'kl': 0.01662558580574114, 'entropy': 1.4903664588928223, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.30000000000000004, 'cur_lr': 0.001, 'total_loss': 9195526775898112.0, 'policy_loss': -0.007885440136305988, 'vf_loss': 9195526775898112.0, 'vf_explained_var': 4.284084e-08, 'kl': 0.018718210514634848, 'entropy': 1.426792811602354, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 24000, 'num_steps_trained': 24000}",False,9,6,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-37-48,1615736268,87.24014091491699,511.212965965271,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",511.212965965271,0,6,"{'cpu_util_percent': 29.822131147540983, 'ram_util_percent': 52.39672131147539}"
12,6,MARL,gneJ12,False,-6816838214.453951,-36111550162.55191,-16911508934.08012,2615.7,1,-15240038567.286163,-1364514198.155023,-4656602806.459711,{},"{'episode_reward': [-12701986319.848959, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094], 'episode_lengths': [2292, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551], 'policy_gneJ12_reward': [-3246806088.4263425, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975], 'policy_light1_reward': [-9455180231.42261, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643]}","{'mean_env_wait_ms': 12.805110088541605, 'mean_processing_ms': 2.5516666916354964, 'mean_inference_ms': 1.809174547496329}",{},0,28000,"{'sample_time_ms': 67371.186, 'sample_throughput': 59.373, 'learn_time_ms': 17049.098, 'learn_throughput': 234.617}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 1718277541724160.0, 'policy_loss': -0.012585076707182452, 'vf_loss': 1718277541724160.0, 'vf_explained_var': 1.3038516e-08, 'kl': 0.012775048162438907, 'entropy': 1.2182236947119236, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.30000000000000004, 'cur_lr': 0.001, 'total_loss': 1.2930515581534208e+16, 'policy_loss': -0.00021289094001986086, 'vf_loss': 1.2930515581534208e+16, 'vf_explained_var': 3.7252903e-08, 'kl': 0.011865647487866227, 'entropy': 1.3305615447461605, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 28000, 'num_steps_trained': 28000}",False,10,7,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-39-07,1615736347,79.72780990600586,590.9407758712769,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",590.9407758712769,0,7,"{'cpu_util_percent': 31.655357142857145, 'ram_util_percent': 52.419642857142854}"
13,6,MARL,light1,False,-6816838214.453951,-36111550162.55191,-16911508934.08012,2615.7,1,-20871511595.26586,-5452324016.298927,-12254906127.620424,{},"{'episode_reward': [-12701986319.848959, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094], 'episode_lengths': [2292, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551], 'policy_gneJ12_reward': [-3246806088.4263425, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975], 'policy_light1_reward': [-9455180231.42261, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643]}","{'mean_env_wait_ms': 12.805110088541605, 'mean_processing_ms': 2.5516666916354964, 'mean_inference_ms': 1.809174547496329}",{},0,28000,"{'sample_time_ms': 67371.186, 'sample_throughput': 59.373, 'learn_time_ms': 17049.098, 'learn_throughput': 234.617}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 1718277541724160.0, 'policy_loss': -0.012585076707182452, 'vf_loss': 1718277541724160.0, 'vf_explained_var': 1.3038516e-08, 'kl': 0.012775048162438907, 'entropy': 1.2182236947119236, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.30000000000000004, 'cur_lr': 0.001, 'total_loss': 1.2930515581534208e+16, 'policy_loss': -0.00021289094001986086, 'vf_loss': 1.2930515581534208e+16, 'vf_explained_var': 3.7252903e-08, 'kl': 0.011865647487866227, 'entropy': 1.3305615447461605, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 28000, 'num_steps_trained': 28000}",False,10,7,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-39-07,1615736347,79.72780990600586,590.9407758712769,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",590.9407758712769,0,7,"{'cpu_util_percent': 31.655357142857145, 'ram_util_percent': 52.419642857142854}"
14,7,MARL,gneJ12,False,-6816838214.453951,-36111550162.55191,-18455465679.597454,2660.0,2,-15240038567.286163,-1364514198.155023,-5104394486.33679,{},"{'episode_reward': [-30696007864.268707, -21654490950.09948, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959], 'episode_lengths': [3178, 2585, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292], 'policy_gneJ12_reward': [-8220127774.960614, -6466577996.483743, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425], 'policy_light1_reward': [-22475880089.308098, -15187912953.615782, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261]}","{'mean_env_wait_ms': 12.747193853501201, 'mean_processing_ms': 2.596726796754299, 'mean_inference_ms': 1.8141375401070796}",{},0,32000,"{'sample_time_ms': 68510.514, 'sample_throughput': 58.385, 'learn_time_ms': 17285.653, 'learn_throughput': 231.406}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 3885410639937536.0, 'policy_loss': -0.0030405374709516764, 'vf_loss': 3885410639937536.0, 'vf_explained_var': 7.450581e-09, 'kl': 0.009307710068242159, 'entropy': 1.2845662757754326, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.30000000000000004, 'cur_lr': 0.001, 'total_loss': 1.6584508467838976e+16, 'policy_loss': 0.005150569835677743, 'vf_loss': 1.6584508467838976e+16, 'vf_explained_var': -1.0430813e-07, 'kl': 0.013419246693956666, 'entropy': 1.2503741383552551, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 32000, 'num_steps_trained': 32000}",False,12,8,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-40-43,1615736443,95.42679381370544,686.3675696849823,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",686.3675696849823,0,8,"{'cpu_util_percent': 39.77969924812031, 'ram_util_percent': 52.596240601503766}"
15,7,MARL,light1,False,-6816838214.453951,-36111550162.55191,-18455465679.597454,2660.0,2,-22475880089.308098,-5452324016.298927,-13351071193.260675,{},"{'episode_reward': [-30696007864.268707, -21654490950.09948, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959], 'episode_lengths': [3178, 2585, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292], 'policy_gneJ12_reward': [-8220127774.960614, -6466577996.483743, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425], 'policy_light1_reward': [-22475880089.308098, -15187912953.615782, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261]}","{'mean_env_wait_ms': 12.747193853501201, 'mean_processing_ms': 2.596726796754299, 'mean_inference_ms': 1.8141375401070796}",{},0,32000,"{'sample_time_ms': 68510.514, 'sample_throughput': 58.385, 'learn_time_ms': 17285.653, 'learn_throughput': 231.406}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 3885410639937536.0, 'policy_loss': -0.0030405374709516764, 'vf_loss': 3885410639937536.0, 'vf_explained_var': 7.450581e-09, 'kl': 0.009307710068242159, 'entropy': 1.2845662757754326, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.30000000000000004, 'cur_lr': 0.001, 'total_loss': 1.6584508467838976e+16, 'policy_loss': 0.005150569835677743, 'vf_loss': 1.6584508467838976e+16, 'vf_explained_var': -1.0430813e-07, 'kl': 0.013419246693956666, 'entropy': 1.2503741383552551, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 32000, 'num_steps_trained': 32000}",False,12,8,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-40-43,1615736443,95.42679381370544,686.3675696849823,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",686.3675696849823,0,8,"{'cpu_util_percent': 39.77969924812031, 'ram_util_percent': 52.596240601503766}"
16,8,MARL,gneJ12,False,-6816838214.453951,-36111550162.55191,-17884326618.93121,2637.6923076923076,1,-15240038567.286163,-1364514198.155023,-4887360037.326379,{},"{'episode_reward': [-11030657890.936306, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948], 'episode_lengths': [2370, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585], 'policy_gneJ12_reward': [-2282946649.2014513, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743], 'policy_light1_reward': [-8747711241.734858, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782]}","{'mean_env_wait_ms': 12.725625572155481, 'mean_processing_ms': 2.607137736083405, 'mean_inference_ms': 1.817758301308727}",{},0,36000,"{'sample_time_ms': 68276.471, 'sample_throughput': 58.585, 'learn_time_ms': 17320.632, 'learn_throughput': 230.938}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 329289976774656.0, 'policy_loss': -0.010664202272891998, 'vf_loss': 329289976774656.0, 'vf_explained_var': 3.5390258e-08, 'kl': 0.020359708432806656, 'entropy': 1.1131328213959932, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.30000000000000004, 'cur_lr': 0.001, 'total_loss': 3820794845069312.0, 'policy_loss': 0.000585192465223372, 'vf_loss': 3820794845069312.0, 'vf_explained_var': 2.7939677e-08, 'kl': 0.022455859783804044, 'entropy': 1.1658661849796772, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 36000, 'num_steps_trained': 36000}",False,13,9,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-42-07,1615736527,84.00741815567017,770.3749878406525,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",770.3749878406525,0,9,"{'cpu_util_percent': 39.82288135593219, 'ram_util_percent': 52.623728813559346}"
17,8,MARL,light1,False,-6816838214.453951,-36111550162.55191,-17884326618.93121,2637.6923076923076,1,-22475880089.308098,-5452324016.298927,-12996966581.604845,{},"{'episode_reward': [-11030657890.936306, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948], 'episode_lengths': [2370, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585], 'policy_gneJ12_reward': [-2282946649.2014513, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743], 'policy_light1_reward': [-8747711241.734858, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782]}","{'mean_env_wait_ms': 12.725625572155481, 'mean_processing_ms': 2.607137736083405, 'mean_inference_ms': 1.817758301308727}",{},0,36000,"{'sample_time_ms': 68276.471, 'sample_throughput': 58.585, 'learn_time_ms': 17320.632, 'learn_throughput': 230.938}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 329289976774656.0, 'policy_loss': -0.010664202272891998, 'vf_loss': 329289976774656.0, 'vf_explained_var': 3.5390258e-08, 'kl': 0.020359708432806656, 'entropy': 1.1131328213959932, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.30000000000000004, 'cur_lr': 0.001, 'total_loss': 3820794845069312.0, 'policy_loss': 0.000585192465223372, 'vf_loss': 3820794845069312.0, 'vf_explained_var': 2.7939677e-08, 'kl': 0.022455859783804044, 'entropy': 1.1658661849796772, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 36000, 'num_steps_trained': 36000}",False,13,9,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-42-07,1615736527,84.00741815567017,770.3749878406525,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",770.3749878406525,0,9,"{'cpu_util_percent': 39.82288135593219, 'ram_util_percent': 52.623728813559346}"
18,9,MARL,gneJ12,False,-4291906933.4735136,-36111550162.55191,-16913439498.541376,2667.3571428571427,1,-15240038567.286163,-813198609.6003428,-4596348506.77452,{},"{'episode_reward': [-4291906933.4735136, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306], 'episode_lengths': [3053, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370], 'policy_gneJ12_reward': [-813198609.6003428, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513], 'policy_light1_reward': [-3478708323.8731723, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858]}","{'mean_env_wait_ms': 12.709352704072696, 'mean_processing_ms': 2.6110654517745084, 'mean_inference_ms': 1.8222512327489895}",{},0,40000,"{'sample_time_ms': 68198.684, 'sample_throughput': 58.652, 'learn_time_ms': 17341.391, 'learn_throughput': 230.662}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 274202076643328.0, 'policy_loss': -0.005715127743314952, 'vf_loss': 274202076643328.0, 'vf_explained_var': -2.9802322e-08, 'kl': 0.009055962022102904, 'entropy': 1.1288293823599815, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 6918652909584384.0, 'policy_loss': 0.0030445205338764936, 'vf_loss': 6918652909584384.0, 'vf_explained_var': 3.7252903e-09, 'kl': 0.007058118921122514, 'entropy': 1.3489003777503967, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 40000, 'num_steps_trained': 40000}",False,14,10,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-43-32,1615736612,85.02670192718506,855.4016897678375,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",855.4016897678375,0,10,"{'cpu_util_percent': 39.54201680672269, 'ram_util_percent': 52.61848739495802}"
19,9,MARL,light1,False,-4291906933.4735136,-36111550162.55191,-16913439498.541376,2667.3571428571427,1,-22475880089.308098,-3478708323.8731723,-12317090991.766867,{},"{'episode_reward': [-4291906933.4735136, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306], 'episode_lengths': [3053, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370], 'policy_gneJ12_reward': [-813198609.6003428, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513], 'policy_light1_reward': [-3478708323.8731723, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858]}","{'mean_env_wait_ms': 12.709352704072696, 'mean_processing_ms': 2.6110654517745084, 'mean_inference_ms': 1.8222512327489895}",{},0,40000,"{'sample_time_ms': 68198.684, 'sample_throughput': 58.652, 'learn_time_ms': 17341.391, 'learn_throughput': 230.662}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 274202076643328.0, 'policy_loss': -0.005715127743314952, 'vf_loss': 274202076643328.0, 'vf_explained_var': -2.9802322e-08, 'kl': 0.009055962022102904, 'entropy': 1.1288293823599815, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 6918652909584384.0, 'policy_loss': 0.0030445205338764936, 'vf_loss': 6918652909584384.0, 'vf_explained_var': 3.7252903e-09, 'kl': 0.007058118921122514, 'entropy': 1.3489003777503967, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 40000, 'num_steps_trained': 40000}",False,14,10,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-43-32,1615736612,85.02670192718506,855.4016897678375,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",855.4016897678375,0,10,"{'cpu_util_percent': 39.54201680672269, 'ram_util_percent': 52.61848739495802}"
20,10,MARL,gneJ12,True,-4291906933.4735136,-36111550162.55191,-16519714516.424454,2642.3125,2,-15240038567.286163,-813198609.6003428,-4334482595.899072,{},"{'episode_reward': [-15188900474.907383, -12338378808.304688, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136], 'episode_lengths': [2676, 2258, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053], 'policy_gneJ12_reward': [-2190723832.6470366, -2812118606.894831, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428], 'policy_light1_reward': [-12998176642.26039, -9526260201.409876, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723]}","{'mean_env_wait_ms': 12.68292677613945, 'mean_processing_ms': 2.6312599395650147, 'mean_inference_ms': 1.8298111461029567}",{},0,44000,"{'sample_time_ms': 68272.731, 'sample_throughput': 58.589, 'learn_time_ms': 17321.508, 'learn_throughput': 230.927}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 752031360876544.0, 'policy_loss': -0.010024928720667958, 'vf_loss': 752031360876544.0, 'vf_explained_var': 3.7252903e-09, 'kl': 0.0064055691109388135, 'entropy': 1.330921959131956, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 7899713030324224.0, 'policy_loss': -0.005568786145886406, 'vf_loss': 7899713030324224.0, 'vf_explained_var': -5.5879354e-08, 'kl': 0.010013436418375932, 'entropy': 1.5364682748913765, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 44000, 'num_steps_trained': 44000}",False,16,11,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-45-02,1615736702,89.9944839477539,945.3961737155914,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",945.3961737155914,0,11,"{'cpu_util_percent': 32.853968253968254, 'ram_util_percent': 52.50476190476188}"
21,10,MARL,light1,True,-4291906933.4735136,-36111550162.55191,-16519714516.424454,2642.3125,2,-22475880089.308098,-3478708323.8731723,-12185231920.5254,{},"{'episode_reward': [-15188900474.907383, -12338378808.304688, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136], 'episode_lengths': [2676, 2258, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053], 'policy_gneJ12_reward': [-2190723832.6470366, -2812118606.894831, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428], 'policy_light1_reward': [-12998176642.26039, -9526260201.409876, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723]}","{'mean_env_wait_ms': 12.68292677613945, 'mean_processing_ms': 2.6312599395650147, 'mean_inference_ms': 1.8298111461029567}",{},0,44000,"{'sample_time_ms': 68272.731, 'sample_throughput': 58.589, 'learn_time_ms': 17321.508, 'learn_throughput': 230.927}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 752031360876544.0, 'policy_loss': -0.010024928720667958, 'vf_loss': 752031360876544.0, 'vf_explained_var': 3.7252903e-09, 'kl': 0.0064055691109388135, 'entropy': 1.330921959131956, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 7899713030324224.0, 'policy_loss': -0.005568786145886406, 'vf_loss': 7899713030324224.0, 'vf_explained_var': -5.5879354e-08, 'kl': 0.010013436418375932, 'entropy': 1.5364682748913765, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 44000, 'num_steps_trained': 44000}",False,16,11,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-45-02,1615736702,89.9944839477539,945.3961737155914,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",945.3961737155914,0,11,"{'cpu_util_percent': 32.853968253968254, 'ram_util_percent': 52.50476190476188}"
22,11,MARL,gneJ12,False,-4291906933.4735136,-36111550162.55191,-16266237874.453749,2646.4444444444443,2,-15240038567.286163,-813198609.6003428,-4184312434.5402594,{},"{'episode_reward': [-14714738308.336655, -13762111169.039543, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688], 'episode_lengths': [2533, 2826, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258], 'policy_gneJ12_reward': [-3218238079.6890216, -2747664207.650495, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831], 'policy_light1_reward': [-11496500228.6477, -11014446961.389086, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876]}","{'mean_env_wait_ms': 12.655228395668424, 'mean_processing_ms': 2.6578702670444425, 'mean_inference_ms': 1.8346375599023088}",{},0,48000,"{'sample_time_ms': 68822.168, 'sample_throughput': 58.121, 'learn_time_ms': 17230.578, 'learn_throughput': 232.145}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 450937167544320.0, 'policy_loss': -0.004356494871899486, 'vf_loss': 450937167544320.0, 'vf_explained_var': -7.450581e-09, 'kl': 0.010216708920779638, 'entropy': 1.2663931921124458, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 5965104470294528.0, 'policy_loss': -0.015579284270643257, 'vf_loss': 5965104470294528.0, 'vf_explained_var': -2.6077032e-08, 'kl': 0.011313767448882572, 'entropy': 1.6025325991213322, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 48000, 'num_steps_trained': 48000}",False,18,12,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-46-28,1615736788,86.2869668006897,1031.6831405162811,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1031.6831405162811,0,12,"{'cpu_util_percent': 28.66198347107438, 'ram_util_percent': 52.39504132231403}"
23,11,MARL,light1,False,-4291906933.4735136,-36111550162.55191,-16266237874.453749,2646.4444444444443,2,-22475880089.308098,-3478708323.8731723,-12081925439.91351,{},"{'episode_reward': [-14714738308.336655, -13762111169.039543, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688], 'episode_lengths': [2533, 2826, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258], 'policy_gneJ12_reward': [-3218238079.6890216, -2747664207.650495, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831], 'policy_light1_reward': [-11496500228.6477, -11014446961.389086, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876]}","{'mean_env_wait_ms': 12.655228395668424, 'mean_processing_ms': 2.6578702670444425, 'mean_inference_ms': 1.8346375599023088}",{},0,48000,"{'sample_time_ms': 68822.168, 'sample_throughput': 58.121, 'learn_time_ms': 17230.578, 'learn_throughput': 232.145}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 450937167544320.0, 'policy_loss': -0.004356494871899486, 'vf_loss': 450937167544320.0, 'vf_explained_var': -7.450581e-09, 'kl': 0.010216708920779638, 'entropy': 1.2663931921124458, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 5965104470294528.0, 'policy_loss': -0.015579284270643257, 'vf_loss': 5965104470294528.0, 'vf_explained_var': -2.6077032e-08, 'kl': 0.011313767448882572, 'entropy': 1.6025325991213322, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 48000, 'num_steps_trained': 48000}",False,18,12,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-46-28,1615736788,86.2869668006897,1031.6831405162811,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1031.6831405162811,0,12,"{'cpu_util_percent': 28.66198347107438, 'ram_util_percent': 52.39504132231403}"
24,12,MARL,gneJ12,False,-4291906933.4735136,-36111550162.55191,-15701331046.49584,2605.5789473684213,1,-15240038567.286163,-769453938.434237,-4004583040.008363,{},"{'episode_reward': [-5533008143.253435, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543], 'episode_lengths': [1870, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826], 'policy_gneJ12_reward': [-769453938.434237, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495], 'policy_light1_reward': [-4763554204.819202, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086]}","{'mean_env_wait_ms': 12.639888367741994, 'mean_processing_ms': 2.665424936324901, 'mean_inference_ms': 1.8363541719966254}",{},0,52000,"{'sample_time_ms': 67736.751, 'sample_throughput': 59.052, 'learn_time_ms': 17148.841, 'learn_throughput': 233.252}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 125692283977728.0, 'policy_loss': -0.012859988259151578, 'vf_loss': 125692283977728.0, 'vf_explained_var': -2.6077032e-08, 'kl': 0.011436918364779558, 'entropy': 1.0783793590962887, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 2141291039162368.0, 'policy_loss': -0.010008932062191889, 'vf_loss': 2141291039162368.0, 'vf_explained_var': 2.0489097e-08, 'kl': 0.013215944360126741, 'entropy': 1.4154021702706814, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 52000, 'num_steps_trained': 52000}",False,19,13,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-47-46,1615736866,77.41244101524353,1109.0955815315247,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1109.0955815315247,0,13,"{'cpu_util_percent': 31.1537037037037, 'ram_util_percent': 52.39999999999997}"
25,12,MARL,light1,False,-4291906933.4735136,-36111550162.55191,-15701331046.49584,2605.5789473684213,1,-22475880089.308098,-3478708323.8731723,-11696748006.487495,{},"{'episode_reward': [-5533008143.253435, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543], 'episode_lengths': [1870, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826], 'policy_gneJ12_reward': [-769453938.434237, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495], 'policy_light1_reward': [-4763554204.819202, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086]}","{'mean_env_wait_ms': 12.639888367741994, 'mean_processing_ms': 2.665424936324901, 'mean_inference_ms': 1.8363541719966254}",{},0,52000,"{'sample_time_ms': 67736.751, 'sample_throughput': 59.052, 'learn_time_ms': 17148.841, 'learn_throughput': 233.252}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 125692283977728.0, 'policy_loss': -0.012859988259151578, 'vf_loss': 125692283977728.0, 'vf_explained_var': -2.6077032e-08, 'kl': 0.011436918364779558, 'entropy': 1.0783793590962887, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 2141291039162368.0, 'policy_loss': -0.010008932062191889, 'vf_loss': 2141291039162368.0, 'vf_explained_var': 2.0489097e-08, 'kl': 0.013215944360126741, 'entropy': 1.4154021702706814, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 52000, 'num_steps_trained': 52000}",False,19,13,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-47-46,1615736866,77.41244101524353,1109.0955815315247,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1109.0955815315247,0,13,"{'cpu_util_percent': 31.1537037037037, 'ram_util_percent': 52.39999999999997}"
26,13,MARL,gneJ12,False,-4291906933.4735136,-36111550162.55191,-14947992652.063847,2636.5238095238096,2,-15240038567.286163,-769453938.434237,-3771482980.4965553,{},"{'episode_reward': [-6516083011.275359, -9066472798.644518, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435], 'episode_lengths': [2923, 2938, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870], 'policy_gneJ12_reward': [-1344690942.973757, -1769373887.294995, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237], 'policy_light1_reward': [-5171392068.301593, -7297098911.349546, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202]}","{'mean_env_wait_ms': 12.608233241662813, 'mean_processing_ms': 2.684882858431507, 'mean_inference_ms': 1.838633414707151}",{},0,56000,"{'sample_time_ms': 68356.276, 'sample_throughput': 58.517, 'learn_time_ms': 17078.734, 'learn_throughput': 234.209}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 247493509513216.0, 'policy_loss': -0.018400449480395764, 'vf_loss': 247493509513216.0, 'vf_explained_var': 2.6077032e-08, 'kl': 0.007412528488202952, 'entropy': 1.1690650843083858, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 3276251762524160.0, 'policy_loss': -0.00533650946454145, 'vf_loss': 3276251762524160.0, 'vf_explained_var': -1.1175871e-07, 'kl': 0.011920859033125453, 'entropy': 1.4926629029214382, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 56000, 'num_steps_trained': 56000}",False,21,14,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-49-11,1615736951,84.7195827960968,1193.8151643276215,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1193.8151643276215,0,14,"{'cpu_util_percent': 28.26470588235294, 'ram_util_percent': 52.39999999999996}"
27,13,MARL,light1,False,-4291906933.4735136,-36111550162.55191,-14947992652.063847,2636.5238095238096,2,-22475880089.308098,-3478708323.8731723,-11176509671.567312,{},"{'episode_reward': [-6516083011.275359, -9066472798.644518, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435], 'episode_lengths': [2923, 2938, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870], 'policy_gneJ12_reward': [-1344690942.973757, -1769373887.294995, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237], 'policy_light1_reward': [-5171392068.301593, -7297098911.349546, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202]}","{'mean_env_wait_ms': 12.608233241662813, 'mean_processing_ms': 2.684882858431507, 'mean_inference_ms': 1.838633414707151}",{},0,56000,"{'sample_time_ms': 68356.276, 'sample_throughput': 58.517, 'learn_time_ms': 17078.734, 'learn_throughput': 234.209}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 247493509513216.0, 'policy_loss': -0.018400449480395764, 'vf_loss': 247493509513216.0, 'vf_explained_var': 2.6077032e-08, 'kl': 0.007412528488202952, 'entropy': 1.1690650843083858, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 3276251762524160.0, 'policy_loss': -0.00533650946454145, 'vf_loss': 3276251762524160.0, 'vf_explained_var': -1.1175871e-07, 'kl': 0.011920859033125453, 'entropy': 1.4926629029214382, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 56000, 'num_steps_trained': 56000}",False,21,14,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-49-11,1615736951,84.7195827960968,1193.8151643276215,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1193.8151643276215,0,14,"{'cpu_util_percent': 28.26470588235294, 'ram_util_percent': 52.39999999999996}"
28,14,MARL,gneJ12,False,-4291906933.4735136,-36111550162.55191,-14907898551.63734,2620.7272727272725,1,-15240038567.286163,-769453938.434237,-3734357655.6441298,{},"{'episode_reward': [-14065922442.680698, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518], 'episode_lengths': [2289, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938], 'policy_gneJ12_reward': [-2954725833.743199, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995], 'policy_light1_reward': [-11111196608.93751, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546]}","{'mean_env_wait_ms': 12.593348992938308, 'mean_processing_ms': 2.6907792964908195, 'mean_inference_ms': 1.8393696177074113}",{},0,60000,"{'sample_time_ms': 67875.8, 'sample_throughput': 58.931, 'learn_time_ms': 17085.655, 'learn_throughput': 234.115}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 651567169536000.0, 'policy_loss': 0.0002537672990001738, 'vf_loss': 651567169536000.0, 'vf_explained_var': -4.8428774e-08, 'kl': 0.012131711118854582, 'entropy': 1.3057188726961613, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 6512337712316416.0, 'policy_loss': -0.01734709000447765, 'vf_loss': 6512337712316416.0, 'vf_explained_var': -1.3038516e-08, 'kl': 0.013314523821463808, 'entropy': 1.5784959979355335, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 60000, 'num_steps_trained': 60000}",False,22,15,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-50-30,1615737030,79.77470278739929,1273.5898671150208,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1273.5898671150208,0,15,"{'cpu_util_percent': 29.76607142857143, 'ram_util_percent': 52.399999999999984}"
29,14,MARL,light1,False,-4291906933.4735136,-36111550162.55191,-14907898551.63734,2620.7272727272725,1,-22475880089.308098,-3478708323.8731723,-11173540895.993233,{},"{'episode_reward': [-14065922442.680698, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518], 'episode_lengths': [2289, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938], 'policy_gneJ12_reward': [-2954725833.743199, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995], 'policy_light1_reward': [-11111196608.93751, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546]}","{'mean_env_wait_ms': 12.593348992938308, 'mean_processing_ms': 2.6907792964908195, 'mean_inference_ms': 1.8393696177074113}",{},0,60000,"{'sample_time_ms': 67875.8, 'sample_throughput': 58.931, 'learn_time_ms': 17085.655, 'learn_throughput': 234.115}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 651567169536000.0, 'policy_loss': 0.0002537672990001738, 'vf_loss': 651567169536000.0, 'vf_explained_var': -4.8428774e-08, 'kl': 0.012131711118854582, 'entropy': 1.3057188726961613, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 6512337712316416.0, 'policy_loss': -0.01734709000447765, 'vf_loss': 6512337712316416.0, 'vf_explained_var': -1.3038516e-08, 'kl': 0.013314523821463808, 'entropy': 1.5784959979355335, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 60000, 'num_steps_trained': 60000}",False,22,15,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-50-30,1615737030,79.77470278739929,1273.5898671150208,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1273.5898671150208,0,15,"{'cpu_util_percent': 29.76607142857143, 'ram_util_percent': 52.399999999999984}"
30,15,MARL,gneJ12,True,-4291906933.4735136,-36111550162.55191,-14368118397.118357,2611.6666666666665,2,-15240038567.286163,-769453938.434237,-3542725764.8635354,{},"{'episode_reward': [-9887304431.805023, -6973768963.014075, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698], 'episode_lengths': [2689, 2335, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289], 'policy_gneJ12_reward': [-1609907313.875391, -1259642618.67862, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199], 'policy_light1_reward': [-8277397117.929639, -5714126344.335461, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751]}","{'mean_env_wait_ms': 12.563261439829438, 'mean_processing_ms': 2.7073502254824664, 'mean_inference_ms': 1.8402016517231836}",{},0,64000,"{'sample_time_ms': 67745.76, 'sample_throughput': 59.044, 'learn_time_ms': 17012.549, 'learn_throughput': 235.121}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 118950424215552.0, 'policy_loss': 0.002569032192695886, 'vf_loss': 118950424215552.0, 'vf_explained_var': 1.8626451e-08, 'kl': 0.01014784412109293, 'entropy': 1.0629288032650948, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 2106358522445824.0, 'policy_loss': -0.005589874985162169, 'vf_loss': 2106358522445824.0, 'vf_explained_var': 0.0, 'kl': 0.012672520635533147, 'entropy': 1.4130873940885067, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 64000, 'num_steps_trained': 64000}",False,24,16,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-51-56,1615737116,85.20869278907776,1358.7985599040985,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1358.7985599040985,0,16,"{'cpu_util_percent': 28.06302521008404, 'ram_util_percent': 52.400840336134415}"
31,15,MARL,light1,True,-4291906933.4735136,-36111550162.55191,-14368118397.118357,2611.6666666666665,2,-22475880089.308098,-3478708323.8731723,-10825392632.254839,{},"{'episode_reward': [-9887304431.805023, -6973768963.014075, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698], 'episode_lengths': [2689, 2335, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289], 'policy_gneJ12_reward': [-1609907313.875391, -1259642618.67862, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199], 'policy_light1_reward': [-8277397117.929639, -5714126344.335461, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751]}","{'mean_env_wait_ms': 12.563261439829438, 'mean_processing_ms': 2.7073502254824664, 'mean_inference_ms': 1.8402016517231836}",{},0,64000,"{'sample_time_ms': 67745.76, 'sample_throughput': 59.044, 'learn_time_ms': 17012.549, 'learn_throughput': 235.121}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 118950424215552.0, 'policy_loss': 0.002569032192695886, 'vf_loss': 118950424215552.0, 'vf_explained_var': 1.8626451e-08, 'kl': 0.01014784412109293, 'entropy': 1.0629288032650948, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 2106358522445824.0, 'policy_loss': -0.005589874985162169, 'vf_loss': 2106358522445824.0, 'vf_explained_var': 0.0, 'kl': 0.012672520635533147, 'entropy': 1.4130873940885067, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 64000, 'num_steps_trained': 64000}",False,24,16,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-51-56,1615737116,85.20869278907776,1358.7985599040985,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1358.7985599040985,0,16,"{'cpu_util_percent': 28.06302521008404, 'ram_util_percent': 52.400840336134415}"
32,16,MARL,gneJ12,False,-2702796301.4121284,-36111550162.55191,-13870382715.203451,2604.9615384615386,2,-15240038567.286163,-437585389.44147974,-3368829845.6648536,{},"{'episode_reward': [-2702796301.4121284, -13092312763.036932, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075], 'episode_lengths': [2025, 3024, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335], 'policy_gneJ12_reward': [-437585389.44147974, -2126572241.1198597, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862], 'policy_light1_reward': [-2265210911.970647, -10965740521.917059, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461]}","{'mean_env_wait_ms': 12.535925836536661, 'mean_processing_ms': 2.7262442884750566, 'mean_inference_ms': 1.8405932089770571}",{},0,68000,"{'sample_time_ms': 68541.305, 'sample_throughput': 58.359, 'learn_time_ms': 16914.389, 'learn_throughput': 236.485}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 208505315786752.0, 'policy_loss': -0.007595838396809995, 'vf_loss': 208505315786752.0, 'vf_explained_var': 4.656613e-08, 'kl': 0.00875845034897793, 'entropy': 1.1078433524817228, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 4065072930357248.0, 'policy_loss': 0.0040505963552277535, 'vf_loss': 4065072930357248.0, 'vf_explained_var': 5.7742e-08, 'kl': 0.007735337585472735, 'entropy': 1.6345899887382984, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 68000, 'num_steps_trained': 68000}",False,26,17,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-53-22,1615737202,86.70151877403259,1445.500078678131,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1445.500078678131,0,17,"{'cpu_util_percent': 28.152066115702482, 'ram_util_percent': 52.399999999999984}"
33,16,MARL,light1,False,-2702796301.4121284,-36111550162.55191,-13870382715.203451,2604.9615384615386,2,-22475880089.308098,-2265210911.970647,-10501552869.538609,{},"{'episode_reward': [-2702796301.4121284, -13092312763.036932, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075], 'episode_lengths': [2025, 3024, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335], 'policy_gneJ12_reward': [-437585389.44147974, -2126572241.1198597, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862], 'policy_light1_reward': [-2265210911.970647, -10965740521.917059, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461]}","{'mean_env_wait_ms': 12.535925836536661, 'mean_processing_ms': 2.7262442884750566, 'mean_inference_ms': 1.8405932089770571}",{},0,68000,"{'sample_time_ms': 68541.305, 'sample_throughput': 58.359, 'learn_time_ms': 16914.389, 'learn_throughput': 236.485}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 208505315786752.0, 'policy_loss': -0.007595838396809995, 'vf_loss': 208505315786752.0, 'vf_explained_var': 4.656613e-08, 'kl': 0.00875845034897793, 'entropy': 1.1078433524817228, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 4065072930357248.0, 'policy_loss': 0.0040505963552277535, 'vf_loss': 4065072930357248.0, 'vf_explained_var': 5.7742e-08, 'kl': 0.007735337585472735, 'entropy': 1.6345899887382984, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 68000, 'num_steps_trained': 68000}",False,26,17,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-53-22,1615737202,86.70151877403259,1445.500078678131,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1445.500078678131,0,17,"{'cpu_util_percent': 28.152066115702482, 'ram_util_percent': 52.399999999999984}"
34,17,MARL,gneJ12,False,-2702796301.4121284,-36111550162.55191,-13517297823.08922,2580.703703703704,1,-15240038567.286163,-437585389.44147974,-3270328275.697413,{},"{'episode_reward': [-4337090628.119313, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932], 'episode_lengths': [1950, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024], 'policy_gneJ12_reward': [-709287456.5439576, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597], 'policy_light1_reward': [-3627803171.575361, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059]}","{'mean_env_wait_ms': 12.523131115154737, 'mean_processing_ms': 2.7331042492347875, 'mean_inference_ms': 1.8406499402775724}",{},0,72000,"{'sample_time_ms': 67251.263, 'sample_throughput': 59.478, 'learn_time_ms': 16684.915, 'learn_throughput': 239.738}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 199281413718016.0, 'policy_loss': -0.01185759375221096, 'vf_loss': 199281413718016.0, 'vf_explained_var': 2.0489097e-08, 'kl': 0.008354561243322678, 'entropy': 1.1387143954634666, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 3846912415367168.0, 'policy_loss': -0.010166886408114806, 'vf_loss': 3846912415367168.0, 'vf_explained_var': -8.940697e-08, 'kl': 0.010922408095211722, 'entropy': 1.621810108423233, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 72000, 'num_steps_trained': 72000}",False,27,18,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-54-43,1615737283,80.23249912261963,1525.7325778007507,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1525.7325778007507,0,18,"{'cpu_util_percent': 30.61150442477876, 'ram_util_percent': 52.40088495575219}"
35,17,MARL,light1,False,-2702796301.4121284,-36111550162.55191,-13517297823.08922,2580.703703703704,1,-22475880089.308098,-2265210911.970647,-10246969547.391823,{},"{'episode_reward': [-4337090628.119313, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932], 'episode_lengths': [1950, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024], 'policy_gneJ12_reward': [-709287456.5439576, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597], 'policy_light1_reward': [-3627803171.575361, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059]}","{'mean_env_wait_ms': 12.523131115154737, 'mean_processing_ms': 2.7331042492347875, 'mean_inference_ms': 1.8406499402775724}",{},0,72000,"{'sample_time_ms': 67251.263, 'sample_throughput': 59.478, 'learn_time_ms': 16684.915, 'learn_throughput': 239.738}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 199281413718016.0, 'policy_loss': -0.01185759375221096, 'vf_loss': 199281413718016.0, 'vf_explained_var': 2.0489097e-08, 'kl': 0.008354561243322678, 'entropy': 1.1387143954634666, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 3846912415367168.0, 'policy_loss': -0.010166886408114806, 'vf_loss': 3846912415367168.0, 'vf_explained_var': -8.940697e-08, 'kl': 0.010922408095211722, 'entropy': 1.621810108423233, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 72000, 'num_steps_trained': 72000}",False,27,18,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-54-43,1615737283,80.23249912261963,1525.7325778007507,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1525.7325778007507,0,18,"{'cpu_util_percent': 30.61150442477876, 'ram_util_percent': 52.40088495575219}"
36,18,MARL,gneJ12,False,-2702796301.4121284,-36111550162.55191,-13244516052.72579,2561.0,2,-15240038567.286163,-437585389.44147974,-3155412645.419559,{},"{'episode_reward': [-10698663530.73486, -8425260774.904094, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313], 'episode_lengths': [2506, 2084, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950], 'policy_gneJ12_reward': [-1878810111.6350858, -1329293161.70196, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576], 'policy_light1_reward': [-8819853419.099773, -7095967613.202136, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361]}","{'mean_env_wait_ms': 12.498659059372942, 'mean_processing_ms': 2.7487692318071444, 'mean_inference_ms': 1.840517053917215}",{},0,76000,"{'sample_time_ms': 67568.027, 'sample_throughput': 59.2, 'learn_time_ms': 16568.776, 'learn_throughput': 241.418}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 131206685917184.0, 'policy_loss': -0.0014814602909609675, 'vf_loss': 131206685917184.0, 'vf_explained_var': -3.7252903e-08, 'kl': 0.012708133188425563, 'entropy': 1.0359075609594584, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 3044120155127808.0, 'policy_loss': -0.005658917041728273, 'vf_loss': 3044120155127808.0, 'vf_explained_var': -9.313226e-08, 'kl': 0.021797908484586515, 'entropy': 1.457843154668808, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 76000, 'num_steps_trained': 76000}",False,29,19,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-56-09,1615737369,86.01072406768799,1611.7433018684387,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1611.7433018684387,0,19,"{'cpu_util_percent': 28.76, 'ram_util_percent': 52.40166666666665}"
37,18,MARL,light1,False,-2702796301.4121284,-36111550162.55191,-13244516052.72579,2561.0,2,-22475880089.308098,-2265210911.970647,-10089103407.306246,{},"{'episode_reward': [-10698663530.73486, -8425260774.904094, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313], 'episode_lengths': [2506, 2084, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950], 'policy_gneJ12_reward': [-1878810111.6350858, -1329293161.70196, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576], 'policy_light1_reward': [-8819853419.099773, -7095967613.202136, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361]}","{'mean_env_wait_ms': 12.498659059372942, 'mean_processing_ms': 2.7487692318071444, 'mean_inference_ms': 1.840517053917215}",{},0,76000,"{'sample_time_ms': 67568.027, 'sample_throughput': 59.2, 'learn_time_ms': 16568.776, 'learn_throughput': 241.418}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 131206685917184.0, 'policy_loss': -0.0014814602909609675, 'vf_loss': 131206685917184.0, 'vf_explained_var': -3.7252903e-08, 'kl': 0.012708133188425563, 'entropy': 1.0359075609594584, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.45000000000000007, 'cur_lr': 0.001, 'total_loss': 3044120155127808.0, 'policy_loss': -0.005658917041728273, 'vf_loss': 3044120155127808.0, 'vf_explained_var': -9.313226e-08, 'kl': 0.021797908484586515, 'entropy': 1.457843154668808, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 76000, 'num_steps_trained': 76000}",False,29,19,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-56-09,1615737369,86.01072406768799,1611.7433018684387,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1611.7433018684387,0,19,"{'cpu_util_percent': 28.76, 'ram_util_percent': 52.40166666666665}"
38,19,MARL,gneJ12,False,-2702796301.4121284,-36111550162.55191,-12960686188.465857,2572.8,1,-15240038567.286163,-437585389.44147974,-3075785525.084083,{},"{'episode_reward': [-4729620124.92776, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094], 'episode_lengths': [2915, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084], 'policy_gneJ12_reward': [-766599035.3552872, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196], 'policy_light1_reward': [-3963021089.5724688, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136]}","{'mean_env_wait_ms': 12.48705046447202, 'mean_processing_ms': 2.75429129957906, 'mean_inference_ms': 1.8403865049864272}",{},0,80000,"{'sample_time_ms': 67081.763, 'sample_throughput': 59.629, 'learn_time_ms': 16522.574, 'learn_throughput': 242.093}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 163038524604416.0, 'policy_loss': -0.0096574988856446, 'vf_loss': 163038524604416.0, 'vf_explained_var': 1.3038516e-08, 'kl': 0.006590692275494803, 'entropy': 1.0528528317809105, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 3613895373619200.0, 'policy_loss': -0.0066091197659261525, 'vf_loss': 3613895373619200.0, 'vf_explained_var': -7.450581e-09, 'kl': 0.008729631706955843, 'entropy': 1.7355170026421547, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 80000, 'num_steps_trained': 80000}",False,30,20,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-57-28,1615737448,79.70295190811157,1691.4462537765503,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1691.4462537765503,0,20,"{'cpu_util_percent': 30.560714285714283, 'ram_util_percent': 52.45803571428571}"
39,19,MARL,light1,False,-2702796301.4121284,-36111550162.55191,-12960686188.465857,2572.8,1,-22475880089.308098,-2265210911.970647,-9884900663.381786,{},"{'episode_reward': [-4729620124.92776, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094], 'episode_lengths': [2915, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084], 'policy_gneJ12_reward': [-766599035.3552872, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196], 'policy_light1_reward': [-3963021089.5724688, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136]}","{'mean_env_wait_ms': 12.48705046447202, 'mean_processing_ms': 2.75429129957906, 'mean_inference_ms': 1.8403865049864272}",{},0,80000,"{'sample_time_ms': 67081.763, 'sample_throughput': 59.629, 'learn_time_ms': 16522.574, 'learn_throughput': 242.093}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 163038524604416.0, 'policy_loss': -0.0096574988856446, 'vf_loss': 163038524604416.0, 'vf_explained_var': 1.3038516e-08, 'kl': 0.006590692275494803, 'entropy': 1.0528528317809105, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 3613895373619200.0, 'policy_loss': -0.0066091197659261525, 'vf_loss': 3613895373619200.0, 'vf_explained_var': -7.450581e-09, 'kl': 0.008729631706955843, 'entropy': 1.7355170026421547, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 80000, 'num_steps_trained': 80000}",False,30,20,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-57-28,1615737448,79.70295190811157,1691.4462537765503,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1691.4462537765503,0,20,"{'cpu_util_percent': 30.560714285714283, 'ram_util_percent': 52.45803571428571}"
40,20,MARL,gneJ12,True,-2702796301.4121284,-36111550162.55191,-12932488259.565819,2579.4375,2,-15240038567.286163,-437585389.44147974,-3082846945.6402693,{},"{'episode_reward': [-12040794274.753006, -12978244377.377497, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776], 'episode_lengths': [3012, 2346, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915], 'policy_gneJ12_reward': [-1902197425.8680964, -4475339082.098021, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872], 'policy_light1_reward': [-10138596848.88492, -8502905295.279441, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688]}","{'mean_env_wait_ms': 12.4663581355763, 'mean_processing_ms': 2.7669130309213292, 'mean_inference_ms': 1.8400586500974696}",{},0,84000,"{'sample_time_ms': 66915.664, 'sample_throughput': 59.777, 'learn_time_ms': 16517.673, 'learn_throughput': 242.165}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1544318498111488.0, 'policy_loss': -0.0013246538437670097, 'vf_loss': 1544318498111488.0, 'vf_explained_var': 4.656613e-08, 'kl': 0.005216907477006316, 'entropy': 1.1710747182369232, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 4567823430975488.0, 'policy_loss': 0.0076117763528600335, 'vf_loss': 4567823430975488.0, 'vf_explained_var': 0.0, 'kl': 0.011442321323556826, 'entropy': 1.7536561042070389, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 84000, 'num_steps_trained': 84000}",False,32,21,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-58-57,1615737537,88.28465700149536,1779.7309107780457,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1779.7309107780457,0,21,"{'cpu_util_percent': 28.102419354838716, 'ram_util_percent': 52.48225806451612}"
41,20,MARL,light1,True,-2702796301.4121284,-36111550162.55191,-12932488259.565819,2579.4375,2,-22475880089.308098,-2265210911.970647,-9849641313.92556,{},"{'episode_reward': [-12040794274.753006, -12978244377.377497, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776], 'episode_lengths': [3012, 2346, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915], 'policy_gneJ12_reward': [-1902197425.8680964, -4475339082.098021, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872], 'policy_light1_reward': [-10138596848.88492, -8502905295.279441, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688]}","{'mean_env_wait_ms': 12.4663581355763, 'mean_processing_ms': 2.7669130309213292, 'mean_inference_ms': 1.8400586500974696}",{},0,84000,"{'sample_time_ms': 66915.664, 'sample_throughput': 59.777, 'learn_time_ms': 16517.673, 'learn_throughput': 242.165}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1544318498111488.0, 'policy_loss': -0.0013246538437670097, 'vf_loss': 1544318498111488.0, 'vf_explained_var': 4.656613e-08, 'kl': 0.005216907477006316, 'entropy': 1.1710747182369232, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 4567823430975488.0, 'policy_loss': 0.0076117763528600335, 'vf_loss': 4567823430975488.0, 'vf_explained_var': 0.0, 'kl': 0.011442321323556826, 'entropy': 1.7536561042070389, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 84000, 'num_steps_trained': 84000}",False,32,21,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_11-58-57,1615737537,88.28465700149536,1779.7309107780457,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1779.7309107780457,0,21,"{'cpu_util_percent': 28.102419354838716, 'ram_util_percent': 52.48225806451612}"
42,21,MARL,gneJ12,False,-2702796301.4121284,-36111550162.55191,-12762694796.842993,2588.969696969697,1,-15240038567.286163,-437585389.44147974,-3027025089.219526,{},"{'episode_reward': [-7329303989.71261, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497], 'episode_lengths': [2894, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346], 'policy_gneJ12_reward': [-1240725683.755743, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021], 'policy_light1_reward': [-6088578305.956874, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441]}","{'mean_env_wait_ms': 12.456576444200271, 'mean_processing_ms': 2.771303791511379, 'mean_inference_ms': 1.8398331516944444}",{},0,88000,"{'sample_time_ms': 66194.091, 'sample_throughput': 60.428, 'learn_time_ms': 16563.238, 'learn_throughput': 241.499}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 188888668962816.0, 'policy_loss': -0.005787851201603189, 'vf_loss': 188888668962816.0, 'vf_explained_var': 3.7252903e-09, 'kl': 0.011008406596374698, 'entropy': 1.1372312046587467, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 3423041673494528.0, 'policy_loss': -0.004836415988393128, 'vf_loss': 3423041673494528.0, 'vf_explained_var': 4.8428774e-08, 'kl': 0.00953340984415263, 'entropy': 1.6221829280257225, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 88000, 'num_steps_trained': 88000}",False,33,22,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-00-16,1615737616,79.52715301513672,1859.2580637931824,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1859.2580637931824,0,22,"{'cpu_util_percent': 30.473873873873877, 'ram_util_percent': 52.445945945945915}"
43,21,MARL,light1,False,-2702796301.4121284,-36111550162.55191,-12762694796.842993,2588.969696969697,1,-22475880089.308098,-2265210911.970647,-9735669707.62348,{},"{'episode_reward': [-7329303989.71261, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497], 'episode_lengths': [2894, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346], 'policy_gneJ12_reward': [-1240725683.755743, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021], 'policy_light1_reward': [-6088578305.956874, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441]}","{'mean_env_wait_ms': 12.456576444200271, 'mean_processing_ms': 2.771303791511379, 'mean_inference_ms': 1.8398331516944444}",{},0,88000,"{'sample_time_ms': 66194.091, 'sample_throughput': 60.428, 'learn_time_ms': 16563.238, 'learn_throughput': 241.499}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 188888668962816.0, 'policy_loss': -0.005787851201603189, 'vf_loss': 188888668962816.0, 'vf_explained_var': 3.7252903e-09, 'kl': 0.011008406596374698, 'entropy': 1.1372312046587467, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 3423041673494528.0, 'policy_loss': -0.004836415988393128, 'vf_loss': 3423041673494528.0, 'vf_explained_var': 4.8428774e-08, 'kl': 0.00953340984415263, 'entropy': 1.6221829280257225, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 88000, 'num_steps_trained': 88000}",False,33,22,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-00-16,1615737616,79.52715301513672,1859.2580637931824,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1859.2580637931824,0,22,"{'cpu_util_percent': 30.473873873873877, 'ram_util_percent': 52.445945945945915}"
44,22,MARL,gneJ12,False,-2702796301.4121284,-36111550162.55191,-12600939759.989985,2611.9142857142856,2,-15240038567.286163,-437585389.44147974,-2951588832.670507,{},"{'episode_reward': [-11080593425.566738, -8783369878.264051, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261], 'episode_lengths': [2876, 3105, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894], 'policy_gneJ12_reward': [-1941261933.6430032, -1472519265.5803735, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743], 'policy_light1_reward': [-9139331491.923727, -7310850612.683665, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874]}","{'mean_env_wait_ms': 12.437458031705232, 'mean_processing_ms': 2.781271398439767, 'mean_inference_ms': 1.8393029561218448}",{},0,92000,"{'sample_time_ms': 66928.171, 'sample_throughput': 59.766, 'learn_time_ms': 16632.242, 'learn_throughput': 240.497}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 119597855670272.0, 'policy_loss': 0.00016239917022176087, 'vf_loss': 119597855670272.0, 'vf_explained_var': -7.0780516e-08, 'kl': 0.01034689717926085, 'entropy': 1.0112139731645584, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 2511787576524800.0, 'policy_loss': -0.006875909894006327, 'vf_loss': 2511787576524800.0, 'vf_explained_var': -8.195639e-08, 'kl': 0.020629462189390324, 'entropy': 1.497951366007328, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 92000, 'num_steps_trained': 92000}",False,35,23,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-01-42,1615737702,85.44342875480652,1944.701492547989,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1944.701492547989,0,23,"{'cpu_util_percent': 29.0775, 'ram_util_percent': 52.448333333333316}"
45,22,MARL,light1,False,-2702796301.4121284,-36111550162.55191,-12600939759.989985,2611.9142857142856,2,-22475880089.308098,-2265210911.970647,-9649350927.319489,{},"{'episode_reward': [-11080593425.566738, -8783369878.264051, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261], 'episode_lengths': [2876, 3105, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894], 'policy_gneJ12_reward': [-1941261933.6430032, -1472519265.5803735, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743], 'policy_light1_reward': [-9139331491.923727, -7310850612.683665, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874]}","{'mean_env_wait_ms': 12.437458031705232, 'mean_processing_ms': 2.781271398439767, 'mean_inference_ms': 1.8393029561218448}",{},0,92000,"{'sample_time_ms': 66928.171, 'sample_throughput': 59.766, 'learn_time_ms': 16632.242, 'learn_throughput': 240.497}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 119597855670272.0, 'policy_loss': 0.00016239917022176087, 'vf_loss': 119597855670272.0, 'vf_explained_var': -7.0780516e-08, 'kl': 0.01034689717926085, 'entropy': 1.0112139731645584, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 0.675, 'cur_lr': 0.001, 'total_loss': 2511787576524800.0, 'policy_loss': -0.006875909894006327, 'vf_loss': 2511787576524800.0, 'vf_explained_var': -8.195639e-08, 'kl': 0.020629462189390324, 'entropy': 1.497951366007328, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 92000, 'num_steps_trained': 92000}",False,35,23,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-01-42,1615737702,85.44342875480652,1944.701492547989,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",1944.701492547989,0,23,"{'cpu_util_percent': 29.0775, 'ram_util_percent': 52.448333333333316}"
46,23,MARL,gneJ12,False,-2702796301.4121284,-36111550162.55191,-12530171008.345613,2623.25,1,-15240038567.286163,-437585389.44147974,-2915352413.9158683,{},"{'episode_reward': [-10053264700.792597, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051], 'episode_lengths': [3020, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105], 'policy_gneJ12_reward': [-1647077757.5035317, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735], 'policy_light1_reward': [-8406186943.289081, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665]}","{'mean_env_wait_ms': 12.428508237661767, 'mean_processing_ms': 2.784836766716805, 'mean_inference_ms': 1.8390095937243802}",{},0,96000,"{'sample_time_ms': 66417.205, 'sample_throughput': 60.225, 'learn_time_ms': 16740.256, 'learn_throughput': 238.945}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 190827380604928.0, 'policy_loss': -0.007863389619160444, 'vf_loss': 190827380604928.0, 'vf_explained_var': -4.0978193e-08, 'kl': 0.007470932818250731, 'entropy': 1.1988339237868786, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 3781861604065280.0, 'policy_loss': 0.0035317712754476815, 'vf_loss': 3781861604065280.0, 'vf_explained_var': -1.2293458e-07, 'kl': 0.007055242225760594, 'entropy': 1.5220087803900242, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 96000, 'num_steps_trained': 96000}",False,36,24,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-03-03,1615737783,80.68997597694397,2025.3914685249329,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2025.3914685249329,0,24,"{'cpu_util_percent': 30.90353982300885, 'ram_util_percent': 52.470796460176985}"
47,23,MARL,light1,False,-2702796301.4121284,-36111550162.55191,-12530171008.345613,2623.25,1,-22475880089.308098,-2265210911.970647,-9614818594.429756,{},"{'episode_reward': [-10053264700.792597, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051], 'episode_lengths': [3020, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105], 'policy_gneJ12_reward': [-1647077757.5035317, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735], 'policy_light1_reward': [-8406186943.289081, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665]}","{'mean_env_wait_ms': 12.428508237661767, 'mean_processing_ms': 2.784836766716805, 'mean_inference_ms': 1.8390095937243802}",{},0,96000,"{'sample_time_ms': 66417.205, 'sample_throughput': 60.225, 'learn_time_ms': 16740.256, 'learn_throughput': 238.945}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 190827380604928.0, 'policy_loss': -0.007863389619160444, 'vf_loss': 190827380604928.0, 'vf_explained_var': -4.0978193e-08, 'kl': 0.007470932818250731, 'entropy': 1.1988339237868786, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 3781861604065280.0, 'policy_loss': 0.0035317712754476815, 'vf_loss': 3781861604065280.0, 'vf_explained_var': -1.2293458e-07, 'kl': 0.007055242225760594, 'entropy': 1.5220087803900242, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 96000, 'num_steps_trained': 96000}",False,36,24,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-03-03,1615737783,80.68997597694397,2025.3914685249329,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2025.3914685249329,0,24,"{'cpu_util_percent': 30.90353982300885, 'ram_util_percent': 52.470796460176985}"
48,24,MARL,gneJ12,False,-2702796301.4121284,-36111550162.55191,-12290113654.852037,2596.9473684210525,2,-15240038567.286163,-437585389.44147974,-2825713298.230876,{},"{'episode_reward': [-10669336925.681664, -5268825658.253636, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597], 'episode_lengths': [2641, 1606, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020], 'policy_gneJ12_reward': [-1767461206.207429, -656957225.5945992, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317], 'policy_light1_reward': [-8901875719.474207, -4611868432.659031, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081]}","{'mean_env_wait_ms': 12.41128403251416, 'mean_processing_ms': 2.793252929615509, 'mean_inference_ms': 1.8383861097931895}",{},0,100000,"{'sample_time_ms': 67062.857, 'sample_throughput': 59.646, 'learn_time_ms': 16757.308, 'learn_throughput': 238.702}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 107245214892032.0, 'policy_loss': -0.0022162551467772573, 'vf_loss': 107245214892032.0, 'vf_explained_var': 2.7939677e-08, 'kl': 0.009603678394341841, 'entropy': 0.9644104465842247, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2694934280798208.0, 'policy_loss': 0.0040228346770163625, 'vf_loss': 2694934280798208.0, 'vf_explained_var': -5.2154064e-08, 'kl': 0.015656154457246885, 'entropy': 1.3399175256490707, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 100000, 'num_steps_trained': 100000}",False,38,25,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-04-29,1615737869,86.40121793746948,2111.7926864624023,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2111.7926864624023,0,25,"{'cpu_util_percent': 28.685123966942154, 'ram_util_percent': 52.44793388429751}"
49,24,MARL,light1,False,-2702796301.4121284,-36111550162.55191,-12290113654.852037,2596.9473684210525,2,-22475880089.308098,-2265210911.970647,-9464400356.62117,{},"{'episode_reward': [-10669336925.681664, -5268825658.253636, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597], 'episode_lengths': [2641, 1606, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020], 'policy_gneJ12_reward': [-1767461206.207429, -656957225.5945992, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317], 'policy_light1_reward': [-8901875719.474207, -4611868432.659031, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081]}","{'mean_env_wait_ms': 12.41128403251416, 'mean_processing_ms': 2.793252929615509, 'mean_inference_ms': 1.8383861097931895}",{},0,100000,"{'sample_time_ms': 67062.857, 'sample_throughput': 59.646, 'learn_time_ms': 16757.308, 'learn_throughput': 238.702}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 107245214892032.0, 'policy_loss': -0.0022162551467772573, 'vf_loss': 107245214892032.0, 'vf_explained_var': 2.7939677e-08, 'kl': 0.009603678394341841, 'entropy': 0.9644104465842247, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2694934280798208.0, 'policy_loss': 0.0040228346770163625, 'vf_loss': 2694934280798208.0, 'vf_explained_var': -5.2154064e-08, 'kl': 0.015656154457246885, 'entropy': 1.3399175256490707, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 100000, 'num_steps_trained': 100000}",False,38,25,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-04-29,1615737869,86.40121793746948,2111.7926864624023,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2111.7926864624023,0,25,"{'cpu_util_percent': 28.685123966942154, 'ram_util_percent': 52.44793388429751}"
50,25,MARL,gneJ12,True,-2702796301.4121284,-36111550162.55191,-12083022156.512636,2601.4871794871797,1,-15240038567.286163,-437585389.44147974,-2773094554.4386697,{},"{'episode_reward': [-4213545219.615416, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636], 'episode_lengths': [2774, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606], 'policy_gneJ12_reward': [-773582290.3348384, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992], 'policy_light1_reward': [-3439962929.280575, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031]}","{'mean_env_wait_ms': 12.40284150871433, 'mean_processing_ms': 2.796250929595001, 'mean_inference_ms': 1.8380514590301977}",{},0,104000,"{'sample_time_ms': 66318.761, 'sample_throughput': 60.315, 'learn_time_ms': 16873.259, 'learn_throughput': 237.061}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 73479224557568.0, 'policy_loss': -0.014549166662618518, 'vf_loss': 73479224557568.0, 'vf_explained_var': -5.2154064e-08, 'kl': 0.011372770328307524, 'entropy': 0.9015294369310141, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1745336938790912.0, 'policy_loss': -0.010882634873269126, 'vf_loss': 1745336938790912.0, 'vf_explained_var': 6.3329935e-08, 'kl': 0.008264163923740853, 'entropy': 1.329192690551281, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 104000, 'num_steps_trained': 104000}",False,39,26,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-05-48,1615737948,78.92735624313354,2190.720042705536,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2190.720042705536,0,26,"{'cpu_util_percent': 30.846846846846844, 'ram_util_percent': 52.45315315315312}"
51,25,MARL,light1,True,-2702796301.4121284,-36111550162.55191,-12083022156.512636,2601.4871794871797,1,-22475880089.308098,-2265210911.970647,-9309927602.073973,{},"{'episode_reward': [-4213545219.615416, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636], 'episode_lengths': [2774, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606], 'policy_gneJ12_reward': [-773582290.3348384, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992], 'policy_light1_reward': [-3439962929.280575, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031]}","{'mean_env_wait_ms': 12.40284150871433, 'mean_processing_ms': 2.796250929595001, 'mean_inference_ms': 1.8380514590301977}",{},0,104000,"{'sample_time_ms': 66318.761, 'sample_throughput': 60.315, 'learn_time_ms': 16873.259, 'learn_throughput': 237.061}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 73479224557568.0, 'policy_loss': -0.014549166662618518, 'vf_loss': 73479224557568.0, 'vf_explained_var': -5.2154064e-08, 'kl': 0.011372770328307524, 'entropy': 0.9015294369310141, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1745336938790912.0, 'policy_loss': -0.010882634873269126, 'vf_loss': 1745336938790912.0, 'vf_explained_var': 6.3329935e-08, 'kl': 0.008264163923740853, 'entropy': 1.329192690551281, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 104000, 'num_steps_trained': 104000}",False,39,26,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-05-48,1615737948,78.92735624313354,2190.720042705536,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2190.720042705536,0,26,"{'cpu_util_percent': 30.846846846846844, 'ram_util_percent': 52.45315315315312}"
52,26,MARL,gneJ12,False,-2702796301.4121284,-36111550162.55191,-11879849100.947378,2599.170731707317,2,-15240038567.286163,-437585389.44147974,-2701759875.9122405,{},"{'episode_reward': [-7053246475.639692, -8782702559.209944, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416], 'episode_lengths': [2573, 2535, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774], 'policy_gneJ12_reward': [-1074052235.9507473, -1547415053.342992, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384], 'policy_light1_reward': [-5979194239.688955, -7235287505.866957, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575]}","{'mean_env_wait_ms': 12.387204481292475, 'mean_processing_ms': 2.80318062808328, 'mean_inference_ms': 1.837367416322449}",{},0,108000,"{'sample_time_ms': 66312.578, 'sample_throughput': 60.32, 'learn_time_ms': 17003.673, 'learn_throughput': 235.243}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 178421369143296.0, 'policy_loss': -0.004961687052855268, 'vf_loss': 178421369143296.0, 'vf_explained_var': -3.7252903e-08, 'kl': 0.014818100709817372, 'entropy': 1.1267421133816242, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 3102567051558912.0, 'policy_loss': -0.0067307323042768985, 'vf_loss': 3102567051558912.0, 'vf_explained_var': -5.5879354e-08, 'kl': 0.010634623766236473, 'entropy': 1.766521256417036, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 108000, 'num_steps_trained': 108000}",False,41,27,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-07-16,1615738036,87.94397115707397,2278.66401386261,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2278.66401386261,0,27,"{'cpu_util_percent': 29.120325203252033, 'ram_util_percent': 52.49512195121951}"
53,26,MARL,light1,False,-2702796301.4121284,-36111550162.55191,-11879849100.947378,2599.170731707317,2,-22475880089.308098,-2265210911.970647,-9178089225.035147,{},"{'episode_reward': [-7053246475.639692, -8782702559.209944, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416], 'episode_lengths': [2573, 2535, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774], 'policy_gneJ12_reward': [-1074052235.9507473, -1547415053.342992, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384], 'policy_light1_reward': [-5979194239.688955, -7235287505.866957, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575]}","{'mean_env_wait_ms': 12.387204481292475, 'mean_processing_ms': 2.80318062808328, 'mean_inference_ms': 1.837367416322449}",{},0,108000,"{'sample_time_ms': 66312.578, 'sample_throughput': 60.32, 'learn_time_ms': 17003.673, 'learn_throughput': 235.243}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 178421369143296.0, 'policy_loss': -0.004961687052855268, 'vf_loss': 178421369143296.0, 'vf_explained_var': -3.7252903e-08, 'kl': 0.014818100709817372, 'entropy': 1.1267421133816242, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 3102567051558912.0, 'policy_loss': -0.0067307323042768985, 'vf_loss': 3102567051558912.0, 'vf_explained_var': -5.5879354e-08, 'kl': 0.010634623766236473, 'entropy': 1.766521256417036, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 108000, 'num_steps_trained': 108000}",False,41,27,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-07-16,1615738036,87.94397115707397,2278.66401386261,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2278.66401386261,0,27,"{'cpu_util_percent': 29.120325203252033, 'ram_util_percent': 52.49512195121951}"
54,27,MARL,gneJ12,False,-2702796301.4121284,-36111550162.55191,-11540366469.760181,2582.6279069767443,2,-15240038567.286163,-437585389.44147974,-2608959079.8984637,{},"{'episode_reward': [-5682742826.437693, -3479202234.4075365, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944], 'episode_lengths': [1824, 2663, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535], 'policy_gneJ12_reward': [-876684152.1178232, -536401371.1142776, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992], 'policy_light1_reward': [-4806058674.319857, -2942800863.2932553, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957]}","{'mean_env_wait_ms': 12.372007772999583, 'mean_processing_ms': 2.811014017872657, 'mean_inference_ms': 1.8366613502722142}",{},0,112000,"{'sample_time_ms': 66803.01, 'sample_throughput': 59.878, 'learn_time_ms': 17055.224, 'learn_throughput': 234.532}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 33700410425344.0, 'policy_loss': -0.006455726717831567, 'vf_loss': 33700410425344.0, 'vf_explained_var': -3.3527613e-08, 'kl': 0.007374608852842357, 'entropy': 0.6130682965740561, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 974091848777728.0, 'policy_loss': -0.0073304540128447115, 'vf_loss': 974091848777728.0, 'vf_explained_var': -2.0489097e-08, 'kl': 0.010711903320043348, 'entropy': 1.2686151675879955, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 112000, 'num_steps_trained': 112000}",False,43,28,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-08-42,1615738122,85.6518907546997,2364.3159046173096,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2364.3159046173096,0,28,"{'cpu_util_percent': 28.263333333333335, 'ram_util_percent': 52.44999999999998}"
55,27,MARL,light1,False,-2702796301.4121284,-36111550162.55191,-11540366469.760181,2582.6279069767443,2,-22475880089.308098,-2265210911.970647,-8931407389.861725,{},"{'episode_reward': [-5682742826.437693, -3479202234.4075365, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944], 'episode_lengths': [1824, 2663, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535], 'policy_gneJ12_reward': [-876684152.1178232, -536401371.1142776, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992], 'policy_light1_reward': [-4806058674.319857, -2942800863.2932553, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957]}","{'mean_env_wait_ms': 12.372007772999583, 'mean_processing_ms': 2.811014017872657, 'mean_inference_ms': 1.8366613502722142}",{},0,112000,"{'sample_time_ms': 66803.01, 'sample_throughput': 59.878, 'learn_time_ms': 17055.224, 'learn_throughput': 234.532}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 33700410425344.0, 'policy_loss': -0.006455726717831567, 'vf_loss': 33700410425344.0, 'vf_explained_var': -3.3527613e-08, 'kl': 0.007374608852842357, 'entropy': 0.6130682965740561, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 974091848777728.0, 'policy_loss': -0.0073304540128447115, 'vf_loss': 974091848777728.0, 'vf_explained_var': -2.0489097e-08, 'kl': 0.010711903320043348, 'entropy': 1.2686151675879955, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 112000, 'num_steps_trained': 112000}",False,43,28,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-08-42,1615738122,85.6518907546997,2364.3159046173096,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2364.3159046173096,0,28,"{'cpu_util_percent': 28.263333333333335, 'ram_util_percent': 52.44999999999998}"
56,28,MARL,gneJ12,False,-2702796301.4121284,-36111550162.55191,-11236335583.429655,2562.5777777777776,2,-15240038567.286163,-437585389.44147974,-2527374099.5138426,{},"{'episode_reward': [-4178021435.672462, -5221321618.974252, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365], 'episode_lengths': [2426, 1837, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663], 'policy_gneJ12_reward': [-702225870.504788, -844368171.9841616, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776], 'policy_light1_reward': [-3475795565.1676683, -4376953446.990093, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553]}","{'mean_env_wait_ms': 12.357379966417719, 'mean_processing_ms': 2.8192744611517684, 'mean_inference_ms': 1.8359657469445387}",{},0,116000,"{'sample_time_ms': 66666.264, 'sample_throughput': 60.0, 'learn_time_ms': 17167.213, 'learn_throughput': 233.002}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 79261928390656.0, 'policy_loss': -0.0011988987680524588, 'vf_loss': 79261928390656.0, 'vf_explained_var': -7.0780516e-08, 'kl': 0.010672478121705353, 'entropy': 0.7799635548144579, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1510141656563712.0, 'policy_loss': -0.005228735943092033, 'vf_loss': 1510141656563712.0, 'vf_explained_var': -4.284084e-08, 'kl': 0.010822756143170409, 'entropy': 1.372999418526888, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 116000, 'num_steps_trained': 116000}",False,45,29,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-10-07,1615738207,85.76360607147217,2450.0795106887817,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2450.0795106887817,0,29,"{'cpu_util_percent': 28.535833333333336, 'ram_util_percent': 52.5}"
57,28,MARL,light1,False,-2702796301.4121284,-36111550162.55191,-11236335583.429655,2562.5777777777776,2,-22475880089.308098,-2265210911.970647,-8708961483.915821,{},"{'episode_reward': [-4178021435.672462, -5221321618.974252, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365], 'episode_lengths': [2426, 1837, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663], 'policy_gneJ12_reward': [-702225870.504788, -844368171.9841616, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776], 'policy_light1_reward': [-3475795565.1676683, -4376953446.990093, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553]}","{'mean_env_wait_ms': 12.357379966417719, 'mean_processing_ms': 2.8192744611517684, 'mean_inference_ms': 1.8359657469445387}",{},0,116000,"{'sample_time_ms': 66666.264, 'sample_throughput': 60.0, 'learn_time_ms': 17167.213, 'learn_throughput': 233.002}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 79261928390656.0, 'policy_loss': -0.0011988987680524588, 'vf_loss': 79261928390656.0, 'vf_explained_var': -7.0780516e-08, 'kl': 0.010672478121705353, 'entropy': 0.7799635548144579, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1510141656563712.0, 'policy_loss': -0.005228735943092033, 'vf_loss': 1510141656563712.0, 'vf_explained_var': -4.284084e-08, 'kl': 0.010822756143170409, 'entropy': 1.372999418526888, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 116000, 'num_steps_trained': 116000}",False,45,29,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-10-07,1615738207,85.76360607147217,2450.0795106887817,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2450.0795106887817,0,29,"{'cpu_util_percent': 28.535833333333336, 'ram_util_percent': 52.5}"
58,29,MARL,gneJ12,False,-2111585148.7219243,-36111550162.55191,-10863199773.497614,2524.6170212765956,2,-15240038567.286163,-345456002.53957677,-2436378643.1976385,{},"{'episode_reward': [-2823702951.3313484, -2111585148.7219243, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252], 'episode_lengths': [1652, 1689, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837], 'policy_gneJ12_reward': [-345456002.53957677, -432505749.62653625, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616], 'policy_light1_reward': [-2478246948.791769, -1679079399.0953887, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093]}","{'mean_env_wait_ms': 12.343275731741894, 'mean_processing_ms': 2.827835788449239, 'mean_inference_ms': 1.835277741526139}",{},0,120000,"{'sample_time_ms': 67215.301, 'sample_throughput': 59.51, 'learn_time_ms': 17192.169, 'learn_throughput': 232.664}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 54541135511552.0, 'policy_loss': -0.0069590147759299725, 'vf_loss': 54541135511552.0, 'vf_explained_var': -2.9802322e-08, 'kl': 0.012314321706071496, 'entropy': 0.7307578045874834, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1254544747003904.0, 'policy_loss': -0.0060190854710526764, 'vf_loss': 1254544747003904.0, 'vf_explained_var': -1.0058284e-07, 'kl': 0.009024309802043717, 'entropy': 1.2720728665590286, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 120000, 'num_steps_trained': 120000}",False,47,30,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-11-33,1615738293,85.44254207611084,2535.5220527648926,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2535.5220527648926,0,30,"{'cpu_util_percent': 29.075833333333332, 'ram_util_percent': 52.5}"
59,29,MARL,light1,False,-2111585148.7219243,-36111550162.55191,-10863199773.497614,2524.6170212765956,2,-22475880089.308098,-1679079399.0953887,-8426821130.299981,{},"{'episode_reward': [-2823702951.3313484, -2111585148.7219243, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252], 'episode_lengths': [1652, 1689, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837], 'policy_gneJ12_reward': [-345456002.53957677, -432505749.62653625, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616], 'policy_light1_reward': [-2478246948.791769, -1679079399.0953887, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093]}","{'mean_env_wait_ms': 12.343275731741894, 'mean_processing_ms': 2.827835788449239, 'mean_inference_ms': 1.835277741526139}",{},0,120000,"{'sample_time_ms': 67215.301, 'sample_throughput': 59.51, 'learn_time_ms': 17192.169, 'learn_throughput': 232.664}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 54541135511552.0, 'policy_loss': -0.0069590147759299725, 'vf_loss': 54541135511552.0, 'vf_explained_var': -2.9802322e-08, 'kl': 0.012314321706071496, 'entropy': 0.7307578045874834, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1254544747003904.0, 'policy_loss': -0.0060190854710526764, 'vf_loss': 1254544747003904.0, 'vf_explained_var': -1.0058284e-07, 'kl': 0.009024309802043717, 'entropy': 1.2720728665590286, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 120000, 'num_steps_trained': 120000}",False,47,30,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-11-33,1615738293,85.44254207611084,2535.5220527648926,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2535.5220527648926,0,30,"{'cpu_util_percent': 29.075833333333332, 'ram_util_percent': 52.5}"
60,30,MARL,gneJ12,True,-2111585148.7219243,-36111550162.55191,-10643747458.807497,2495.6530612244896,2,-15240038567.286163,-345456002.53957677,-2374383025.817777,{},"{'episode_reward': [-5310184701.267029, -5663051425.912619, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243], 'episode_lengths': [1903, 1727, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689], 'policy_gneJ12_reward': [-717641329.397345, -1117330705.3847182, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625], 'policy_light1_reward': [-4592543371.869682, -4545720720.527898, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887]}","{'mean_env_wait_ms': 12.330107856244265, 'mean_processing_ms': 2.8366106761555954, 'mean_inference_ms': 1.8346135393655951}",{},0,124000,"{'sample_time_ms': 67017.348, 'sample_throughput': 59.686, 'learn_time_ms': 17310.155, 'learn_throughput': 231.078}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 125383932116992.0, 'policy_loss': -0.009586225321982056, 'vf_loss': 125383932116992.0, 'vf_explained_var': -2.6077032e-08, 'kl': 0.010223612262052484, 'entropy': 1.0308187864720821, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2441492228472832.0, 'policy_loss': -0.011516303406096995, 'vf_loss': 2441492228472832.0, 'vf_explained_var': -6.3329935e-08, 'kl': 0.008230772546085063, 'entropy': 1.557381872087717, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 124000, 'num_steps_trained': 124000}",False,49,31,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-13-00,1615738380,87.48526215553284,2623.0073149204254,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2623.0073149204254,0,31,"{'cpu_util_percent': 30.51147540983607, 'ram_util_percent': 52.52131147540984}"
61,30,MARL,light1,True,-2111585148.7219243,-36111550162.55191,-10643747458.807497,2495.6530612244896,2,-22475880089.308098,-1679079399.0953887,-8269364432.989727,{},"{'episode_reward': [-5310184701.267029, -5663051425.912619, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243], 'episode_lengths': [1903, 1727, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689], 'policy_gneJ12_reward': [-717641329.397345, -1117330705.3847182, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625], 'policy_light1_reward': [-4592543371.869682, -4545720720.527898, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887]}","{'mean_env_wait_ms': 12.330107856244265, 'mean_processing_ms': 2.8366106761555954, 'mean_inference_ms': 1.8346135393655951}",{},0,124000,"{'sample_time_ms': 67017.348, 'sample_throughput': 59.686, 'learn_time_ms': 17310.155, 'learn_throughput': 231.078}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 125383932116992.0, 'policy_loss': -0.009586225321982056, 'vf_loss': 125383932116992.0, 'vf_explained_var': -2.6077032e-08, 'kl': 0.010223612262052484, 'entropy': 1.0308187864720821, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2441492228472832.0, 'policy_loss': -0.011516303406096995, 'vf_loss': 2441492228472832.0, 'vf_explained_var': -6.3329935e-08, 'kl': 0.008230772546085063, 'entropy': 1.557381872087717, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 124000, 'num_steps_trained': 124000}",False,49,31,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-13-00,1615738380,87.48526215553284,2623.0073149204254,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2623.0073149204254,0,31,"{'cpu_util_percent': 30.51147540983607, 'ram_util_percent': 52.52131147540984}"
62,31,MARL,gneJ12,False,-2111585148.7219243,-36111550162.55191,-10427525501.104343,2496.7843137254904,2,-15240038567.286163,-345456002.53957677,-2311425421.565078,{},"{'episode_reward': [-5913834772.612201, -4346340302.141951, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619], 'episode_lengths': [2493, 2556, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727], 'policy_gneJ12_reward': [-871464333.6156688, -666463901.1322331, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182], 'policy_light1_reward': [-5042370438.996545, -3679876401.009723, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898]}","{'mean_env_wait_ms': 12.317441883226731, 'mean_processing_ms': 2.84541679126982, 'mean_inference_ms': 1.8339847071699058}",{},0,128000,"{'sample_time_ms': 67569.89, 'sample_throughput': 59.198, 'learn_time_ms': 17372.118, 'learn_throughput': 230.254}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 76980574093312.0, 'policy_loss': -0.0017428523278795183, 'vf_loss': 76980574093312.0, 'vf_explained_var': 3.1664968e-08, 'kl': 0.013061971265415195, 'entropy': 0.7281055748462677, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1394179804495872.0, 'policy_loss': -0.001264839491341263, 'vf_loss': 1394179804495872.0, 'vf_explained_var': 4.284084e-08, 'kl': 0.012220653050462715, 'entropy': 1.3892906345427036, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 128000, 'num_steps_trained': 128000}",False,51,32,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-14-26,1615738466,85.67194294929504,2708.6792578697205,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2708.6792578697205,0,32,"{'cpu_util_percent': 28.9925, 'ram_util_percent': 52.5}"
63,31,MARL,light1,False,-2111585148.7219243,-36111550162.55191,-10427525501.104343,2496.7843137254904,2,-22475880089.308098,-1679079399.0953887,-8116100079.539272,{},"{'episode_reward': [-5913834772.612201, -4346340302.141951, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619], 'episode_lengths': [2493, 2556, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727], 'policy_gneJ12_reward': [-871464333.6156688, -666463901.1322331, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182], 'policy_light1_reward': [-5042370438.996545, -3679876401.009723, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898]}","{'mean_env_wait_ms': 12.317441883226731, 'mean_processing_ms': 2.84541679126982, 'mean_inference_ms': 1.8339847071699058}",{},0,128000,"{'sample_time_ms': 67569.89, 'sample_throughput': 59.198, 'learn_time_ms': 17372.118, 'learn_throughput': 230.254}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 76980574093312.0, 'policy_loss': -0.0017428523278795183, 'vf_loss': 76980574093312.0, 'vf_explained_var': 3.1664968e-08, 'kl': 0.013061971265415195, 'entropy': 0.7281055748462677, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1394179804495872.0, 'policy_loss': -0.001264839491341263, 'vf_loss': 1394179804495872.0, 'vf_explained_var': 4.284084e-08, 'kl': 0.012220653050462715, 'entropy': 1.3892906345427036, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 128000, 'num_steps_trained': 128000}",False,51,32,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-14-26,1615738466,85.67194294929504,2708.6792578697205,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2708.6792578697205,0,32,"{'cpu_util_percent': 28.9925, 'ram_util_percent': 52.5}"
64,32,MARL,gneJ12,False,-2111585148.7219243,-36111550162.55191,-10418051123.342798,2499.4423076923076,1,-15240038567.286163,-345456002.53957677,-2303109239.053782,{},"{'episode_reward': [-9934857857.50397, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951], 'episode_lengths': [2635, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556], 'policy_gneJ12_reward': [-1878983930.9776862, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331], 'policy_light1_reward': [-8055873926.52628, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723]}","{'mean_env_wait_ms': 12.311551305933799, 'mean_processing_ms': 2.848898517649929, 'mean_inference_ms': 1.8336726172107283}",{},0,132000,"{'sample_time_ms': 67058.503, 'sample_throughput': 59.649, 'learn_time_ms': 17507.594, 'learn_throughput': 228.472}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 263396488904704.0, 'policy_loss': -0.0037319183174986392, 'vf_loss': 263396488904704.0, 'vf_explained_var': 2.0489097e-08, 'kl': 0.009896932693663985, 'entropy': 1.420347437262535, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 3969373702193152.0, 'policy_loss': -0.006139331526355818, 'vf_loss': 3969373702193152.0, 'vf_explained_var': -3.7252903e-09, 'kl': 0.008294186474813614, 'entropy': 1.9232615903019905, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 132000, 'num_steps_trained': 132000}",False,52,33,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-15-48,1615738548,81.68454599380493,2790.3638038635254,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2790.3638038635254,0,33,"{'cpu_util_percent': 30.85652173913044, 'ram_util_percent': 52.5}"
65,32,MARL,light1,False,-2111585148.7219243,-36111550162.55191,-10418051123.342798,2499.4423076923076,1,-22475880089.308098,-1679079399.0953887,-8114941884.289022,{},"{'episode_reward': [-9934857857.50397, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951], 'episode_lengths': [2635, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556], 'policy_gneJ12_reward': [-1878983930.9776862, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331], 'policy_light1_reward': [-8055873926.52628, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723]}","{'mean_env_wait_ms': 12.311551305933799, 'mean_processing_ms': 2.848898517649929, 'mean_inference_ms': 1.8336726172107283}",{},0,132000,"{'sample_time_ms': 67058.503, 'sample_throughput': 59.649, 'learn_time_ms': 17507.594, 'learn_throughput': 228.472}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 263396488904704.0, 'policy_loss': -0.0037319183174986392, 'vf_loss': 263396488904704.0, 'vf_explained_var': 2.0489097e-08, 'kl': 0.009896932693663985, 'entropy': 1.420347437262535, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 3969373702193152.0, 'policy_loss': -0.006139331526355818, 'vf_loss': 3969373702193152.0, 'vf_explained_var': -3.7252903e-09, 'kl': 0.008294186474813614, 'entropy': 1.9232615903019905, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 132000, 'num_steps_trained': 132000}",False,52,33,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-15-48,1615738548,81.68454599380493,2790.3638038635254,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2790.3638038635254,0,33,"{'cpu_util_percent': 30.85652173913044, 'ram_util_percent': 52.5}"
66,33,MARL,gneJ12,False,-2111585148.7219243,-36111550162.55191,-10282746733.456062,2488.185185185185,2,-15240038567.286163,-345456002.53957677,-2264350184.604624,{},"{'episode_reward': [-10359173322.694244, -3170491870.107619, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397], 'episode_lengths': [2686, 1705, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635], 'policy_gneJ12_reward': [-2028256000.611692, -484973537.2413313, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862], 'policy_light1_reward': [-8330917322.082564, -2685518332.8662896, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628]}","{'mean_env_wait_ms': 12.29998220169938, 'mean_processing_ms': 2.856125191873482, 'mean_inference_ms': 1.8330437152143806}",{},0,136000,"{'sample_time_ms': 67531.809, 'sample_throughput': 59.231, 'learn_time_ms': 17521.619, 'learn_throughput': 228.289}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 82199338549248.0, 'policy_loss': -0.008442556078080088, 'vf_loss': 82199338549248.0, 'vf_explained_var': -5.5879354e-08, 'kl': 0.009550765025778674, 'entropy': 0.7615123074501753, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1609127998521344.0, 'policy_loss': -0.007787777867633849, 'vf_loss': 1609127998521344.0, 'vf_explained_var': -2.2351742e-08, 'kl': 0.010495683396584354, 'entropy': 1.4653695486485958, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 136000, 'num_steps_trained': 136000}",False,54,34,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-17-14,1615738634,85.56317520141602,2875.9269790649414,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2875.9269790649414,0,34,"{'cpu_util_percent': 28.166666666666668, 'ram_util_percent': 52.5}"
67,33,MARL,light1,False,-2111585148.7219243,-36111550162.55191,-10282746733.456062,2488.185185185185,2,-22475880089.308098,-1679079399.0953887,-8018396548.851445,{},"{'episode_reward': [-10359173322.694244, -3170491870.107619, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397], 'episode_lengths': [2686, 1705, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635], 'policy_gneJ12_reward': [-2028256000.611692, -484973537.2413313, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862], 'policy_light1_reward': [-8330917322.082564, -2685518332.8662896, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628]}","{'mean_env_wait_ms': 12.29998220169938, 'mean_processing_ms': 2.856125191873482, 'mean_inference_ms': 1.8330437152143806}",{},0,136000,"{'sample_time_ms': 67531.809, 'sample_throughput': 59.231, 'learn_time_ms': 17521.619, 'learn_throughput': 228.289}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 82199338549248.0, 'policy_loss': -0.008442556078080088, 'vf_loss': 82199338549248.0, 'vf_explained_var': -5.5879354e-08, 'kl': 0.009550765025778674, 'entropy': 0.7615123074501753, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1609127998521344.0, 'policy_loss': -0.007787777867633849, 'vf_loss': 1609127998521344.0, 'vf_explained_var': -2.2351742e-08, 'kl': 0.010495683396584354, 'entropy': 1.4653695486485958, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 136000, 'num_steps_trained': 136000}",False,54,34,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-17-14,1615738634,85.56317520141602,2875.9269790649414,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2875.9269790649414,0,34,"{'cpu_util_percent': 28.166666666666668, 'ram_util_percent': 52.5}"
68,34,MARL,gneJ12,False,-2111585148.7219243,-36111550162.55191,-10076308400.478273,2483.9464285714284,2,-15240038567.286163,-345456002.53957677,-2207037421.552255,{},"{'episode_reward': [-6120881779.208017, -2884065040.9479156, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619], 'episode_lengths': [2699, 2040, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705], 'policy_gneJ12_reward': [-827954789.3643361, -491230848.9122557, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313], 'policy_light1_reward': [-5292926989.84368, -2392834192.0356603, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896]}","{'mean_env_wait_ms': 12.288903772015008, 'mean_processing_ms': 2.8634774469296715, 'mean_inference_ms': 1.8324478213954924}",{},0,140000,"{'sample_time_ms': 67454.486, 'sample_throughput': 59.299, 'learn_time_ms': 17576.981, 'learn_throughput': 227.57}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 104034420654080.0, 'policy_loss': -0.008344229310750961, 'vf_loss': 104034420654080.0, 'vf_explained_var': 9.313226e-09, 'kl': 0.009343121317215264, 'entropy': 0.7945788726210594, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1289813170847744.0, 'policy_loss': -0.010874851344851777, 'vf_loss': 1289813170847744.0, 'vf_explained_var': -3.5390258e-08, 'kl': 0.00822448544204235, 'entropy': 1.290805108845234, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 140000, 'num_steps_trained': 140000}",False,56,35,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-18-40,1615738720,86.18178415298462,2962.108763217926,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2962.108763217926,0,35,"{'cpu_util_percent': 28.44333333333333, 'ram_util_percent': 52.52916666666667}"
69,34,MARL,light1,False,-2111585148.7219243,-36111550162.55191,-10076308400.478273,2483.9464285714284,2,-22475880089.308098,-1679079399.0953887,-7869270978.9260235,{},"{'episode_reward': [-6120881779.208017, -2884065040.9479156, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619], 'episode_lengths': [2699, 2040, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705], 'policy_gneJ12_reward': [-827954789.3643361, -491230848.9122557, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313], 'policy_light1_reward': [-5292926989.84368, -2392834192.0356603, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896]}","{'mean_env_wait_ms': 12.288903772015008, 'mean_processing_ms': 2.8634774469296715, 'mean_inference_ms': 1.8324478213954924}",{},0,140000,"{'sample_time_ms': 67454.486, 'sample_throughput': 59.299, 'learn_time_ms': 17576.981, 'learn_throughput': 227.57}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 104034420654080.0, 'policy_loss': -0.008344229310750961, 'vf_loss': 104034420654080.0, 'vf_explained_var': 9.313226e-09, 'kl': 0.009343121317215264, 'entropy': 0.7945788726210594, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1289813170847744.0, 'policy_loss': -0.010874851344851777, 'vf_loss': 1289813170847744.0, 'vf_explained_var': -3.5390258e-08, 'kl': 0.00822448544204235, 'entropy': 1.290805108845234, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 140000, 'num_steps_trained': 140000}",False,56,35,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-18-40,1615738720,86.18178415298462,2962.108763217926,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",2962.108763217926,0,35,"{'cpu_util_percent': 28.44333333333333, 'ram_util_percent': 52.52916666666667}"
70,35,MARL,gneJ12,True,-2111585148.7219243,-36111550162.55191,-10038181016.633835,2483.40350877193,1,-15240038567.286163,-345456002.53957677,-2198476147.259339,{},"{'episode_reward': [-7903047521.345258, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156], 'episode_lengths': [2453, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040], 'policy_gneJ12_reward': [-1719044786.856025, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557], 'policy_light1_reward': [-6184002734.489236, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603]}","{'mean_env_wait_ms': 12.283574537926837, 'mean_processing_ms': 2.8664895128013446, 'mean_inference_ms': 1.8321491993904353}",{},0,144000,"{'sample_time_ms': 67564.302, 'sample_throughput': 59.203, 'learn_time_ms': 17622.744, 'learn_throughput': 226.979}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 131084842696704.0, 'policy_loss': -0.004471413849387318, 'vf_loss': 131084842696704.0, 'vf_explained_var': -2.9802322e-08, 'kl': 0.009532487390970346, 'entropy': 0.8828034829348326, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1843968438435840.0, 'policy_loss': -0.002356786571908742, 'vf_loss': 1843968438435840.0, 'vf_explained_var': -3.7252903e-09, 'kl': 0.011675405607093126, 'entropy': 1.510181237012148, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 144000, 'num_steps_trained': 144000}",False,57,36,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-20-00,1615738800,80.48359894752502,3042.592362165451,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3042.592362165451,0,36,"{'cpu_util_percent': 30.20353982300885, 'ram_util_percent': 52.522123893805315}"
71,35,MARL,light1,True,-2111585148.7219243,-36111550162.55191,-10038181016.633835,2483.40350877193,1,-22475880089.308098,-1679079399.0953887,-7839704869.374501,{},"{'episode_reward': [-7903047521.345258, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156], 'episode_lengths': [2453, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040], 'policy_gneJ12_reward': [-1719044786.856025, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557], 'policy_light1_reward': [-6184002734.489236, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603]}","{'mean_env_wait_ms': 12.283574537926837, 'mean_processing_ms': 2.8664895128013446, 'mean_inference_ms': 1.8321491993904353}",{},0,144000,"{'sample_time_ms': 67564.302, 'sample_throughput': 59.203, 'learn_time_ms': 17622.744, 'learn_throughput': 226.979}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 131084842696704.0, 'policy_loss': -0.004471413849387318, 'vf_loss': 131084842696704.0, 'vf_explained_var': -2.9802322e-08, 'kl': 0.009532487390970346, 'entropy': 0.8828034829348326, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1843968438435840.0, 'policy_loss': -0.002356786571908742, 'vf_loss': 1843968438435840.0, 'vf_explained_var': -3.7252903e-09, 'kl': 0.011675405607093126, 'entropy': 1.510181237012148, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 144000, 'num_steps_trained': 144000}",False,57,36,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-20-00,1615738800,80.48359894752502,3042.592362165451,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3042.592362165451,0,36,"{'cpu_util_percent': 30.20353982300885, 'ram_util_percent': 52.522123893805315}"
72,36,MARL,gneJ12,False,-2111585148.7219243,-36111550162.55191,-9923143742.94741,2482.64406779661,2,-15240038567.286163,-345456002.53957677,-2155018159.4878383,{},"{'episode_reward': [-5787081395.009127, -7502081490.759654, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258], 'episode_lengths': [2962, 1960, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453], 'policy_gneJ12_reward': [-734728779.0476569, -1098202236.9525063, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025], 'policy_light1_reward': [-5052352615.961467, -6403879253.807137, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236]}","{'mean_env_wait_ms': 12.273629893024927, 'mean_processing_ms': 2.872913143741673, 'mean_inference_ms': 1.8315804609825146}",{},0,148000,"{'sample_time_ms': 67661.529, 'sample_throughput': 59.118, 'learn_time_ms': 17695.24, 'learn_throughput': 226.049}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 999698348376064.0, 'policy_loss': 0.0010078189807245508, 'vf_loss': 999698348376064.0, 'vf_explained_var': -2.6077032e-08, 'kl': 0.008591722056735307, 'entropy': 1.2921186573803425, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 3344120038817792.0, 'policy_loss': -0.007753720215987414, 'vf_loss': 3344120038817792.0, 'vf_explained_var': -4.0978193e-08, 'kl': 0.008126445347443223, 'entropy': 1.7303607799112797, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 148000, 'num_steps_trained': 148000}",False,59,37,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-21-30,1615738890,89.64130997657776,3132.233672142029,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3132.233672142029,0,37,"{'cpu_util_percent': 29.609523809523807, 'ram_util_percent': 52.53650793650794}"
73,36,MARL,light1,False,-2111585148.7219243,-36111550162.55191,-9923143742.94741,2482.64406779661,2,-22475880089.308098,-1679079399.0953887,-7768125583.459579,{},"{'episode_reward': [-5787081395.009127, -7502081490.759654, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258], 'episode_lengths': [2962, 1960, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453], 'policy_gneJ12_reward': [-734728779.0476569, -1098202236.9525063, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025], 'policy_light1_reward': [-5052352615.961467, -6403879253.807137, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236]}","{'mean_env_wait_ms': 12.273629893024927, 'mean_processing_ms': 2.872913143741673, 'mean_inference_ms': 1.8315804609825146}",{},0,148000,"{'sample_time_ms': 67661.529, 'sample_throughput': 59.118, 'learn_time_ms': 17695.24, 'learn_throughput': 226.049}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 999698348376064.0, 'policy_loss': 0.0010078189807245508, 'vf_loss': 999698348376064.0, 'vf_explained_var': -2.6077032e-08, 'kl': 0.008591722056735307, 'entropy': 1.2921186573803425, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 3344120038817792.0, 'policy_loss': -0.007753720215987414, 'vf_loss': 3344120038817792.0, 'vf_explained_var': -4.0978193e-08, 'kl': 0.008126445347443223, 'entropy': 1.7303607799112797, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 148000, 'num_steps_trained': 148000}",False,59,37,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-21-30,1615738890,89.64130997657776,3132.233672142029,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3132.233672142029,0,37,"{'cpu_util_percent': 29.609523809523807, 'ram_util_percent': 52.53650793650794}"
74,37,MARL,gneJ12,False,-2111585148.7219243,-36111550162.55191,-9947167449.047947,2485.0491803278687,2,-15240038567.286163,-345456002.53957677,-2207718634.3040743,{},"{'episode_reward': [-13903271510.926207, -7408462047.101337, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654], 'episode_lengths': [2353, 2759, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960], 'policy_gneJ12_reward': [-6360153602.347856, -1164611680.418224, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063], 'policy_light1_reward': [-7543117908.578321, -6243850366.683111, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137]}","{'mean_env_wait_ms': 12.264321652021842, 'mean_processing_ms': 2.8794929422197644, 'mean_inference_ms': 1.8310440390221974}",{},0,152000,"{'sample_time_ms': 67818.541, 'sample_throughput': 58.981, 'learn_time_ms': 17772.236, 'learn_throughput': 225.07}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 3443395009708032.0, 'policy_loss': -0.006562951472005807, 'vf_loss': 3443395009708032.0, 'vf_explained_var': 2.9802322e-08, 'kl': 0.006559623676366755, 'entropy': 0.8473711777478456, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 3875173610553344.0, 'policy_loss': -0.008266147546237335, 'vf_loss': 3875173610553344.0, 'vf_explained_var': -8.568168e-08, 'kl': 0.006463129197072703, 'entropy': 1.5824898555874825, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 152000, 'num_steps_trained': 152000}",False,61,38,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-22-58,1615738978,87.99230313301086,3220.2259752750397,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3220.2259752750397,0,38,"{'cpu_util_percent': 31.226829268292683, 'ram_util_percent': 52.57642276422765}"
75,37,MARL,light1,False,-2111585148.7219243,-36111550162.55191,-9947167449.047947,2485.0491803278687,2,-22475880089.308098,-1679079399.0953887,-7739448814.743879,{},"{'episode_reward': [-13903271510.926207, -7408462047.101337, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654], 'episode_lengths': [2353, 2759, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960], 'policy_gneJ12_reward': [-6360153602.347856, -1164611680.418224, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063], 'policy_light1_reward': [-7543117908.578321, -6243850366.683111, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137]}","{'mean_env_wait_ms': 12.264321652021842, 'mean_processing_ms': 2.8794929422197644, 'mean_inference_ms': 1.8310440390221974}",{},0,152000,"{'sample_time_ms': 67818.541, 'sample_throughput': 58.981, 'learn_time_ms': 17772.236, 'learn_throughput': 225.07}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 3443395009708032.0, 'policy_loss': -0.006562951472005807, 'vf_loss': 3443395009708032.0, 'vf_explained_var': 2.9802322e-08, 'kl': 0.006559623676366755, 'entropy': 0.8473711777478456, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 3875173610553344.0, 'policy_loss': -0.008266147546237335, 'vf_loss': 3875173610553344.0, 'vf_explained_var': -8.568168e-08, 'kl': 0.006463129197072703, 'entropy': 1.5824898555874825, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 152000, 'num_steps_trained': 152000}",False,61,38,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-22-58,1615738978,87.99230313301086,3220.2259752750397,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3220.2259752750397,0,38,"{'cpu_util_percent': 31.226829268292683, 'ram_util_percent': 52.57642276422765}"
76,38,MARL,gneJ12,False,-2111585148.7219243,-36111550162.55191,-9867573276.922867,2489.6774193548385,1,-15240038567.286163,-345456002.53957677,-2182948835.0878863,{},"{'episode_reward': [-5012328777.292989, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337], 'episode_lengths': [2772, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759], 'policy_gneJ12_reward': [-671991082.9004169, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224], 'policy_light1_reward': [-4340337694.392566, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111]}","{'mean_env_wait_ms': 12.259661227732636, 'mean_processing_ms': 2.882218166201566, 'mean_inference_ms': 1.8307632713301174}",{},0,156000,"{'sample_time_ms': 67111.886, 'sample_throughput': 59.602, 'learn_time_ms': 17740.935, 'learn_throughput': 225.467}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 24562769461248.0, 'policy_loss': -0.00335895165335387, 'vf_loss': 24562769461248.0, 'vf_explained_var': 9.313226e-09, 'kl': 0.017020864936057478, 'entropy': 0.4003755711019039, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 830100945764352.0, 'policy_loss': -0.0021839271939825267, 'vf_loss': 830100945764352.0, 'vf_explained_var': -1.1175871e-08, 'kl': 0.011551107018021867, 'entropy': 1.0744436476379633, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 156000, 'num_steps_trained': 156000}",False,62,39,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-24-16,1615739056,78.38442087173462,3298.6103961467743,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3298.6103961467743,0,39,"{'cpu_util_percent': 29.650000000000006, 'ram_util_percent': 52.54818181818182}"
77,38,MARL,light1,False,-2111585148.7219243,-36111550162.55191,-9867573276.922867,2489.6774193548385,1,-22475880089.308098,-1679079399.0953887,-7684624441.834987,{},"{'episode_reward': [-5012328777.292989, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337], 'episode_lengths': [2772, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759], 'policy_gneJ12_reward': [-671991082.9004169, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224], 'policy_light1_reward': [-4340337694.392566, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111]}","{'mean_env_wait_ms': 12.259661227732636, 'mean_processing_ms': 2.882218166201566, 'mean_inference_ms': 1.8307632713301174}",{},0,156000,"{'sample_time_ms': 67111.886, 'sample_throughput': 59.602, 'learn_time_ms': 17740.935, 'learn_throughput': 225.467}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 24562769461248.0, 'policy_loss': -0.00335895165335387, 'vf_loss': 24562769461248.0, 'vf_explained_var': 9.313226e-09, 'kl': 0.017020864936057478, 'entropy': 0.4003755711019039, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 830100945764352.0, 'policy_loss': -0.0021839271939825267, 'vf_loss': 830100945764352.0, 'vf_explained_var': -1.1175871e-08, 'kl': 0.011551107018021867, 'entropy': 1.0744436476379633, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 156000, 'num_steps_trained': 156000}",False,62,39,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-24-16,1615739056,78.38442087173462,3298.6103961467743,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3298.6103961467743,0,39,"{'cpu_util_percent': 29.650000000000006, 'ram_util_percent': 52.54818181818182}"
78,39,MARL,gneJ12,False,-2111585148.7219243,-36111550162.55191,-9684480771.254944,2481.859375,2,-15240038567.286163,-300039252.8852076,-2132617048.6598644,{},"{'episode_reward': [-2417432422.48234, -5599793768.616113, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989], 'episode_lengths': [2735, 1744, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772], 'policy_gneJ12_reward': [-300039252.8852076, -844624085.897139, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169], 'policy_light1_reward': [-2117393169.5971327, -4755169682.718984, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566]}","{'mean_env_wait_ms': 12.25056091920711, 'mean_processing_ms': 2.8878751422911386, 'mean_inference_ms': 1.8301983597003253}",{},0,160000,"{'sample_time_ms': 67148.116, 'sample_throughput': 59.57, 'learn_time_ms': 17768.605, 'learn_throughput': 225.116}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 74217929572352.0, 'policy_loss': -0.017488377168774605, 'vf_loss': 74217929572352.0, 'vf_explained_var': 7.450581e-09, 'kl': 0.018980003136675805, 'entropy': 0.7022034898400307, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1895955930546176.0, 'policy_loss': -0.011054100992623717, 'vf_loss': 1895955930546176.0, 'vf_explained_var': -4.0978193e-08, 'kl': 0.008450806250039022, 'entropy': 1.418343797326088, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 160000, 'num_steps_trained': 160000}",False,64,40,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-25-43,1615739143,86.08123278617859,3384.691628932953,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3384.691628932953,0,40,"{'cpu_util_percent': 29.022499999999997, 'ram_util_percent': 52.56500000000001}"
79,39,MARL,light1,False,-2111585148.7219243,-36111550162.55191,-9684480771.254944,2481.859375,2,-22475880089.308098,-1679079399.0953887,-7551863722.595083,{},"{'episode_reward': [-2417432422.48234, -5599793768.616113, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989], 'episode_lengths': [2735, 1744, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772], 'policy_gneJ12_reward': [-300039252.8852076, -844624085.897139, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169], 'policy_light1_reward': [-2117393169.5971327, -4755169682.718984, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566]}","{'mean_env_wait_ms': 12.25056091920711, 'mean_processing_ms': 2.8878751422911386, 'mean_inference_ms': 1.8301983597003253}",{},0,160000,"{'sample_time_ms': 67148.116, 'sample_throughput': 59.57, 'learn_time_ms': 17768.605, 'learn_throughput': 225.116}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 74217929572352.0, 'policy_loss': -0.017488377168774605, 'vf_loss': 74217929572352.0, 'vf_explained_var': 7.450581e-09, 'kl': 0.018980003136675805, 'entropy': 0.7022034898400307, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1895955930546176.0, 'policy_loss': -0.011054100992623717, 'vf_loss': 1895955930546176.0, 'vf_explained_var': -4.0978193e-08, 'kl': 0.008450806250039022, 'entropy': 1.418343797326088, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 160000, 'num_steps_trained': 160000}",False,64,40,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-25-43,1615739143,86.08123278617859,3384.691628932953,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3384.691628932953,0,40,"{'cpu_util_percent': 29.022499999999997, 'ram_util_percent': 52.56500000000001}"
80,40,MARL,gneJ12,True,-2111585148.7219243,-36111550162.55191,-9560737335.964447,2474.4545454545455,2,-15240038567.286163,-300039252.8852076,-2094645340.0018435,{},"{'episode_reward': [-4272085435.506847, -6929809377.830323, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113], 'episode_lengths': [2383, 2092, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744], 'policy_gneJ12_reward': [-688232558.147012, -1070868767.743339, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139], 'policy_light1_reward': [-3583852877.3598323, -5858940610.086982, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984]}","{'mean_env_wait_ms': 12.241871007031063, 'mean_processing_ms': 2.893735381821614, 'mean_inference_ms': 1.8296458189922666}",{},0,164000,"{'sample_time_ms': 67144.734, 'sample_throughput': 59.573, 'learn_time_ms': 17743.903, 'learn_throughput': 225.43}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 86294403088384.0, 'policy_loss': -0.014792181871598586, 'vf_loss': 86294403088384.0, 'vf_explained_var': -4.8428774e-08, 'kl': 0.007723116934357677, 'entropy': 0.9123503025621176, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2038291381616640.0, 'policy_loss': -0.00895511228009127, 'vf_loss': 2038291381616640.0, 'vf_explained_var': -4.8428774e-08, 'kl': 0.011034586488676723, 'entropy': 1.387808982282877, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 164000, 'num_steps_trained': 164000}",False,66,41,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-27-10,1615739230,87.20413994789124,3471.895768880844,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3471.895768880844,0,41,"{'cpu_util_percent': 28.67377049180328, 'ram_util_percent': 52.580327868852486}"
81,40,MARL,light1,True,-2111585148.7219243,-36111550162.55191,-9560737335.964447,2474.4545454545455,2,-22475880089.308098,-1679079399.0953887,-7466091995.962607,{},"{'episode_reward': [-4272085435.506847, -6929809377.830323, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113], 'episode_lengths': [2383, 2092, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744], 'policy_gneJ12_reward': [-688232558.147012, -1070868767.743339, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139], 'policy_light1_reward': [-3583852877.3598323, -5858940610.086982, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984]}","{'mean_env_wait_ms': 12.241871007031063, 'mean_processing_ms': 2.893735381821614, 'mean_inference_ms': 1.8296458189922666}",{},0,164000,"{'sample_time_ms': 67144.734, 'sample_throughput': 59.573, 'learn_time_ms': 17743.903, 'learn_throughput': 225.43}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 86294403088384.0, 'policy_loss': -0.014792181871598586, 'vf_loss': 86294403088384.0, 'vf_explained_var': -4.8428774e-08, 'kl': 0.007723116934357677, 'entropy': 0.9123503025621176, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2038291381616640.0, 'policy_loss': -0.00895511228009127, 'vf_loss': 2038291381616640.0, 'vf_explained_var': -4.8428774e-08, 'kl': 0.011034586488676723, 'entropy': 1.387808982282877, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 164000, 'num_steps_trained': 164000}",False,66,41,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-27-10,1615739230,87.20413994789124,3471.895768880844,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3471.895768880844,0,41,"{'cpu_util_percent': 28.67377049180328, 'ram_util_percent': 52.580327868852486}"
82,41,MARL,gneJ12,False,-1686754835.8733134,-36111550162.55191,-9413331270.167053,2464.044117647059,2,-15240038567.286163,-287137176.1454663,-2056282107.4863453,{},"{'episode_reward': [-1686754835.8733134, -7411107361.832801, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323], 'episode_lengths': [1751, 2490, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092], 'policy_gneJ12_reward': [-287137176.1454663, -1293453692.8043478, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339], 'policy_light1_reward': [-1399617659.7278473, -6117653669.028437, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982]}","{'mean_env_wait_ms': 12.233467649686107, 'mean_processing_ms': 2.8997079768487257, 'mean_inference_ms': 1.8291053587766868}",{},0,168000,"{'sample_time_ms': 67199.523, 'sample_throughput': 59.524, 'learn_time_ms': 17757.075, 'learn_throughput': 225.262}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 89278841094144.0, 'policy_loss': -0.0024604589270893484, 'vf_loss': 89278841094144.0, 'vf_explained_var': 6.146729e-08, 'kl': 0.015161309493123554, 'entropy': 0.701263939961791, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1687242254843904.0, 'policy_loss': -0.0030594751588068902, 'vf_loss': 1687242254843904.0, 'vf_explained_var': -3.7252903e-08, 'kl': 0.005536959499295335, 'entropy': 1.3829504996538162, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 168000, 'num_steps_trained': 168000}",False,68,42,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-28-36,1615739316,86.3519492149353,3558.2477180957794,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3558.2477180957794,0,42,"{'cpu_util_percent': 28.777685950413225, 'ram_util_percent': 52.566115702479344}"
83,41,MARL,light1,False,-1686754835.8733134,-36111550162.55191,-9413331270.167053,2464.044117647059,2,-22475880089.308098,-1399617659.7278473,-7357049162.680712,{},"{'episode_reward': [-1686754835.8733134, -7411107361.832801, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323], 'episode_lengths': [1751, 2490, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092], 'policy_gneJ12_reward': [-287137176.1454663, -1293453692.8043478, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339], 'policy_light1_reward': [-1399617659.7278473, -6117653669.028437, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982]}","{'mean_env_wait_ms': 12.233467649686107, 'mean_processing_ms': 2.8997079768487257, 'mean_inference_ms': 1.8291053587766868}",{},0,168000,"{'sample_time_ms': 67199.523, 'sample_throughput': 59.524, 'learn_time_ms': 17757.075, 'learn_throughput': 225.262}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 89278841094144.0, 'policy_loss': -0.0024604589270893484, 'vf_loss': 89278841094144.0, 'vf_explained_var': 6.146729e-08, 'kl': 0.015161309493123554, 'entropy': 0.701263939961791, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1687242254843904.0, 'policy_loss': -0.0030594751588068902, 'vf_loss': 1687242254843904.0, 'vf_explained_var': -3.7252903e-08, 'kl': 0.005536959499295335, 'entropy': 1.3829504996538162, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 168000, 'num_steps_trained': 168000}",False,68,42,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-28-36,1615739316,86.3519492149353,3558.2477180957794,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3558.2477180957794,0,42,"{'cpu_util_percent': 28.777685950413225, 'ram_util_percent': 52.566115702479344}"
84,42,MARL,gneJ12,False,-1686754835.8733134,-36111550162.55191,-9344151181.506718,2463.8985507246375,1,-15240038567.286163,-287137176.1454663,-2036983238.4033654,{},"{'episode_reward': [-4639905152.603937, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801], 'episode_lengths': [2454, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490], 'policy_gneJ12_reward': [-724660140.7607212, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478], 'policy_light1_reward': [-3915245011.8432126, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437]}","{'mean_env_wait_ms': 12.229519706419993, 'mean_processing_ms': 2.902195510264653, 'mean_inference_ms': 1.8288449581537907}",{},0,172000,"{'sample_time_ms': 67250.876, 'sample_throughput': 59.479, 'learn_time_ms': 17702.845, 'learn_throughput': 225.952}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1263202153267200.0, 'policy_loss': 0.005768692557467148, 'vf_loss': 1263202153267200.0, 'vf_explained_var': 3.5390258e-08, 'kl': 0.00814286588865798, 'entropy': 1.06548903696239, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1540276413792256.0, 'policy_loss': -0.0015830349875614047, 'vf_loss': 1540276413792256.0, 'vf_explained_var': -5.5879354e-08, 'kl': 0.010097013873746619, 'entropy': 1.5253912322223186, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 172000, 'num_steps_trained': 172000}",False,69,43,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-29-58,1615739398,81.65607523918152,3639.903793334961,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3639.903793334961,0,43,"{'cpu_util_percent': 30.877391304347828, 'ram_util_percent': 52.553043478260875}"
85,42,MARL,light1,False,-1686754835.8733134,-36111550162.55191,-9344151181.506718,2463.8985507246375,1,-22475880089.308098,-1399617659.7278473,-7307167943.103356,{},"{'episode_reward': [-4639905152.603937, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801], 'episode_lengths': [2454, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490], 'policy_gneJ12_reward': [-724660140.7607212, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478], 'policy_light1_reward': [-3915245011.8432126, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437]}","{'mean_env_wait_ms': 12.229519706419993, 'mean_processing_ms': 2.902195510264653, 'mean_inference_ms': 1.8288449581537907}",{},0,172000,"{'sample_time_ms': 67250.876, 'sample_throughput': 59.479, 'learn_time_ms': 17702.845, 'learn_throughput': 225.952}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1263202153267200.0, 'policy_loss': 0.005768692557467148, 'vf_loss': 1263202153267200.0, 'vf_explained_var': 3.5390258e-08, 'kl': 0.00814286588865798, 'entropy': 1.06548903696239, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1540276413792256.0, 'policy_loss': -0.0015830349875614047, 'vf_loss': 1540276413792256.0, 'vf_explained_var': -5.5879354e-08, 'kl': 0.010097013873746619, 'entropy': 1.5253912322223186, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 172000, 'num_steps_trained': 172000}",False,69,43,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-29-58,1615739398,81.65607523918152,3639.903793334961,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3639.903793334961,0,43,"{'cpu_util_percent': 30.877391304347828, 'ram_util_percent': 52.553043478260875}"
86,43,MARL,gneJ12,False,-1686754835.8733134,-36111550162.55191,-9310810370.414143,2464.549295774648,2,-15240038567.286163,-287137176.1454663,-2054613186.0224097,{},"{'episode_reward': [-8429769091.925227, -7891335683.515518, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937], 'episode_lengths': [2284, 2690, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454], 'policy_gneJ12_reward': [-4068779683.6180153, -1256913074.1409013, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212], 'policy_light1_reward': [-4360989408.307195, -6634422609.37463, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126]}","{'mean_env_wait_ms': 12.221820025143144, 'mean_processing_ms': 2.907479615031666, 'mean_inference_ms': 1.8283285805580578}",{},0,176000,"{'sample_time_ms': 67412.112, 'sample_throughput': 59.337, 'learn_time_ms': 17744.338, 'learn_throughput': 225.424}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 90497952514048.0, 'policy_loss': -0.007576510659419, 'vf_loss': 90497952514048.0, 'vf_explained_var': 1.3038516e-08, 'kl': 0.015002314117737114, 'entropy': 0.855998232960701, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2031057947852800.0, 'policy_loss': -0.008084053202765062, 'vf_loss': 2031057947852800.0, 'vf_explained_var': -3.3527613e-08, 'kl': 0.007007454645645339, 'entropy': 1.544980064034462, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 176000, 'num_steps_trained': 176000}",False,71,44,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-31-25,1615739485,87.59110808372498,3727.494901418686,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3727.494901418686,0,44,"{'cpu_util_percent': 28.288617886178862, 'ram_util_percent': 52.5837398373984}"
87,43,MARL,light1,False,-1686754835.8733134,-36111550162.55191,-9310810370.414143,2464.549295774648,2,-22475880089.308098,-1399617659.7278473,-7256197184.391738,{},"{'episode_reward': [-8429769091.925227, -7891335683.515518, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937], 'episode_lengths': [2284, 2690, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454], 'policy_gneJ12_reward': [-4068779683.6180153, -1256913074.1409013, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212], 'policy_light1_reward': [-4360989408.307195, -6634422609.37463, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126]}","{'mean_env_wait_ms': 12.221820025143144, 'mean_processing_ms': 2.907479615031666, 'mean_inference_ms': 1.8283285805580578}",{},0,176000,"{'sample_time_ms': 67412.112, 'sample_throughput': 59.337, 'learn_time_ms': 17744.338, 'learn_throughput': 225.424}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 90497952514048.0, 'policy_loss': -0.007576510659419, 'vf_loss': 90497952514048.0, 'vf_explained_var': 1.3038516e-08, 'kl': 0.015002314117737114, 'entropy': 0.855998232960701, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2031057947852800.0, 'policy_loss': -0.008084053202765062, 'vf_loss': 2031057947852800.0, 'vf_explained_var': -3.3527613e-08, 'kl': 0.007007454645645339, 'entropy': 1.544980064034462, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 176000, 'num_steps_trained': 176000}",False,71,44,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-31-25,1615739485,87.59110808372498,3727.494901418686,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3727.494901418686,0,44,"{'cpu_util_percent': 28.288617886178862, 'ram_util_percent': 52.5837398373984}"
88,44,MARL,gneJ12,False,-1686754835.8733134,-36111550162.55191,-9263325635.365135,2467.5416666666665,1,-15240038567.286163,-287137176.1454663,-2038592384.2314694,{},"{'episode_reward': [-5891909446.885428, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518], 'episode_lengths': [2680, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690], 'policy_gneJ12_reward': [-901115457.074669, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013], 'policy_light1_reward': [-4990793989.810763, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463]}","{'mean_env_wait_ms': 12.21799583739169, 'mean_processing_ms': 2.9096774200817825, 'mean_inference_ms': 1.8280737023628935}",{},0,180000,"{'sample_time_ms': 66677.986, 'sample_throughput': 59.99, 'learn_time_ms': 17729.046, 'learn_throughput': 225.618}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 27742631100416.0, 'policy_loss': -0.005964917945675552, 'vf_loss': 27742631100416.0, 'vf_explained_var': -4.8428774e-08, 'kl': 0.0101360240514623, 'entropy': 0.44853938091546297, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 829169751556096.0, 'policy_loss': -0.011094723449787125, 'vf_loss': 829169751556096.0, 'vf_explained_var': 7.4505806e-08, 'kl': 0.01173272701271344, 'entropy': 1.0055241342633963, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 180000, 'num_steps_trained': 180000}",False,72,45,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-32-44,1615739564,78.68850588798523,3806.183407306671,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3806.183407306671,0,45,"{'cpu_util_percent': 30.521818181818183, 'ram_util_percent': 52.58000000000001}"
89,44,MARL,light1,False,-1686754835.8733134,-36111550162.55191,-9263325635.365135,2467.5416666666665,1,-22475880089.308098,-1399617659.7278473,-7224733251.13367,{},"{'episode_reward': [-5891909446.885428, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518], 'episode_lengths': [2680, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690], 'policy_gneJ12_reward': [-901115457.074669, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013], 'policy_light1_reward': [-4990793989.810763, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463]}","{'mean_env_wait_ms': 12.21799583739169, 'mean_processing_ms': 2.9096774200817825, 'mean_inference_ms': 1.8280737023628935}",{},0,180000,"{'sample_time_ms': 66677.986, 'sample_throughput': 59.99, 'learn_time_ms': 17729.046, 'learn_throughput': 225.618}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 27742631100416.0, 'policy_loss': -0.005964917945675552, 'vf_loss': 27742631100416.0, 'vf_explained_var': -4.8428774e-08, 'kl': 0.0101360240514623, 'entropy': 0.44853938091546297, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 829169751556096.0, 'policy_loss': -0.011094723449787125, 'vf_loss': 829169751556096.0, 'vf_explained_var': 7.4505806e-08, 'kl': 0.01173272701271344, 'entropy': 1.0055241342633963, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 180000, 'num_steps_trained': 180000}",False,72,45,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-32-44,1615739564,78.68850588798523,3806.183407306671,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3806.183407306671,0,45,"{'cpu_util_percent': 30.521818181818183, 'ram_util_percent': 52.58000000000001}"
90,45,MARL,gneJ12,True,-1686754835.8733134,-36111550162.55191,-9083561409.557781,2462.162162162162,2,-15240038567.286163,-287137176.1454663,-1993385867.7874665,{},"{'episode_reward': [-2200733305.7762156, -3023365255.209923, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428], 'episode_lengths': [2828, 1709, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680], 'policy_gneJ12_reward': [-335037224.7266496, -396865326.8800977, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669], 'policy_light1_reward': [-1865696081.049564, -2626499928.329827, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763]}","{'mean_env_wait_ms': 12.210455410625325, 'mean_processing_ms': 2.9142512377970733, 'mean_inference_ms': 1.8275665947039819}",{},0,184000,"{'sample_time_ms': 67219.014, 'sample_throughput': 59.507, 'learn_time_ms': 17732.183, 'learn_throughput': 225.579}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 59600164880384.0, 'policy_loss': -0.015317491168389097, 'vf_loss': 59600164880384.0, 'vf_explained_var': -7.0780516e-08, 'kl': 0.010531648993492126, 'entropy': 0.7307784743607044, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1631156030144512.0, 'policy_loss': -0.006482174096163362, 'vf_loss': 1631156030144512.0, 'vf_explained_var': 1.3038516e-08, 'kl': 0.013467855940689333, 'entropy': 1.2805267926305532, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 184000, 'num_steps_trained': 184000}",False,74,46,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-34-10,1615739650,85.92568397521973,3892.109091281891,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3892.109091281891,0,46,"{'cpu_util_percent': 28.625, 'ram_util_percent': 52.545833333333334}"
91,45,MARL,light1,True,-1686754835.8733134,-36111550162.55191,-9083561409.557781,2462.162162162162,2,-22475880089.308098,-1399617659.7278473,-7090175541.77032,{},"{'episode_reward': [-2200733305.7762156, -3023365255.209923, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428], 'episode_lengths': [2828, 1709, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680], 'policy_gneJ12_reward': [-335037224.7266496, -396865326.8800977, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669], 'policy_light1_reward': [-1865696081.049564, -2626499928.329827, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763]}","{'mean_env_wait_ms': 12.210455410625325, 'mean_processing_ms': 2.9142512377970733, 'mean_inference_ms': 1.8275665947039819}",{},0,184000,"{'sample_time_ms': 67219.014, 'sample_throughput': 59.507, 'learn_time_ms': 17732.183, 'learn_throughput': 225.579}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 59600164880384.0, 'policy_loss': -0.015317491168389097, 'vf_loss': 59600164880384.0, 'vf_explained_var': -7.0780516e-08, 'kl': 0.010531648993492126, 'entropy': 0.7307784743607044, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1631156030144512.0, 'policy_loss': -0.006482174096163362, 'vf_loss': 1631156030144512.0, 'vf_explained_var': 1.3038516e-08, 'kl': 0.013467855940689333, 'entropy': 1.2805267926305532, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 184000, 'num_steps_trained': 184000}",False,74,46,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-34-10,1615739650,85.92568397521973,3892.109091281891,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3892.109091281891,0,46,"{'cpu_util_percent': 28.625, 'ram_util_percent': 52.545833333333334}"
92,46,MARL,gneJ12,False,-1686754835.8733134,-36111550162.55191,-9064644826.999332,2465.32,1,-15240038567.286163,-287137176.1454663,-1980761983.5138762,{},"{'episode_reward': [-7664817717.674085, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923], 'episode_lengths': [2699, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709], 'policy_gneJ12_reward': [-1046594547.2681506, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977], 'policy_light1_reward': [-6618223170.405935, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827]}","{'mean_env_wait_ms': 12.206833311414766, 'mean_processing_ms': 2.9161595110915086, 'mean_inference_ms': 1.8273159089029765}",{},0,188000,"{'sample_time_ms': 66414.141, 'sample_throughput': 60.228, 'learn_time_ms': 17707.694, 'learn_throughput': 225.891}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 93088053592064.0, 'policy_loss': 0.0025868000520858914, 'vf_loss': 93088053592064.0, 'vf_explained_var': -3.7252903e-08, 'kl': 0.01550393870275002, 'entropy': 0.9563991352915764, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2982004157054976.0, 'policy_loss': 0.002865436290448997, 'vf_loss': 2982004157054976.0, 'vf_explained_var': -5.9604645e-08, 'kl': 0.00653678076560027, 'entropy': 1.7267249748110771, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 188000, 'num_steps_trained': 188000}",False,75,47,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-35-32,1615739732,81.34842705726624,3973.457518339157,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3973.457518339157,0,47,"{'cpu_util_percent': 30.67543859649123, 'ram_util_percent': 52.558771929824566}"
93,46,MARL,light1,False,-1686754835.8733134,-36111550162.55191,-9064644826.999332,2465.32,1,-22475880089.308098,-1399617659.7278473,-7083882843.485461,{},"{'episode_reward': [-7664817717.674085, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923], 'episode_lengths': [2699, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709], 'policy_gneJ12_reward': [-1046594547.2681506, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977], 'policy_light1_reward': [-6618223170.405935, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827]}","{'mean_env_wait_ms': 12.206833311414766, 'mean_processing_ms': 2.9161595110915086, 'mean_inference_ms': 1.8273159089029765}",{},0,188000,"{'sample_time_ms': 66414.141, 'sample_throughput': 60.228, 'learn_time_ms': 17707.694, 'learn_throughput': 225.891}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 93088053592064.0, 'policy_loss': 0.0025868000520858914, 'vf_loss': 93088053592064.0, 'vf_explained_var': -3.7252903e-08, 'kl': 0.01550393870275002, 'entropy': 0.9563991352915764, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2982004157054976.0, 'policy_loss': 0.002865436290448997, 'vf_loss': 2982004157054976.0, 'vf_explained_var': -5.9604645e-08, 'kl': 0.00653678076560027, 'entropy': 1.7267249748110771, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 188000, 'num_steps_trained': 188000}",False,75,47,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-35-32,1615739732,81.34842705726624,3973.457518339157,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",3973.457518339157,0,47,"{'cpu_util_percent': 30.67543859649123, 'ram_util_percent': 52.558771929824566}"
94,47,MARL,gneJ12,False,-1686754835.8733134,-36111550162.55191,-9046453361.650871,2470.2987012987014,2,-15240038567.286163,-287137176.1454663,-1959867964.755805,{},"{'episode_reward': [-10319368058.19908, -6409178763.96813, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085], 'episode_lengths': [3107, 2207, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699], 'policy_gneJ12_reward': [-1407667140.7486799, -945017381.9076248, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506], 'policy_light1_reward': [-8911700917.450415, -5464161382.060507, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935]}","{'mean_env_wait_ms': 12.199798068854701, 'mean_processing_ms': 2.9202253024318647, 'mean_inference_ms': 1.826820225999069}",{},0,192000,"{'sample_time_ms': 66363.152, 'sample_throughput': 60.274, 'learn_time_ms': 17708.997, 'learn_throughput': 225.874}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 83390225973248.0, 'policy_loss': -0.012271258819964714, 'vf_loss': 83390225973248.0, 'vf_explained_var': -4.8428774e-08, 'kl': 0.012597899723914452, 'entropy': 0.7760713826864958, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1949711263072256.0, 'policy_loss': -0.01233915041666478, 'vf_loss': 1949711263072256.0, 'vf_explained_var': -1.4901161e-08, 'kl': 0.008688801739481278, 'entropy': 1.5888747237622738, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 192000, 'num_steps_trained': 192000}",False,77,48,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-36-59,1615739819,87.49558687210083,4060.953105211258,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4060.953105211258,0,48,"{'cpu_util_percent': 28.04552845528455, 'ram_util_percent': 52.545528455284554}"
95,47,MARL,light1,False,-1686754835.8733134,-36111550162.55191,-9046453361.650871,2470.2987012987014,2,-22475880089.308098,-1399617659.7278473,-7086585396.895071,{},"{'episode_reward': [-10319368058.19908, -6409178763.96813, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085], 'episode_lengths': [3107, 2207, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699], 'policy_gneJ12_reward': [-1407667140.7486799, -945017381.9076248, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506], 'policy_light1_reward': [-8911700917.450415, -5464161382.060507, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935]}","{'mean_env_wait_ms': 12.199798068854701, 'mean_processing_ms': 2.9202253024318647, 'mean_inference_ms': 1.826820225999069}",{},0,192000,"{'sample_time_ms': 66363.152, 'sample_throughput': 60.274, 'learn_time_ms': 17708.997, 'learn_throughput': 225.874}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 83390225973248.0, 'policy_loss': -0.012271258819964714, 'vf_loss': 83390225973248.0, 'vf_explained_var': -4.8428774e-08, 'kl': 0.012597899723914452, 'entropy': 0.7760713826864958, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1949711263072256.0, 'policy_loss': -0.01233915041666478, 'vf_loss': 1949711263072256.0, 'vf_explained_var': -1.4901161e-08, 'kl': 0.008688801739481278, 'entropy': 1.5888747237622738, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 192000, 'num_steps_trained': 192000}",False,77,48,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-36-59,1615739819,87.49558687210083,4060.953105211258,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4060.953105211258,0,48,"{'cpu_util_percent': 28.04552845528455, 'ram_util_percent': 52.545528455284554}"
96,48,MARL,gneJ12,False,-1686754835.8733134,-36111550162.55191,-8932972658.489405,2474.481012658228,2,-15240038567.286163,-287137176.1454663,-1929595847.7793498,{},"{'episode_reward': [-4998279002.191491, -4129652171.3543386, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813], 'episode_lengths': [2385, 2886, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207], 'policy_gneJ12_reward': [-822993752.3205738, -705244936.0510466, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248], 'policy_light1_reward': [-4175285249.8709173, -3424407235.3032975, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507]}","{'mean_env_wait_ms': 12.192896574074366, 'mean_processing_ms': 2.9243400779115576, 'mean_inference_ms': 1.826343819114534}",{},0,196000,"{'sample_time_ms': 66999.935, 'sample_throughput': 59.702, 'learn_time_ms': 17727.932, 'learn_throughput': 225.633}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 32915819003904.0, 'policy_loss': -0.01599225215613842, 'vf_loss': 32915819003904.0, 'vf_explained_var': -1.4901161e-08, 'kl': 0.01111720287008211, 'entropy': 0.4278342188335955, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 828182651469824.0, 'policy_loss': -0.010920929969870485, 'vf_loss': 828182651469824.0, 'vf_explained_var': -2.9802322e-08, 'kl': 0.015678646042943, 'entropy': 1.0610963646322489, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 196000, 'num_steps_trained': 196000}",False,79,49,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-38-24,1615739904,84.94289302825928,4145.895998239517,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4145.895998239517,0,49,"{'cpu_util_percent': 29.013445378151253, 'ram_util_percent': 52.63109243697482}"
97,48,MARL,light1,False,-1686754835.8733134,-36111550162.55191,-8932972658.489405,2474.481012658228,2,-22475880089.308098,-1399617659.7278473,-7003376810.71006,{},"{'episode_reward': [-4998279002.191491, -4129652171.3543386, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813], 'episode_lengths': [2385, 2886, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207], 'policy_gneJ12_reward': [-822993752.3205738, -705244936.0510466, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248], 'policy_light1_reward': [-4175285249.8709173, -3424407235.3032975, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507]}","{'mean_env_wait_ms': 12.192896574074366, 'mean_processing_ms': 2.9243400779115576, 'mean_inference_ms': 1.826343819114534}",{},0,196000,"{'sample_time_ms': 66999.935, 'sample_throughput': 59.702, 'learn_time_ms': 17727.932, 'learn_throughput': 225.633}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 32915819003904.0, 'policy_loss': -0.01599225215613842, 'vf_loss': 32915819003904.0, 'vf_explained_var': -1.4901161e-08, 'kl': 0.01111720287008211, 'entropy': 0.4278342188335955, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 828182651469824.0, 'policy_loss': -0.010920929969870485, 'vf_loss': 828182651469824.0, 'vf_explained_var': -2.9802322e-08, 'kl': 0.015678646042943, 'entropy': 1.0610963646322489, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 196000, 'num_steps_trained': 196000}",False,79,49,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-38-24,1615739904,84.94289302825928,4145.895998239517,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4145.895998239517,0,49,"{'cpu_util_percent': 29.013445378151253, 'ram_util_percent': 52.63109243697482}"
98,49,MARL,gneJ12,False,-1686754835.8733134,-36111550162.55191,-8833592231.007277,2462.8888888888887,2,-15240038567.286163,-287137176.1454663,-1901033502.475175,{},"{'episode_reward': [-3096926695.15342, -6719203995.772927, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386], 'episode_lengths': [1865, 2145, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886], 'policy_gneJ12_reward': [-465166408.38311154, -1080475317.5374076, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466], 'policy_light1_reward': [-2631760286.770302, -5638728678.235514, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975]}","{'mean_env_wait_ms': 12.186274693180842, 'mean_processing_ms': 2.9287608433953016, 'mean_inference_ms': 1.8258772619130517}",{},0,200000,"{'sample_time_ms': 67233.227, 'sample_throughput': 59.494, 'learn_time_ms': 17769.205, 'learn_throughput': 225.109}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 93927154647040.0, 'policy_loss': -0.0029103736742399633, 'vf_loss': 93927154647040.0, 'vf_explained_var': -7.4505806e-08, 'kl': 0.013578927813796327, 'entropy': 0.873015558347106, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2014840826626048.0, 'policy_loss': -0.002170663618016988, 'vf_loss': 2014840826626048.0, 'vf_explained_var': -7.0780516e-08, 'kl': 0.009306195453973487, 'entropy': 1.3604608178138733, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 200000, 'num_steps_trained': 200000}",False,81,50,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-39-53,1615739993,88.82689809799194,4234.722896337509,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4234.722896337509,0,50,"{'cpu_util_percent': 28.96209677419355, 'ram_util_percent': 52.63225806451616}"
99,49,MARL,light1,False,-1686754835.8733134,-36111550162.55191,-8833592231.007277,2462.8888888888887,2,-22475880089.308098,-1399617659.7278473,-6932558728.5321045,{},"{'episode_reward': [-3096926695.15342, -6719203995.772927, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386], 'episode_lengths': [1865, 2145, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886], 'policy_gneJ12_reward': [-465166408.38311154, -1080475317.5374076, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466], 'policy_light1_reward': [-2631760286.770302, -5638728678.235514, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975]}","{'mean_env_wait_ms': 12.186274693180842, 'mean_processing_ms': 2.9287608433953016, 'mean_inference_ms': 1.8258772619130517}",{},0,200000,"{'sample_time_ms': 67233.227, 'sample_throughput': 59.494, 'learn_time_ms': 17769.205, 'learn_throughput': 225.109}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 93927154647040.0, 'policy_loss': -0.0029103736742399633, 'vf_loss': 93927154647040.0, 'vf_explained_var': -7.4505806e-08, 'kl': 0.013578927813796327, 'entropy': 0.873015558347106, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2014840826626048.0, 'policy_loss': -0.002170663618016988, 'vf_loss': 2014840826626048.0, 'vf_explained_var': -7.0780516e-08, 'kl': 0.009306195453973487, 'entropy': 1.3604608178138733, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 200000, 'num_steps_trained': 200000}",False,81,50,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-39-53,1615739993,88.82689809799194,4234.722896337509,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4234.722896337509,0,50,"{'cpu_util_percent': 28.96209677419355, 'ram_util_percent': 52.63225806451616}"
100,50,MARL,gneJ12,True,-1686754835.8733134,-36111550162.55191,-8814156253.379747,2468.829268292683,1,-15240038567.286163,-287137176.1454663,-1892659893.2566066,{},"{'episode_reward': [-7239842065.5500145, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927], 'episode_lengths': [2950, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145], 'policy_gneJ12_reward': [-1214397546.5526025, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076], 'policy_light1_reward': [-6025444518.997421, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514]}","{'mean_env_wait_ms': 12.183010609738435, 'mean_processing_ms': 2.930619210213092, 'mean_inference_ms': 1.8256459661092839}",{},0,204000,"{'sample_time_ms': 66433.578, 'sample_throughput': 60.211, 'learn_time_ms': 17774.114, 'learn_throughput': 225.046}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 65427205259264.0, 'policy_loss': -0.008800528914434835, 'vf_loss': 65427205259264.0, 'vf_explained_var': 1.6763806e-08, 'kl': 0.016857452705153264, 'entropy': 0.7333340104669333, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1396246753312768.0, 'policy_loss': -0.007694709405768663, 'vf_loss': 1396246753312768.0, 'vf_explained_var': -1.8626451e-08, 'kl': 0.010221491887932643, 'entropy': 1.2538143284618855, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 204000, 'num_steps_trained': 204000}",False,82,51,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-41-12,1615740072,79.25758481025696,4313.980481147766,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4313.980481147766,0,51,"{'cpu_util_percent': 30.42072072072072, 'ram_util_percent': 52.59549549549551}"
101,50,MARL,light1,True,-1686754835.8733134,-36111550162.55191,-8814156253.379747,2468.829268292683,1,-22475880089.308098,-1399617659.7278473,-6921496360.123143,{},"{'episode_reward': [-7239842065.5500145, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927], 'episode_lengths': [2950, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145], 'policy_gneJ12_reward': [-1214397546.5526025, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076], 'policy_light1_reward': [-6025444518.997421, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514]}","{'mean_env_wait_ms': 12.183010609738435, 'mean_processing_ms': 2.930619210213092, 'mean_inference_ms': 1.8256459661092839}",{},0,204000,"{'sample_time_ms': 66433.578, 'sample_throughput': 60.211, 'learn_time_ms': 17774.114, 'learn_throughput': 225.046}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 65427205259264.0, 'policy_loss': -0.008800528914434835, 'vf_loss': 65427205259264.0, 'vf_explained_var': 1.6763806e-08, 'kl': 0.016857452705153264, 'entropy': 0.7333340104669333, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1396246753312768.0, 'policy_loss': -0.007694709405768663, 'vf_loss': 1396246753312768.0, 'vf_explained_var': -1.8626451e-08, 'kl': 0.010221491887932643, 'entropy': 1.2538143284618855, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 204000, 'num_steps_trained': 204000}",False,82,51,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-41-12,1615740072,79.25758481025696,4313.980481147766,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4313.980481147766,0,51,"{'cpu_util_percent': 30.42072072072072, 'ram_util_percent': 52.59549549549551}"
102,51,MARL,gneJ12,False,-1686754835.8733134,-36111550162.55191,-8672177692.105358,2453.2261904761904,2,-15240038567.286163,-287137176.1454663,-1857956655.3112018,{},"{'episode_reward': [-2469182055.903954, -3232931303.8067436, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145], 'episode_lengths': [1590, 2037, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950], 'policy_gneJ12_reward': [-376314002.68504137, -493933796.4141268, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025], 'policy_light1_reward': [-2092868053.2189114, -2738997507.3926215, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421]}","{'mean_env_wait_ms': 12.176564238448002, 'mean_processing_ms': 2.9344656120823958, 'mean_inference_ms': 1.8251917909869169}",{},0,208000,"{'sample_time_ms': 66382.256, 'sample_throughput': 60.257, 'learn_time_ms': 17782.805, 'learn_throughput': 224.936}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 66343537213440.0, 'policy_loss': -0.011667566926917061, 'vf_loss': 66343537213440.0, 'vf_explained_var': 7.450581e-09, 'kl': 0.015542390319751576, 'entropy': 0.5852489285171032, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1396113040998400.0, 'policy_loss': 0.0017372301081195474, 'vf_loss': 1396113040998400.0, 'vf_explained_var': 6.146729e-08, 'kl': 0.01113373386033345, 'entropy': 1.2900199554860592, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 208000, 'num_steps_trained': 208000}",False,84,52,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-42-38,1615740158,85.92540097236633,4399.905882120132,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4399.905882120132,0,52,"{'cpu_util_percent': 28.721487603305782, 'ram_util_percent': 52.54462809917356}"
103,51,MARL,light1,False,-1686754835.8733134,-36111550162.55191,-8672177692.105358,2453.2261904761904,2,-22475880089.308098,-1399617659.7278473,-6814221036.794159,{},"{'episode_reward': [-2469182055.903954, -3232931303.8067436, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145], 'episode_lengths': [1590, 2037, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950], 'policy_gneJ12_reward': [-376314002.68504137, -493933796.4141268, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025], 'policy_light1_reward': [-2092868053.2189114, -2738997507.3926215, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421]}","{'mean_env_wait_ms': 12.176564238448002, 'mean_processing_ms': 2.9344656120823958, 'mean_inference_ms': 1.8251917909869169}",{},0,208000,"{'sample_time_ms': 66382.256, 'sample_throughput': 60.257, 'learn_time_ms': 17782.805, 'learn_throughput': 224.936}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 66343537213440.0, 'policy_loss': -0.011667566926917061, 'vf_loss': 66343537213440.0, 'vf_explained_var': 7.450581e-09, 'kl': 0.015542390319751576, 'entropy': 0.5852489285171032, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1396113040998400.0, 'policy_loss': 0.0017372301081195474, 'vf_loss': 1396113040998400.0, 'vf_explained_var': 6.146729e-08, 'kl': 0.01113373386033345, 'entropy': 1.2900199554860592, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 208000, 'num_steps_trained': 208000}",False,84,52,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-42-38,1615740158,85.92540097236633,4399.905882120132,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4399.905882120132,0,52,"{'cpu_util_percent': 28.721487603305782, 'ram_util_percent': 52.54462809917356}"
104,52,MARL,gneJ12,False,-1686754835.8733134,-36111550162.55191,-8611282860.802158,2449.5581395348836,2,-15240038567.286163,-287137176.1454663,-1838408271.494628,{},"{'episode_reward': [-5477981833.357709, -6629418058.777674, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436], 'episode_lengths': [2144, 2447, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037], 'policy_gneJ12_reward': [-909809534.7084033, -1124942767.6886528, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268], 'policy_light1_reward': [-4568172298.649288, -5504475291.089009, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215]}","{'mean_env_wait_ms': 12.170628404574645, 'mean_processing_ms': 2.938442034471461, 'mean_inference_ms': 1.8247591510500163}",{},0,212000,"{'sample_time_ms': 67190.79, 'sample_throughput': 59.532, 'learn_time_ms': 17841.049, 'learn_throughput': 224.202}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 395275558453248.0, 'policy_loss': -0.010934950230875984, 'vf_loss': 395275558453248.0, 'vf_explained_var': 3.5390258e-08, 'kl': 0.007301917714357842, 'entropy': 1.2528913207352161, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2118979569057792.0, 'policy_loss': 0.0015628255205228925, 'vf_loss': 2118979569057792.0, 'vf_explained_var': 1.1175871e-08, 'kl': 0.009544997428747592, 'entropy': 1.6633943915367126, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 212000, 'num_steps_trained': 212000}",False,86,53,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-44-09,1615740249,90.32324290275574,4490.229125022888,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4490.229125022888,0,53,"{'cpu_util_percent': 29.580952380952382, 'ram_util_percent': 52.59206349206351}"
105,52,MARL,light1,False,-1686754835.8733134,-36111550162.55191,-8611282860.802158,2449.5581395348836,2,-22475880089.308098,-1399617659.7278473,-6772874589.30753,{},"{'episode_reward': [-5477981833.357709, -6629418058.777674, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436], 'episode_lengths': [2144, 2447, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037], 'policy_gneJ12_reward': [-909809534.7084033, -1124942767.6886528, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268], 'policy_light1_reward': [-4568172298.649288, -5504475291.089009, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215]}","{'mean_env_wait_ms': 12.170628404574645, 'mean_processing_ms': 2.938442034471461, 'mean_inference_ms': 1.8247591510500163}",{},0,212000,"{'sample_time_ms': 67190.79, 'sample_throughput': 59.532, 'learn_time_ms': 17841.049, 'learn_throughput': 224.202}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 395275558453248.0, 'policy_loss': -0.010934950230875984, 'vf_loss': 395275558453248.0, 'vf_explained_var': 3.5390258e-08, 'kl': 0.007301917714357842, 'entropy': 1.2528913207352161, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2118979569057792.0, 'policy_loss': 0.0015628255205228925, 'vf_loss': 2118979569057792.0, 'vf_explained_var': 1.1175871e-08, 'kl': 0.009544997428747592, 'entropy': 1.6633943915367126, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 212000, 'num_steps_trained': 212000}",False,86,53,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-44-09,1615740249,90.32324290275574,4490.229125022888,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4490.229125022888,0,53,"{'cpu_util_percent': 29.580952380952382, 'ram_util_percent': 52.59206349206351}"
106,53,MARL,gneJ12,False,-1686754835.8733134,-36111550162.55191,-8536804818.170788,2453.590909090909,2,-15240038567.286163,-287137176.1454663,-1834349931.547962,{},"{'episode_reward': [-8122143510.3583355, -2546354459.6854653, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674], 'episode_lengths': [2474, 2780, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447], 'policy_gneJ12_reward': [-2929168253.5400286, -390514374.14264065, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528], 'policy_light1_reward': [-5192975256.818316, -2155840085.5428247, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009]}","{'mean_env_wait_ms': 12.164872600962328, 'mean_processing_ms': 2.942545878165278, 'mean_inference_ms': 1.8243364613363744}",{},0,216000,"{'sample_time_ms': 67157.359, 'sample_throughput': 59.562, 'learn_time_ms': 17786.75, 'learn_throughput': 224.887}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 306795682725888.0, 'policy_loss': -0.005429766490124166, 'vf_loss': 306795682725888.0, 'vf_explained_var': -4.0978193e-08, 'kl': 0.014027080113010015, 'entropy': 0.2317464437801391, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 707667795378176.0, 'policy_loss': -0.01331809238763526, 'vf_loss': 707667795378176.0, 'vf_explained_var': -2.2351742e-08, 'kl': 0.008228332189901266, 'entropy': 0.9106592405587435, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 216000, 'num_steps_trained': 216000}",False,88,54,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-45-35,1615740335,86.71339392662048,4576.942518949509,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4576.942518949509,0,54,"{'cpu_util_percent': 29.031147540983607, 'ram_util_percent': 52.595901639344284}"
107,53,MARL,light1,False,-1686754835.8733134,-36111550162.55191,-8536804818.170788,2453.590909090909,2,-22475880089.308098,-1399617659.7278473,-6702454886.622828,{},"{'episode_reward': [-8122143510.3583355, -2546354459.6854653, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674], 'episode_lengths': [2474, 2780, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447], 'policy_gneJ12_reward': [-2929168253.5400286, -390514374.14264065, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528], 'policy_light1_reward': [-5192975256.818316, -2155840085.5428247, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009]}","{'mean_env_wait_ms': 12.164872600962328, 'mean_processing_ms': 2.942545878165278, 'mean_inference_ms': 1.8243364613363744}",{},0,216000,"{'sample_time_ms': 67157.359, 'sample_throughput': 59.562, 'learn_time_ms': 17786.75, 'learn_throughput': 224.887}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 306795682725888.0, 'policy_loss': -0.005429766490124166, 'vf_loss': 306795682725888.0, 'vf_explained_var': -4.0978193e-08, 'kl': 0.014027080113010015, 'entropy': 0.2317464437801391, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 707667795378176.0, 'policy_loss': -0.01331809238763526, 'vf_loss': 707667795378176.0, 'vf_explained_var': -2.2351742e-08, 'kl': 0.008228332189901266, 'entropy': 0.9106592405587435, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 216000, 'num_steps_trained': 216000}",False,88,54,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-45-35,1615740335,86.71339392662048,4576.942518949509,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4576.942518949509,0,54,"{'cpu_util_percent': 29.031147540983607, 'ram_util_percent': 52.595901639344284}"
108,54,MARL,gneJ12,False,-1686754835.8733134,-36111550162.55191,-8554241153.6460905,2458.438202247191,1,-15240038567.286163,-287137176.1454663,-1828024347.2382772,{},"{'episode_reward': [-10088638675.472885, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653], 'episode_lengths': [2885, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780], 'policy_gneJ12_reward': [-1271372927.9860237, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065], 'policy_light1_reward': [-8817265747.486847, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247]}","{'mean_env_wait_ms': 12.162092677559064, 'mean_processing_ms': 2.944303558738759, 'mean_inference_ms': 1.8241303299949545}",{},0,220000,"{'sample_time_ms': 67326.518, 'sample_throughput': 59.412, 'learn_time_ms': 17872.568, 'learn_throughput': 223.807}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 111886167703552.0, 'policy_loss': -0.007604926737258211, 'vf_loss': 111886167703552.0, 'vf_explained_var': -3.7252903e-09, 'kl': 0.0148219445545692, 'entropy': 1.0844802614301443, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 3723039577473024.0, 'policy_loss': -0.007557558768894523, 'vf_loss': 3723039577473024.0, 'vf_explained_var': -3.3527613e-08, 'kl': 0.005709204870072426, 'entropy': 1.655590694397688, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 220000, 'num_steps_trained': 220000}",False,89,55,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-46-57,1615740417,81.23782324790955,4658.180342197418,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4658.180342197418,0,55,"{'cpu_util_percent': 30.449557522123897, 'ram_util_percent': 52.59557522123895}"
109,54,MARL,light1,False,-1686754835.8733134,-36111550162.55191,-8554241153.6460905,2458.438202247191,1,-22475880089.308098,-1399617659.7278473,-6726216806.407818,{},"{'episode_reward': [-10088638675.472885, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653], 'episode_lengths': [2885, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780], 'policy_gneJ12_reward': [-1271372927.9860237, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065], 'policy_light1_reward': [-8817265747.486847, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247]}","{'mean_env_wait_ms': 12.162092677559064, 'mean_processing_ms': 2.944303558738759, 'mean_inference_ms': 1.8241303299949545}",{},0,220000,"{'sample_time_ms': 67326.518, 'sample_throughput': 59.412, 'learn_time_ms': 17872.568, 'learn_throughput': 223.807}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 111886167703552.0, 'policy_loss': -0.007604926737258211, 'vf_loss': 111886167703552.0, 'vf_explained_var': -3.7252903e-09, 'kl': 0.0148219445545692, 'entropy': 1.0844802614301443, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 3723039577473024.0, 'policy_loss': -0.007557558768894523, 'vf_loss': 3723039577473024.0, 'vf_explained_var': -3.3527613e-08, 'kl': 0.005709204870072426, 'entropy': 1.655590694397688, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 220000, 'num_steps_trained': 220000}",False,89,55,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-46-57,1615740417,81.23782324790955,4658.180342197418,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4658.180342197418,0,55,"{'cpu_util_percent': 30.449557522123897, 'ram_util_percent': 52.59557522123895}"
110,55,MARL,gneJ12,True,-1686754835.8733134,-36111550162.55191,-8486207195.840632,2454.3406593406594,2,-15240038567.286163,-287137176.1454663,-1806892337.6698487,{},"{'episode_reward': [-9161855599.02221, -1755536547.973253, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885], 'episode_lengths': [2915, 1629, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885], 'policy_gneJ12_reward': [-1403547595.7073157, -329488228.0422415, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237], 'policy_light1_reward': [-7758308003.314882, -1426048319.9310126, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847]}","{'mean_env_wait_ms': 12.156724556709808, 'mean_processing_ms': 2.947981452921526, 'mean_inference_ms': 1.8237459708962662}",{},0,224000,"{'sample_time_ms': 67540.857, 'sample_throughput': 59.223, 'learn_time_ms': 17881.315, 'learn_throughput': 223.697}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 65004914606080.0, 'policy_loss': -0.009747683769091964, 'vf_loss': 65004914606080.0, 'vf_explained_var': 4.284084e-08, 'kl': 0.016025412463932298, 'entropy': 0.49926409777253866, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1536413472391168.0, 'policy_loss': -0.0027051398064941168, 'vf_loss': 1536413472391168.0, 'vf_explained_var': 5.7742e-08, 'kl': 0.01176581320760306, 'entropy': 1.2658966444432735, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 224000, 'num_steps_trained': 224000}",False,91,56,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-48-25,1615740505,88.15639901161194,4746.33674120903,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4746.33674120903,0,56,"{'cpu_util_percent': 30.4983870967742, 'ram_util_percent': 52.641129032258085}"
111,55,MARL,light1,True,-1686754835.8733134,-36111550162.55191,-8486207195.840632,2454.3406593406594,2,-22475880089.308098,-1399617659.7278473,-6679314858.170787,{},"{'episode_reward': [-9161855599.02221, -1755536547.973253, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885], 'episode_lengths': [2915, 1629, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885], 'policy_gneJ12_reward': [-1403547595.7073157, -329488228.0422415, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237], 'policy_light1_reward': [-7758308003.314882, -1426048319.9310126, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847]}","{'mean_env_wait_ms': 12.156724556709808, 'mean_processing_ms': 2.947981452921526, 'mean_inference_ms': 1.8237459708962662}",{},0,224000,"{'sample_time_ms': 67540.857, 'sample_throughput': 59.223, 'learn_time_ms': 17881.315, 'learn_throughput': 223.697}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 65004914606080.0, 'policy_loss': -0.009747683769091964, 'vf_loss': 65004914606080.0, 'vf_explained_var': 4.284084e-08, 'kl': 0.016025412463932298, 'entropy': 0.49926409777253866, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1536413472391168.0, 'policy_loss': -0.0027051398064941168, 'vf_loss': 1536413472391168.0, 'vf_explained_var': 5.7742e-08, 'kl': 0.01176581320760306, 'entropy': 1.2658966444432735, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 224000, 'num_steps_trained': 224000}",False,91,56,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-48-25,1615740505,88.15639901161194,4746.33674120903,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4746.33674120903,0,56,"{'cpu_util_percent': 30.4983870967742, 'ram_util_percent': 52.641129032258085}"
112,56,MARL,gneJ12,False,-1686754835.8733134,-36111550162.55191,-8441804929.777235,2447.9347826086955,1,-15240038567.286163,-287137176.1454663,-1794235678.3342853,{},"{'episode_reward': [-4401198718.008069, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253], 'episode_lengths': [1865, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629], 'policy_gneJ12_reward': [-642479678.7980547, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415], 'policy_light1_reward': [-3758719039.2100058, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126]}","{'mean_env_wait_ms': 12.154188407017836, 'mean_processing_ms': 2.9495483068439383, 'mean_inference_ms': 1.8235610990348863}",{},0,228000,"{'sample_time_ms': 67647.345, 'sample_throughput': 59.13, 'learn_time_ms': 17889.255, 'learn_throughput': 223.598}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 970639280177152.0, 'policy_loss': -0.010362184766563587, 'vf_loss': 970639280177152.0, 'vf_explained_var': 3.7252903e-09, 'kl': 0.006968726032937411, 'entropy': 1.0918725319206715, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2016319377506304.0, 'policy_loss': -0.0180485438904725, 'vf_loss': 2016319377506304.0, 'vf_explained_var': -7.450581e-09, 'kl': 0.00991186939063482, 'entropy': 1.674966175109148, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 228000, 'num_steps_trained': 228000}",False,92,57,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-49-47,1615740587,82.49214720726013,4828.82888841629,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4828.82888841629,0,57,"{'cpu_util_percent': 29.97565217391304, 'ram_util_percent': 52.597391304347845}"
113,56,MARL,light1,False,-1686754835.8733134,-36111550162.55191,-8441804929.777235,2447.9347826086955,1,-22475880089.308098,-1399617659.7278473,-6647569251.442953,{},"{'episode_reward': [-4401198718.008069, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253], 'episode_lengths': [1865, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629], 'policy_gneJ12_reward': [-642479678.7980547, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415], 'policy_light1_reward': [-3758719039.2100058, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126]}","{'mean_env_wait_ms': 12.154188407017836, 'mean_processing_ms': 2.9495483068439383, 'mean_inference_ms': 1.8235610990348863}",{},0,228000,"{'sample_time_ms': 67647.345, 'sample_throughput': 59.13, 'learn_time_ms': 17889.255, 'learn_throughput': 223.598}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 970639280177152.0, 'policy_loss': -0.010362184766563587, 'vf_loss': 970639280177152.0, 'vf_explained_var': 3.7252903e-09, 'kl': 0.006968726032937411, 'entropy': 1.0918725319206715, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2016319377506304.0, 'policy_loss': -0.0180485438904725, 'vf_loss': 2016319377506304.0, 'vf_explained_var': -7.450581e-09, 'kl': 0.00991186939063482, 'entropy': 1.674966175109148, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 228000, 'num_steps_trained': 228000}",False,92,57,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-49-47,1615740587,82.49214720726013,4828.82888841629,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4828.82888841629,0,57,"{'cpu_util_percent': 29.97565217391304, 'ram_util_percent': 52.597391304347845}"
114,57,MARL,gneJ12,False,-1686754835.8733134,-36111550162.55191,-8461532065.330029,2458.351063829787,2,-15240038567.286163,-287137176.1454663,-1808021046.0712512,{},"{'episode_reward': [-10159391130.441244, -8578569471.075841, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069], 'episode_lengths': [2961, 2914, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865], 'policy_gneJ12_reward': [-3610339306.861568, -1273956617.0817642, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547], 'policy_light1_reward': [-6549051823.579716, -7304612853.994057, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058]}","{'mean_env_wait_ms': 12.149267833740142, 'mean_processing_ms': 2.952843836925471, 'mean_inference_ms': 1.8231929836575056}",{},0,232000,"{'sample_time_ms': 67687.779, 'sample_throughput': 59.095, 'learn_time_ms': 17910.072, 'learn_throughput': 223.338}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 106742360571904.0, 'policy_loss': -0.01839727145852521, 'vf_loss': 106742360571904.0, 'vf_explained_var': -6.3329935e-08, 'kl': 0.013052504655206576, 'entropy': 0.9159503933042288, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2663147806654464.0, 'policy_loss': -0.015619349287590012, 'vf_loss': 2663147806654464.0, 'vf_explained_var': 8.754432e-08, 'kl': 0.011478928630822338, 'entropy': 1.6275878362357616, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 232000, 'num_steps_trained': 232000}",False,94,58,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-51-15,1615740675,88.10842895507812,4916.937317371368,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4916.937317371368,0,58,"{'cpu_util_percent': 28.376612903225805, 'ram_util_percent': 52.60000000000003}"
115,57,MARL,light1,False,-1686754835.8733134,-36111550162.55191,-8461532065.330029,2458.351063829787,2,-22475880089.308098,-1399617659.7278473,-6653511019.258781,{},"{'episode_reward': [-10159391130.441244, -8578569471.075841, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069], 'episode_lengths': [2961, 2914, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865], 'policy_gneJ12_reward': [-3610339306.861568, -1273956617.0817642, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547], 'policy_light1_reward': [-6549051823.579716, -7304612853.994057, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058]}","{'mean_env_wait_ms': 12.149267833740142, 'mean_processing_ms': 2.952843836925471, 'mean_inference_ms': 1.8231929836575056}",{},0,232000,"{'sample_time_ms': 67687.779, 'sample_throughput': 59.095, 'learn_time_ms': 17910.072, 'learn_throughput': 223.338}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 106742360571904.0, 'policy_loss': -0.01839727145852521, 'vf_loss': 106742360571904.0, 'vf_explained_var': -6.3329935e-08, 'kl': 0.013052504655206576, 'entropy': 0.9159503933042288, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2663147806654464.0, 'policy_loss': -0.015619349287590012, 'vf_loss': 2663147806654464.0, 'vf_explained_var': 8.754432e-08, 'kl': 0.011478928630822338, 'entropy': 1.6275878362357616, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 232000, 'num_steps_trained': 232000}",False,94,58,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-51-15,1615740675,88.10842895507812,4916.937317371368,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",4916.937317371368,0,58,"{'cpu_util_percent': 28.376612903225805, 'ram_util_percent': 52.60000000000003}"
116,58,MARL,gneJ12,False,-1686754835.8733134,-36111550162.55191,-8453336731.3590765,2460.221052631579,1,-15240038567.286163,-287137176.1454663,-1809329397.3938398,{},"{'episode_reward': [-7682975338.08967, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841], 'episode_lengths': [2636, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914], 'policy_gneJ12_reward': [-1932314421.7172155, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642], 'policy_light1_reward': [-5750660916.3724575, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057]}","{'mean_env_wait_ms': 12.146957427740292, 'mean_processing_ms': 2.954252647953685, 'mean_inference_ms': 1.8230178744677334}",{},0,236000,"{'sample_time_ms': 67423.687, 'sample_throughput': 59.326, 'learn_time_ms': 17994.509, 'learn_throughput': 222.29}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 293184379289600.0, 'policy_loss': -0.007892251916928217, 'vf_loss': 293184379289600.0, 'vf_explained_var': 2.7939677e-08, 'kl': 0.011700745373673271, 'entropy': 0.9736285265535116, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2701144581210112.0, 'policy_loss': 0.001953237922862172, 'vf_loss': 2701144581210112.0, 'vf_explained_var': -1.0430813e-07, 'kl': 0.0063031132449395955, 'entropy': 1.7537303492426872, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 236000, 'num_steps_trained': 236000}",False,95,59,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-52-39,1615740759,83.14458870887756,5000.081906080246,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5000.081906080246,0,59,"{'cpu_util_percent': 29.97758620689655, 'ram_util_percent': 52.60000000000003}"
117,58,MARL,light1,False,-1686754835.8733134,-36111550162.55191,-8453336731.3590765,2460.221052631579,1,-22475880089.308098,-1399617659.7278473,-6644007333.96524,{},"{'episode_reward': [-7682975338.08967, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841], 'episode_lengths': [2636, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914], 'policy_gneJ12_reward': [-1932314421.7172155, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642], 'policy_light1_reward': [-5750660916.3724575, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057]}","{'mean_env_wait_ms': 12.146957427740292, 'mean_processing_ms': 2.954252647953685, 'mean_inference_ms': 1.8230178744677334}",{},0,236000,"{'sample_time_ms': 67423.687, 'sample_throughput': 59.326, 'learn_time_ms': 17994.509, 'learn_throughput': 222.29}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 293184379289600.0, 'policy_loss': -0.007892251916928217, 'vf_loss': 293184379289600.0, 'vf_explained_var': 2.7939677e-08, 'kl': 0.011700745373673271, 'entropy': 0.9736285265535116, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2701144581210112.0, 'policy_loss': 0.001953237922862172, 'vf_loss': 2701144581210112.0, 'vf_explained_var': -1.0430813e-07, 'kl': 0.0063031132449395955, 'entropy': 1.7537303492426872, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 236000, 'num_steps_trained': 236000}",False,95,59,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-52-39,1615740759,83.14458870887756,5000.081906080246,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5000.081906080246,0,59,"{'cpu_util_percent': 29.97758620689655, 'ram_util_percent': 52.60000000000003}"
118,59,MARL,gneJ12,False,-1686754835.8733134,-36111550162.55191,-8414917301.383065,2463.4742268041236,2,-15240038567.286163,-287137176.1454663,-1791913288.939482,{},"{'episode_reward': [-10109422670.647093, -3070566084.3977823, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967], 'episode_lengths': [2956, 2280, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636], 'policy_gneJ12_reward': [-1470186295.3253741, -459109979.3895999, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155], 'policy_light1_reward': [-8639236375.32171, -2611456105.0081816, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575]}","{'mean_env_wait_ms': 12.142368836607835, 'mean_processing_ms': 2.9573211503733323, 'mean_inference_ms': 1.8226668589869108}",{},0,240000,"{'sample_time_ms': 67325.01, 'sample_throughput': 59.413, 'learn_time_ms': 17962.814, 'learn_throughput': 222.682}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 41132954091520.0, 'policy_loss': -0.013166786346118897, 'vf_loss': 41132954091520.0, 'vf_explained_var': -2.9802322e-08, 'kl': 0.010993863033945672, 'entropy': 0.34060101164504886, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1288375076126720.0, 'policy_loss': -0.009995976666687056, 'vf_loss': 1288375076126720.0, 'vf_explained_var': -4.8428774e-08, 'kl': 0.010538743292272557, 'entropy': 1.2243907153606415, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 240000, 'num_steps_trained': 240000}",False,97,60,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-54-06,1615740846,87.52322602272034,5087.605132102966,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5087.605132102966,0,60,"{'cpu_util_percent': 28.234959349593492, 'ram_util_percent': 52.59918699186994}"
119,59,MARL,light1,False,-1686754835.8733134,-36111550162.55191,-8414917301.383065,2463.4742268041236,2,-22475880089.308098,-1399617659.7278473,-6623004012.443584,{},"{'episode_reward': [-10109422670.647093, -3070566084.3977823, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967], 'episode_lengths': [2956, 2280, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636], 'policy_gneJ12_reward': [-1470186295.3253741, -459109979.3895999, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155], 'policy_light1_reward': [-8639236375.32171, -2611456105.0081816, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575]}","{'mean_env_wait_ms': 12.142368836607835, 'mean_processing_ms': 2.9573211503733323, 'mean_inference_ms': 1.8226668589869108}",{},0,240000,"{'sample_time_ms': 67325.01, 'sample_throughput': 59.413, 'learn_time_ms': 17962.814, 'learn_throughput': 222.682}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 41132954091520.0, 'policy_loss': -0.013166786346118897, 'vf_loss': 41132954091520.0, 'vf_explained_var': -2.9802322e-08, 'kl': 0.010993863033945672, 'entropy': 0.34060101164504886, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1288375076126720.0, 'policy_loss': -0.009995976666687056, 'vf_loss': 1288375076126720.0, 'vf_explained_var': -4.8428774e-08, 'kl': 0.010538743292272557, 'entropy': 1.2243907153606415, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 240000, 'num_steps_trained': 240000}",False,97,60,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-54-06,1615740846,87.52322602272034,5087.605132102966,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5087.605132102966,0,60,"{'cpu_util_percent': 28.234959349593492, 'ram_util_percent': 52.59918699186994}"
120,60,MARL,gneJ12,True,-1686754835.8733134,-36111550162.55191,-8401123946.500776,2468.1938775510203,1,-15240038567.286163,-287137176.1454663,-1782752663.247059,{},"{'episode_reward': [-7063168522.918712, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823], 'episode_lengths': [2926, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280], 'policy_gneJ12_reward': [-894171971.0820235, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999], 'policy_light1_reward': [-6168996551.836704, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816]}","{'mean_env_wait_ms': 12.140087502587813, 'mean_processing_ms': 2.9586211526199855, 'mean_inference_ms': 1.822491343512408}",{},0,244000,"{'sample_time_ms': 67315.159, 'sample_throughput': 59.422, 'learn_time_ms': 17965.823, 'learn_throughput': 222.645}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 43049927507968.0, 'policy_loss': -0.0073113881080644205, 'vf_loss': 43049927507968.0, 'vf_explained_var': -1.0430813e-07, 'kl': 0.013223803878645413, 'entropy': 0.45225307811051607, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1408316076982272.0, 'policy_loss': -0.003948323923395947, 'vf_loss': 1408316076982272.0, 'vf_explained_var': 2.2351742e-08, 'kl': 0.007459973159711808, 'entropy': 1.4197070002555847, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 244000, 'num_steps_trained': 244000}",False,98,61,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-55-25,1615740925,79.18954110145569,5166.794673204422,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5166.794673204422,0,61,"{'cpu_util_percent': 30.409909909909906, 'ram_util_percent': 52.59639639639642}"
121,60,MARL,light1,True,-1686754835.8733134,-36111550162.55191,-8401123946.500776,2468.1938775510203,1,-22475880089.308098,-1399617659.7278473,-6618371283.253718,{},"{'episode_reward': [-7063168522.918712, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823], 'episode_lengths': [2926, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280], 'policy_gneJ12_reward': [-894171971.0820235, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999], 'policy_light1_reward': [-6168996551.836704, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816]}","{'mean_env_wait_ms': 12.140087502587813, 'mean_processing_ms': 2.9586211526199855, 'mean_inference_ms': 1.822491343512408}",{},0,244000,"{'sample_time_ms': 67315.159, 'sample_throughput': 59.422, 'learn_time_ms': 17965.823, 'learn_throughput': 222.645}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 43049927507968.0, 'policy_loss': -0.0073113881080644205, 'vf_loss': 43049927507968.0, 'vf_explained_var': -1.0430813e-07, 'kl': 0.013223803878645413, 'entropy': 0.45225307811051607, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1408316076982272.0, 'policy_loss': -0.003948323923395947, 'vf_loss': 1408316076982272.0, 'vf_explained_var': 2.2351742e-08, 'kl': 0.007459973159711808, 'entropy': 1.4197070002555847, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 244000, 'num_steps_trained': 244000}",False,98,61,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-55-25,1615740925,79.18954110145569,5166.794673204422,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5166.794673204422,0,61,"{'cpu_util_percent': 30.409909909909906, 'ram_util_percent': 52.59639639639642}"
122,61,MARL,gneJ12,False,-1686754835.8733134,-36111550162.55191,-8349816738.960056,2469.45,2,-15240038567.286163,-287137176.1454663,-1765337384.282835,{},"{'episode_reward': [-4337888901.664533, -7333638237.264958, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712], 'episode_lengths': [2503, 2559, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926], 'policy_gneJ12_reward': [-619145639.4702997, -1204831790.6013885, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235], 'policy_light1_reward': [-3718743262.194234, -6128806446.66358, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704]}","{'mean_env_wait_ms': 12.1356714598278, 'mean_processing_ms': 2.9615259601568438, 'mean_inference_ms': 1.8221493545006209}",{},0,248000,"{'sample_time_ms': 67711.079, 'sample_throughput': 59.075, 'learn_time_ms': 18000.258, 'learn_throughput': 222.219}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 114629774934016.0, 'policy_loss': -0.01217063027434051, 'vf_loss': 114629774934016.0, 'vf_explained_var': 1.4901161e-08, 'kl': 0.013094083376927301, 'entropy': 0.9699459113180637, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2239265303953408.0, 'policy_loss': -0.0067427417961880565, 'vf_loss': 2239265303953408.0, 'vf_explained_var': -1.15484e-07, 'kl': 0.009683503943961114, 'entropy': 1.7467273063957691, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 248000, 'num_steps_trained': 248000}",False,100,62,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-56-56,1615741016,90.22908473014832,5257.02375793457,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5257.02375793457,0,62,"{'cpu_util_percent': 27.958730158730162, 'ram_util_percent': 52.59841269841273}"
123,61,MARL,light1,False,-1686754835.8733134,-36111550162.55191,-8349816738.960056,2469.45,2,-22475880089.308098,-1399617659.7278473,-6584479354.677221,{},"{'episode_reward': [-4337888901.664533, -7333638237.264958, -22499901518.185413, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712], 'episode_lengths': [2503, 2559, 3314, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926], 'policy_gneJ12_reward': [-619145639.4702997, -1204831790.6013885, -6015531683.418047, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235], 'policy_light1_reward': [-3718743262.194234, -6128806446.66358, -16484369834.76737, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704]}","{'mean_env_wait_ms': 12.1356714598278, 'mean_processing_ms': 2.9615259601568438, 'mean_inference_ms': 1.8221493545006209}",{},0,248000,"{'sample_time_ms': 67711.079, 'sample_throughput': 59.075, 'learn_time_ms': 18000.258, 'learn_throughput': 222.219}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 114629774934016.0, 'policy_loss': -0.01217063027434051, 'vf_loss': 114629774934016.0, 'vf_explained_var': 1.4901161e-08, 'kl': 0.013094083376927301, 'entropy': 0.9699459113180637, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2239265303953408.0, 'policy_loss': -0.0067427417961880565, 'vf_loss': 2239265303953408.0, 'vf_explained_var': -1.15484e-07, 'kl': 0.009683503943961114, 'entropy': 1.7467273063957691, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 248000, 'num_steps_trained': 248000}",False,100,62,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-56-56,1615741016,90.22908473014832,5257.02375793457,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5257.02375793457,0,62,"{'cpu_util_percent': 27.958730158730162, 'ram_util_percent': 52.59841269841273}"
124,62,MARL,gneJ12,False,-1686754835.8733134,-36111550162.55191,-8187752604.7124195,2457.87,1,-15240038567.286163,-287137176.1454663,-1716085847.002703,{},"{'episode_reward': [-6293488093.421741, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958], 'episode_lengths': [2156, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559], 'policy_gneJ12_reward': [-1090377955.4048524, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885], 'policy_light1_reward': [-5203110138.016882, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358]}","{'mean_env_wait_ms': 12.113828097447316, 'mean_processing_ms': 2.970562778759378, 'mean_inference_ms': 1.822149857435811}",{},0,252000,"{'sample_time_ms': 66773.233, 'sample_throughput': 59.904, 'learn_time_ms': 17966.399, 'learn_throughput': 222.638}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 69496194465792.0, 'policy_loss': -0.006404637941159308, 'vf_loss': 69496194465792.0, 'vf_explained_var': 2.2351742e-08, 'kl': 0.01623916087555699, 'entropy': 0.5137092787772417, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1642758234177536.0, 'policy_loss': -0.015460640599485487, 'vf_loss': 1642758234177536.0, 'vf_explained_var': -8.940697e-08, 'kl': 0.011357931245584041, 'entropy': 1.552983958274126, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 252000, 'num_steps_trained': 252000}",False,101,63,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-58-16,1615741096,80.60668087005615,5337.6304388046265,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5337.6304388046265,0,63,"{'cpu_util_percent': 29.99115044247788, 'ram_util_percent': 52.572566371681425}"
125,62,MARL,light1,False,-1686754835.8733134,-36111550162.55191,-8187752604.7124195,2457.87,1,-22475880089.308098,-1399617659.7278473,-6471666757.709717,{},"{'episode_reward': [-6293488093.421741, -19522681691.132637, -36111550162.55191, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958], 'episode_lengths': [2156, 2999, 2947, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559], 'policy_gneJ12_reward': [-1090377955.4048524, -5227995262.474674, -15240038567.286163, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885], 'policy_light1_reward': [-5203110138.016882, -14294686428.657932, -20871511595.26586, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358]}","{'mean_env_wait_ms': 12.113828097447316, 'mean_processing_ms': 2.970562778759378, 'mean_inference_ms': 1.822149857435811}",{},0,252000,"{'sample_time_ms': 66773.233, 'sample_throughput': 59.904, 'learn_time_ms': 17966.399, 'learn_throughput': 222.638}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 69496194465792.0, 'policy_loss': -0.006404637941159308, 'vf_loss': 69496194465792.0, 'vf_explained_var': 2.2351742e-08, 'kl': 0.01623916087555699, 'entropy': 0.5137092787772417, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1642758234177536.0, 'policy_loss': -0.015460640599485487, 'vf_loss': 1642758234177536.0, 'vf_explained_var': -8.940697e-08, 'kl': 0.011357931245584041, 'entropy': 1.552983958274126, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 252000, 'num_steps_trained': 252000}",False,101,63,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-58-16,1615741096,80.60668087005615,5337.6304388046265,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5337.6304388046265,0,63,"{'cpu_util_percent': 29.99115044247788, 'ram_util_percent': 52.572566371681425}"
126,63,MARL,gneJ12,False,-1686754835.8733134,-30696007864.268707,-7746913928.900271,2453.18,2,-8220127774.960614,-287137176.1454663,-1527252842.672454,{},"{'episode_reward': [-6207584560.953309, -5342779711.51648, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741], 'episode_lengths': [2946, 2531, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156], 'policy_gneJ12_reward': [-895584598.6864187, -689148798.0495437, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524], 'policy_light1_reward': [-5311999962.266876, -4653630913.46693, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882]}","{'mean_env_wait_ms': 12.090131045433795, 'mean_processing_ms': 2.9859022557005646, 'mean_inference_ms': 1.822036494318575}",{},0,256000,"{'sample_time_ms': 66602.802, 'sample_throughput': 60.058, 'learn_time_ms': 17982.078, 'learn_throughput': 222.444}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 31973091049472.0, 'policy_loss': -0.007799698505550623, 'vf_loss': 31973091049472.0, 'vf_explained_var': -1.8626451e-08, 'kl': 0.01286522981536109, 'entropy': 0.13440952231758274, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 944567289380864.0, 'policy_loss': -0.002073933108476922, 'vf_loss': 944567289380864.0, 'vf_explained_var': 7.4505806e-08, 'kl': 0.008131591595883947, 'entropy': 1.0494224689900875, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 256000, 'num_steps_trained': 256000}",False,103,64,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-59-42,1615741182,85.1659631729126,5422.796401977539,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5422.796401977539,0,64,"{'cpu_util_percent': 28.798333333333336, 'ram_util_percent': 52.596666666666685}"
127,63,MARL,light1,False,-1686754835.8733134,-30696007864.268707,-7746913928.900271,2453.18,2,-22475880089.308098,-1399617659.7278473,-6219661086.227818,{},"{'episode_reward': [-6207584560.953309, -5342779711.51648, -17245191149.60162, -15767598036.95368, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741], 'episode_lengths': [2946, 2531, 2353, 2848, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156], 'policy_gneJ12_reward': [-895584598.6864187, -689148798.0495437, -4873195201.312979, -3361593945.652061, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524], 'policy_light1_reward': [-5311999962.266876, -4653630913.46693, -12371995948.288662, -12406004091.301584, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882]}","{'mean_env_wait_ms': 12.090131045433795, 'mean_processing_ms': 2.9859022557005646, 'mean_inference_ms': 1.822036494318575}",{},0,256000,"{'sample_time_ms': 66602.802, 'sample_throughput': 60.058, 'learn_time_ms': 17982.078, 'learn_throughput': 222.444}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 31973091049472.0, 'policy_loss': -0.007799698505550623, 'vf_loss': 31973091049472.0, 'vf_explained_var': -1.8626451e-08, 'kl': 0.01286522981536109, 'entropy': 0.13440952231758274, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 944567289380864.0, 'policy_loss': -0.002073933108476922, 'vf_loss': 944567289380864.0, 'vf_explained_var': 7.4505806e-08, 'kl': 0.008131591595883947, 'entropy': 1.0494224689900875, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 256000, 'num_steps_trained': 256000}",False,103,64,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_12-59-42,1615741182,85.1659631729126,5422.796401977539,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5422.796401977539,0,64,"{'cpu_util_percent': 28.798333333333336, 'ram_util_percent': 52.596666666666685}"
128,64,MARL,gneJ12,False,-1492193727.9310474,-30696007864.268707,-7482577711.537824,2448.33,2,-8220127774.960614,-240361471.98858276,-1454655288.319793,{},"{'episode_reward': [-1492193727.9310474, -5086973722.37946, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648], 'episode_lengths': [2431, 2285, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531], 'policy_gneJ12_reward': [-240361471.98858276, -734672239.7103533, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437], 'policy_light1_reward': [-1251832255.9424639, -4352301482.669098, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693]}","{'mean_env_wait_ms': 12.071740508682947, 'mean_processing_ms': 2.997768832574907, 'mean_inference_ms': 1.8218878110264527}",{},0,260000,"{'sample_time_ms': 67407.253, 'sample_throughput': 59.341, 'learn_time_ms': 17925.025, 'learn_throughput': 223.152}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 51233195622400.0, 'policy_loss': -0.018372713588178158, 'vf_loss': 51233195622400.0, 'vf_explained_var': 7.636845e-08, 'kl': 0.011989575810730457, 'entropy': 0.4521771124564111, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1442421074296832.0, 'policy_loss': -0.006731358385877684, 'vf_loss': 1442421074296832.0, 'vf_explained_var': 2.9802322e-08, 'kl': 0.012290876067709178, 'entropy': 1.2406095191836357, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 260000, 'num_steps_trained': 260000}",False,105,65,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-01-10,1615741270,88.71211075782776,5511.508512735367,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5511.508512735367,0,65,"{'cpu_util_percent': 27.899193548387093, 'ram_util_percent': 52.598387096774225}"
129,64,MARL,light1,False,-1492193727.9310474,-30696007864.268707,-7482577711.537824,2448.33,2,-22475880089.308098,-1251832255.9424639,-6027922423.218031,{},"{'episode_reward': [-1492193727.9310474, -5086973722.37946, -8901056531.067524, -6816838214.453951, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648], 'episode_lengths': [2431, 2285, 1748, 2185, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531], 'policy_gneJ12_reward': [-240361471.98858276, -734672239.7103533, -1738780344.1620493, -1364514198.155023, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437], 'policy_light1_reward': [-1251832255.9424639, -4352301482.669098, -7162276186.905483, -5452324016.298927, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693]}","{'mean_env_wait_ms': 12.071740508682947, 'mean_processing_ms': 2.997768832574907, 'mean_inference_ms': 1.8218878110264527}",{},0,260000,"{'sample_time_ms': 67407.253, 'sample_throughput': 59.341, 'learn_time_ms': 17925.025, 'learn_throughput': 223.152}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 51233195622400.0, 'policy_loss': -0.018372713588178158, 'vf_loss': 51233195622400.0, 'vf_explained_var': 7.636845e-08, 'kl': 0.011989575810730457, 'entropy': 0.4521771124564111, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1442421074296832.0, 'policy_loss': -0.006731358385877684, 'vf_loss': 1442421074296832.0, 'vf_explained_var': 2.9802322e-08, 'kl': 0.012290876067709178, 'entropy': 1.2406095191836357, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 260000, 'num_steps_trained': 260000}",False,105,65,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-01-10,1615741270,88.71211075782776,5511.508512735367,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5511.508512735367,0,65,"{'cpu_util_percent': 27.899193548387093, 'ram_util_percent': 52.598387096774225}"
130,65,MARL,gneJ12,True,-1492193727.9310474,-30696007864.268707,-7439326427.971993,2449.21,2,-8220127774.960614,-240361471.98858276,-1440953407.3785715,{},"{'episode_reward': [-5809425999.603443, -5583340389.3349695, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946], 'episode_lengths': [1902, 2119, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285], 'policy_gneJ12_reward': [-877936282.0853721, -855170166.1095194, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533], 'policy_light1_reward': [-4931489717.51806, -4728170223.225439, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098]}","{'mean_env_wait_ms': 12.060582335538951, 'mean_processing_ms': 3.007012402971668, 'mean_inference_ms': 1.8218496280541416}",{},0,264000,"{'sample_time_ms': 67272.945, 'sample_throughput': 59.459, 'learn_time_ms': 17956.24, 'learn_throughput': 222.764}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 92752555540480.0, 'policy_loss': -0.008242032170528546, 'vf_loss': 92752555540480.0, 'vf_explained_var': -1.8626451e-09, 'kl': 0.012911572572193108, 'entropy': 1.0012793187052011, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2281727183552512.0, 'policy_loss': -0.009730407153256238, 'vf_loss': 2281727183552512.0, 'vf_explained_var': 4.8428774e-08, 'kl': 0.007807665126165375, 'entropy': 1.6883609816432, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 264000, 'num_steps_trained': 264000}",False,107,66,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-02-37,1615741357,87.12499189376831,5598.633504629135,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5598.633504629135,0,66,"{'cpu_util_percent': 28.549180327868854, 'ram_util_percent': 52.60000000000002}"
131,65,MARL,light1,True,-1492193727.9310474,-30696007864.268707,-7439326427.971993,2449.21,2,-22475880089.308098,-1251832255.9424639,-5998373020.593422,{},"{'episode_reward': [-5809425999.603443, -5583340389.3349695, -13014368030.96041, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946], 'episode_lengths': [1902, 2119, 2920, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285], 'policy_gneJ12_reward': [-877936282.0853721, -855170166.1095194, -2352689390.238283, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533], 'policy_light1_reward': [-4931489717.51806, -4728170223.225439, -10661678640.722157, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098]}","{'mean_env_wait_ms': 12.060582335538951, 'mean_processing_ms': 3.007012402971668, 'mean_inference_ms': 1.8218496280541416}",{},0,264000,"{'sample_time_ms': 67272.945, 'sample_throughput': 59.459, 'learn_time_ms': 17956.24, 'learn_throughput': 222.764}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 92752555540480.0, 'policy_loss': -0.008242032170528546, 'vf_loss': 92752555540480.0, 'vf_explained_var': -1.8626451e-09, 'kl': 0.012911572572193108, 'entropy': 1.0012793187052011, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2281727183552512.0, 'policy_loss': -0.009730407153256238, 'vf_loss': 2281727183552512.0, 'vf_explained_var': 4.8428774e-08, 'kl': 0.007807665126165375, 'entropy': 1.6883609816432, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 264000, 'num_steps_trained': 264000}",False,107,66,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-02-37,1615741357,87.12499189376831,5598.633504629135,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5598.633504629135,0,66,"{'cpu_util_percent': 28.549180327868854, 'ram_util_percent': 52.60000000000002}"
132,66,MARL,gneJ12,False,-1492193727.9310474,-30696007864.268707,-7391802916.564042,2446.8,1,-8220127774.960614,-240361471.98858276,-1429769837.5020084,{},"{'episode_reward': [-8262016890.165334, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695], 'episode_lengths': [2679, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119], 'policy_gneJ12_reward': [-1234332402.5819883, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194], 'policy_light1_reward': [-7027684487.5833435, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439]}","{'mean_env_wait_ms': 12.055364330214074, 'mean_processing_ms': 3.0099838804212613, 'mean_inference_ms': 1.8217782393047026}",{},0,268000,"{'sample_time_ms': 67039.03, 'sample_throughput': 59.667, 'learn_time_ms': 17901.593, 'learn_throughput': 223.444}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 70517100511232.0, 'policy_loss': -0.01183870216482319, 'vf_loss': 70517100511232.0, 'vf_explained_var': 2.4214387e-08, 'kl': 0.014107223236351274, 'entropy': 0.6192283723503351, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1683911876804608.0, 'policy_loss': -0.008435645780991763, 'vf_loss': 1683911876804608.0, 'vf_explained_var': -3.7252903e-08, 'kl': 0.012415391160175204, 'entropy': 1.3987134099006653, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 268000, 'num_steps_trained': 268000}",False,108,67,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-03-57,1615741437,79.60656309127808,5678.240067720413,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5678.240067720413,0,67,"{'cpu_util_percent': 30.085585585585587, 'ram_util_percent': 52.5927927927928}"
133,66,MARL,light1,False,-1492193727.9310474,-30696007864.268707,-7391802916.564042,2446.8,1,-22475880089.308098,-1251832255.9424639,-5962033079.062034,{},"{'episode_reward': [-8262016890.165334, -16533917686.045094, -12701986319.848959, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695], 'episode_lengths': [2679, 2551, 2292, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119], 'policy_gneJ12_reward': [-1234332402.5819883, -3144883383.4714975, -3246806088.4263425, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194], 'policy_light1_reward': [-7027684487.5833435, -13389034302.573643, -9455180231.42261, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439]}","{'mean_env_wait_ms': 12.055364330214074, 'mean_processing_ms': 3.0099838804212613, 'mean_inference_ms': 1.8217782393047026}",{},0,268000,"{'sample_time_ms': 67039.03, 'sample_throughput': 59.667, 'learn_time_ms': 17901.593, 'learn_throughput': 223.444}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 70517100511232.0, 'policy_loss': -0.01183870216482319, 'vf_loss': 70517100511232.0, 'vf_explained_var': 2.4214387e-08, 'kl': 0.014107223236351274, 'entropy': 0.6192283723503351, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1683911876804608.0, 'policy_loss': -0.008435645780991763, 'vf_loss': 1683911876804608.0, 'vf_explained_var': -3.7252903e-08, 'kl': 0.012415391160175204, 'entropy': 1.3987134099006653, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 268000, 'num_steps_trained': 268000}",False,108,67,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-03-57,1615741437,79.60656309127808,5678.240067720413,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5678.240067720413,0,67,"{'cpu_util_percent': 30.085585585585587, 'ram_util_percent': 52.5927927927928}"
134,67,MARL,gneJ12,False,-1492193727.9310474,-30696007864.268707,-7169842040.352167,2444.24,2,-8220127774.960614,-240361471.98858276,-1376891999.1571074,{},"{'episode_reward': [-3544071693.232634, -3495744691.473967, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334], 'episode_lengths': [2784, 1803, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679], 'policy_gneJ12_reward': [-585805773.4265519, -518099863.981158, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883], 'policy_light1_reward': [-2958265919.8060827, -2977644827.492804, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435]}","{'mean_env_wait_ms': 12.0455746216389, 'mean_processing_ms': 3.0174121024000056, 'mean_inference_ms': 1.8216703578412463}",{},0,272000,"{'sample_time_ms': 66865.786, 'sample_throughput': 59.821, 'learn_time_ms': 17849.614, 'learn_throughput': 224.094}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 31343474704384.0, 'policy_loss': -0.010528584767598659, 'vf_loss': 31343474704384.0, 'vf_explained_var': 1.6763806e-08, 'kl': 0.015240234963130206, 'entropy': 0.20753946353215724, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 850475310120960.0, 'policy_loss': -0.0038159528630785644, 'vf_loss': 850475310120960.0, 'vf_explained_var': -1.1175871e-08, 'kl': 0.011265462744631805, 'entropy': 1.1549999751150608, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 272000, 'num_steps_trained': 272000}",False,110,68,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-05-23,1615741523,85.85641670227051,5764.096484422684,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5764.096484422684,0,68,"{'cpu_util_percent': 28.70495867768595, 'ram_util_percent': 52.59834710743804}"
135,67,MARL,light1,False,-1492193727.9310474,-30696007864.268707,-7169842040.352167,2444.24,2,-22475880089.308098,-1251832255.9424639,-5792950041.195061,{},"{'episode_reward': [-3544071693.232634, -3495744691.473967, -30696007864.268707, -21654490950.09948, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334], 'episode_lengths': [2784, 1803, 3178, 2585, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679], 'policy_gneJ12_reward': [-585805773.4265519, -518099863.981158, -8220127774.960614, -6466577996.483743, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883], 'policy_light1_reward': [-2958265919.8060827, -2977644827.492804, -22475880089.308098, -15187912953.615782, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435]}","{'mean_env_wait_ms': 12.0455746216389, 'mean_processing_ms': 3.0174121024000056, 'mean_inference_ms': 1.8216703578412463}",{},0,272000,"{'sample_time_ms': 66865.786, 'sample_throughput': 59.821, 'learn_time_ms': 17849.614, 'learn_throughput': 224.094}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 31343474704384.0, 'policy_loss': -0.010528584767598659, 'vf_loss': 31343474704384.0, 'vf_explained_var': 1.6763806e-08, 'kl': 0.015240234963130206, 'entropy': 0.20753946353215724, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 850475310120960.0, 'policy_loss': -0.0038159528630785644, 'vf_loss': 850475310120960.0, 'vf_explained_var': -1.1175871e-08, 'kl': 0.011265462744631805, 'entropy': 1.1549999751150608, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 272000, 'num_steps_trained': 272000}",False,110,68,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-05-23,1615741523,85.85641670227051,5764.096484422684,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5764.096484422684,0,68,"{'cpu_util_percent': 28.70495867768595, 'ram_util_percent': 52.59834710743804}"
136,68,MARL,gneJ12,False,-1492193727.9310474,-15188900474.907383,-6756408610.293112,2440.29,2,-6360153602.347856,-240361471.98858276,-1247433614.4018557,{},"{'episode_reward': [-3121846543.736691, -7885309264.72593, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967], 'episode_lengths': [2605, 2763, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803], 'policy_gneJ12_reward': [-472614073.474828, -1268253222.4443936, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158], 'policy_light1_reward': [-2649232470.2618575, -6617056042.281524, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804]}","{'mean_env_wait_ms': 12.034295268732315, 'mean_processing_ms': 3.0235236896802307, 'mean_inference_ms': 1.8209605696801259}",{},0,276000,"{'sample_time_ms': 67370.4, 'sample_throughput': 59.373, 'learn_time_ms': 17821.147, 'learn_throughput': 224.452}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 82991178973184.0, 'policy_loss': -0.024158846674254164, 'vf_loss': 82991178973184.0, 'vf_explained_var': 4.284084e-08, 'kl': 0.012531194486655295, 'entropy': 0.7925750613212585, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1830821912641536.0, 'policy_loss': -0.0037557516916422173, 'vf_loss': 1830821912641536.0, 'vf_explained_var': 5.2154064e-08, 'kl': 0.01343542399990838, 'entropy': 1.591101497411728, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 276000, 'num_steps_trained': 276000}",False,112,69,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-06-51,1615741611,87.90949892997742,5852.005983352661,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5852.005983352661,0,69,"{'cpu_util_percent': 28.991056910569107, 'ram_util_percent': 52.64390243902441}"
137,68,MARL,light1,False,-1492193727.9310474,-15188900474.907383,-6756408610.293112,2440.29,2,-12998176642.26039,-1251832255.9424639,-5508974995.891256,{},"{'episode_reward': [-3121846543.736691, -7885309264.72593, -11030657890.936306, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967], 'episode_lengths': [2605, 2763, 2370, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803], 'policy_gneJ12_reward': [-472614073.474828, -1268253222.4443936, -2282946649.2014513, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158], 'policy_light1_reward': [-2649232470.2618575, -6617056042.281524, -8747711241.734858, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804]}","{'mean_env_wait_ms': 12.034295268732315, 'mean_processing_ms': 3.0235236896802307, 'mean_inference_ms': 1.8209605696801259}",{},0,276000,"{'sample_time_ms': 67370.4, 'sample_throughput': 59.373, 'learn_time_ms': 17821.147, 'learn_throughput': 224.452}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 82991178973184.0, 'policy_loss': -0.024158846674254164, 'vf_loss': 82991178973184.0, 'vf_explained_var': 4.284084e-08, 'kl': 0.012531194486655295, 'entropy': 0.7925750613212585, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1830821912641536.0, 'policy_loss': -0.0037557516916422173, 'vf_loss': 1830821912641536.0, 'vf_explained_var': 5.2154064e-08, 'kl': 0.01343542399990838, 'entropy': 1.591101497411728, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 276000, 'num_steps_trained': 276000}",False,112,69,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-06-51,1615741611,87.90949892997742,5852.005983352661,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5852.005983352661,0,69,"{'cpu_util_percent': 28.991056910569107, 'ram_util_percent': 52.64390243902441}"
138,69,MARL,gneJ12,False,-1492193727.9310474,-15188900474.907383,-6723371056.371288,2444.1,1,-6360153602.347856,-240361471.98858276,-1235405802.6112978,{},"{'episode_reward': [-7726902498.753979, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593], 'episode_lengths': [2751, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763], 'policy_gneJ12_reward': [-1080165470.1456554, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936], 'policy_light1_reward': [-6646737028.608324, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524]}","{'mean_env_wait_ms': 12.028546783149045, 'mean_processing_ms': 3.027324663686552, 'mean_inference_ms': 1.8203848485959355}",{},0,280000,"{'sample_time_ms': 66645.24, 'sample_throughput': 60.019, 'learn_time_ms': 17852.621, 'learn_throughput': 224.057}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 66445207011328.0, 'policy_loss': -0.007327685423661023, 'vf_loss': 66445207011328.0, 'vf_explained_var': -4.8428774e-08, 'kl': 0.020296623202739283, 'entropy': 0.7043832363560796, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2100382608130048.0, 'policy_loss': -0.006279942870605737, 'vf_loss': 2100382608130048.0, 'vf_explained_var': 1.3038516e-08, 'kl': 0.00787288237188477, 'entropy': 1.7462266571819782, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 280000, 'num_steps_trained': 280000}",False,113,70,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-08-12,1615741692,80.58682012557983,5932.592803478241,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5932.592803478241,0,70,"{'cpu_util_percent': 30.578761061946903, 'ram_util_percent': 52.600000000000016}"
139,69,MARL,light1,False,-1492193727.9310474,-15188900474.907383,-6723371056.371288,2444.1,1,-12998176642.26039,-1251832255.9424639,-5487965253.75999,{},"{'episode_reward': [-7726902498.753979, -4291906933.4735136, -15188900474.907383, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593], 'episode_lengths': [2751, 3053, 2676, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763], 'policy_gneJ12_reward': [-1080165470.1456554, -813198609.6003428, -2190723832.6470366, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936], 'policy_light1_reward': [-6646737028.608324, -3478708323.8731723, -12998176642.26039, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524]}","{'mean_env_wait_ms': 12.028546783149045, 'mean_processing_ms': 3.027324663686552, 'mean_inference_ms': 1.8203848485959355}",{},0,280000,"{'sample_time_ms': 66645.24, 'sample_throughput': 60.019, 'learn_time_ms': 17852.621, 'learn_throughput': 224.057}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 66445207011328.0, 'policy_loss': -0.007327685423661023, 'vf_loss': 66445207011328.0, 'vf_explained_var': -4.8428774e-08, 'kl': 0.020296623202739283, 'entropy': 0.7043832363560796, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2100382608130048.0, 'policy_loss': -0.006279942870605737, 'vf_loss': 2100382608130048.0, 'vf_explained_var': 1.3038516e-08, 'kl': 0.00787288237188477, 'entropy': 1.7462266571819782, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 280000, 'num_steps_trained': 280000}",False,113,70,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-08-12,1615741692,80.58682012557983,5932.592803478241,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",5932.592803478241,0,70,"{'cpu_util_percent': 30.578761061946903, 'ram_util_percent': 52.600000000000016}"
140,70,MARL,gneJ12,True,-1492193727.9310474,-14714738308.336655,-6600860446.178572,2423.6,2,-6360153602.347856,-240361471.98858276,-1214982359.754794,{},"{'episode_reward': [-4117389826.929455, -3112356562.179847, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979], 'episode_lengths': [2011, 1668, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751], 'policy_gneJ12_reward': [-536590291.3253861, -424987865.27157956, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554], 'policy_light1_reward': [-3580799535.6040707, -2687368696.90827, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324]}","{'mean_env_wait_ms': 12.01641349389975, 'mean_processing_ms': 3.0355287933360016, 'mean_inference_ms': 1.8188161200396689}",{},0,284000,"{'sample_time_ms': 67638.531, 'sample_throughput': 59.138, 'learn_time_ms': 17874.857, 'learn_throughput': 223.778}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 75186408914944.0, 'policy_loss': -0.010009749559685588, 'vf_loss': 75186408914944.0, 'vf_explained_var': 4.0978193e-08, 'kl': 0.01085628404689487, 'entropy': 0.6841730810701847, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1719299131572224.0, 'policy_loss': -0.005041329306550324, 'vf_loss': 1719299131572224.0, 'vf_explained_var': -8.940697e-08, 'kl': 0.011271722534729633, 'entropy': 1.6607967615127563, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 284000, 'num_steps_trained': 284000}",False,115,71,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-09-41,1615741781,89.34395217895508,6021.936755657196,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6021.936755657196,0,71,"{'cpu_util_percent': 27.9768, 'ram_util_percent': 52.62720000000002}"
141,70,MARL,light1,True,-1492193727.9310474,-14714738308.336655,-6600860446.178572,2423.6,2,-11496500228.6477,-1251832255.9424639,-5385878086.423779,{},"{'episode_reward': [-4117389826.929455, -3112356562.179847, -12338378808.304688, -14714738308.336655, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979], 'episode_lengths': [2011, 1668, 2258, 2533, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751], 'policy_gneJ12_reward': [-536590291.3253861, -424987865.27157956, -2812118606.894831, -3218238079.6890216, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554], 'policy_light1_reward': [-3580799535.6040707, -2687368696.90827, -9526260201.409876, -11496500228.6477, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324]}","{'mean_env_wait_ms': 12.01641349389975, 'mean_processing_ms': 3.0355287933360016, 'mean_inference_ms': 1.8188161200396689}",{},0,284000,"{'sample_time_ms': 67638.531, 'sample_throughput': 59.138, 'learn_time_ms': 17874.857, 'learn_throughput': 223.778}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 75186408914944.0, 'policy_loss': -0.010009749559685588, 'vf_loss': 75186408914944.0, 'vf_explained_var': 4.0978193e-08, 'kl': 0.01085628404689487, 'entropy': 0.6841730810701847, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1719299131572224.0, 'policy_loss': -0.005041329306550324, 'vf_loss': 1719299131572224.0, 'vf_explained_var': -8.940697e-08, 'kl': 0.011271722534729633, 'entropy': 1.6607967615127563, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 284000, 'num_steps_trained': 284000}",False,115,71,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-09-41,1615741781,89.34395217895508,6021.936755657196,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6021.936755657196,0,71,"{'cpu_util_percent': 27.9768, 'ram_util_percent': 52.62720000000002}"
142,71,MARL,gneJ12,False,-1492193727.9310474,-14065922442.680698,-6483921914.4792,2428.46,2,-6360153602.347856,-240361471.98858276,-1182387675.8116322,{},"{'episode_reward': [-7293927110.61356, -8065336836.090649, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847], 'episode_lengths': [2748, 2529, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668], 'policy_gneJ12_reward': [-1607514609.0146015, -1163373683.253074, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956], 'policy_light1_reward': [-5686412501.598962, -6901963152.837594, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827]}","{'mean_env_wait_ms': 12.004922136777875, 'mean_processing_ms': 3.0419379851055486, 'mean_inference_ms': 1.817313768072964}",{},0,288000,"{'sample_time_ms': 67567.592, 'sample_throughput': 59.2, 'learn_time_ms': 17876.589, 'learn_throughput': 223.756}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 160223522193408.0, 'policy_loss': -0.009432866529095918, 'vf_loss': 160223522193408.0, 'vf_explained_var': 2.2351742e-08, 'kl': 0.009876044758129865, 'entropy': 0.7371091144159436, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2247049344974848.0, 'policy_loss': -0.0030040193087188527, 'vf_loss': 2247049344974848.0, 'vf_explained_var': -8.940697e-08, 'kl': 0.01653797876497265, 'entropy': 1.6667251735925674, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 288000, 'num_steps_trained': 288000}",False,117,72,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-11-11,1615741871,89.53693699836731,6111.473692655563,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6111.473692655563,0,72,"{'cpu_util_percent': 28.4216, 'ram_util_percent': 52.623200000000026}"
143,71,MARL,light1,False,-1492193727.9310474,-14065922442.680698,-6483921914.4792,2428.46,2,-11111196608.93751,-1251832255.9424639,-5301534238.667568,{},"{'episode_reward': [-7293927110.61356, -8065336836.090649, -13762111169.039543, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847], 'episode_lengths': [2748, 2529, 2826, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668], 'policy_gneJ12_reward': [-1607514609.0146015, -1163373683.253074, -2747664207.650495, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956], 'policy_light1_reward': [-5686412501.598962, -6901963152.837594, -11014446961.389086, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827]}","{'mean_env_wait_ms': 12.004922136777875, 'mean_processing_ms': 3.0419379851055486, 'mean_inference_ms': 1.817313768072964}",{},0,288000,"{'sample_time_ms': 67567.592, 'sample_throughput': 59.2, 'learn_time_ms': 17876.589, 'learn_throughput': 223.756}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 160223522193408.0, 'policy_loss': -0.009432866529095918, 'vf_loss': 160223522193408.0, 'vf_explained_var': 2.2351742e-08, 'kl': 0.009876044758129865, 'entropy': 0.7371091144159436, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2247049344974848.0, 'policy_loss': -0.0030040193087188527, 'vf_loss': 2247049344974848.0, 'vf_explained_var': -8.940697e-08, 'kl': 0.01653797876497265, 'entropy': 1.6667251735925674, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 288000, 'num_steps_trained': 288000}",False,117,72,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-11-11,1615741871,89.53693699836731,6111.473692655563,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6111.473692655563,0,72,"{'cpu_util_percent': 28.4216, 'ram_util_percent': 52.623200000000026}"
144,72,MARL,gneJ12,False,-1492193727.9310474,-14065922442.680698,-6377207398.498026,2427.68,1,-6360153602.347856,-240361471.98858276,-1159439090.4166894,{},"{'episode_reward': [-3090659570.922184, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649], 'episode_lengths': [2748, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529], 'policy_gneJ12_reward': [-452805668.15621835, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074], 'policy_light1_reward': [-2637853902.7659593, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594]}","{'mean_env_wait_ms': 11.999494764641822, 'mean_processing_ms': 3.044508942462878, 'mean_inference_ms': 1.8166130324261287}",{},0,292000,"{'sample_time_ms': 67623.424, 'sample_throughput': 59.151, 'learn_time_ms': 17936.397, 'learn_throughput': 223.01}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 39170359230464.0, 'policy_loss': -0.018870537081966177, 'vf_loss': 39170359230464.0, 'vf_explained_var': 3.3527613e-08, 'kl': 0.009535920413327403, 'entropy': 0.2387405512854457, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1057845176958976.0, 'policy_loss': -0.006817688496084884, 'vf_loss': 1057845176958976.0, 'vf_explained_var': 0.0, 'kl': 0.010011606980697252, 'entropy': 1.1015481874346733, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 292000, 'num_steps_trained': 292000}",False,118,73,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-12-32,1615741952,81.76292705535889,6193.236619710922,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6193.236619710922,0,73,"{'cpu_util_percent': 34.04, 'ram_util_percent': 52.64521739130437}"
145,72,MARL,light1,False,-1492193727.9310474,-14065922442.680698,-6377207398.498026,2427.68,1,-11111196608.93751,-1251832255.9424639,-5217768308.081336,{},"{'episode_reward': [-3090659570.922184, -5533008143.253435, -6516083011.275359, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649], 'episode_lengths': [2748, 1870, 2923, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529], 'policy_gneJ12_reward': [-452805668.15621835, -769453938.434237, -1344690942.973757, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074], 'policy_light1_reward': [-2637853902.7659593, -4763554204.819202, -5171392068.301593, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594]}","{'mean_env_wait_ms': 11.999494764641822, 'mean_processing_ms': 3.044508942462878, 'mean_inference_ms': 1.8166130324261287}",{},0,292000,"{'sample_time_ms': 67623.424, 'sample_throughput': 59.151, 'learn_time_ms': 17936.397, 'learn_throughput': 223.01}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 39170359230464.0, 'policy_loss': -0.018870537081966177, 'vf_loss': 39170359230464.0, 'vf_explained_var': 3.3527613e-08, 'kl': 0.009535920413327403, 'entropy': 0.2387405512854457, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1057845176958976.0, 'policy_loss': -0.006817688496084884, 'vf_loss': 1057845176958976.0, 'vf_explained_var': 0.0, 'kl': 0.010011606980697252, 'entropy': 1.1015481874346733, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 292000, 'num_steps_trained': 292000}",False,118,73,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-12-32,1615741952,81.76292705535889,6193.236619710922,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6193.236619710922,0,73,"{'cpu_util_percent': 34.04, 'ram_util_percent': 52.64521739130437}"
146,73,MARL,gneJ12,False,-1492193727.9310474,-14065922442.680698,-6416620330.388293,2433.87,2,-6360153602.347856,-240361471.98858276,-1170845227.883696,{},"{'episode_reward': [-8554029376.3252325, -7436354967.230244, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184], 'episode_lengths': [3027, 2385, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748], 'policy_gneJ12_reward': [-1193868000.630011, -2060890627.4786792, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835], 'policy_light1_reward': [-7360161375.695224, -5375464339.751551, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593]}","{'mean_env_wait_ms': 11.990737880351084, 'mean_processing_ms': 3.050571967024281, 'mean_inference_ms': 1.8154113044880698}",{},0,296000,"{'sample_time_ms': 68131.937, 'sample_throughput': 58.71, 'learn_time_ms': 18020.996, 'learn_throughput': 221.963}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 519753550004224.0, 'policy_loss': -0.0012775788200087845, 'vf_loss': 519753550004224.0, 'vf_explained_var': 1.1175871e-08, 'kl': 0.00719844333070796, 'entropy': 0.9273708052933216, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2524993564966912.0, 'policy_loss': 0.0020088493765797466, 'vf_loss': 2524993564966912.0, 'vf_explained_var': 0.0, 'kl': 0.012021470502077136, 'entropy': 1.7981803975999355, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 296000, 'num_steps_trained': 296000}",False,120,74,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-14-04,1615742044,91.0969557762146,6284.333575487137,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6284.333575487137,0,74,"{'cpu_util_percent': 30.68359375, 'ram_util_percent': 52.62421875000001}"
147,73,MARL,light1,False,-1492193727.9310474,-14065922442.680698,-6416620330.388293,2433.87,2,-11111196608.93751,-1251832255.9424639,-5245775102.504596,{},"{'episode_reward': [-8554029376.3252325, -7436354967.230244, -9066472798.644518, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184], 'episode_lengths': [3027, 2385, 2938, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748], 'policy_gneJ12_reward': [-1193868000.630011, -2060890627.4786792, -1769373887.294995, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835], 'policy_light1_reward': [-7360161375.695224, -5375464339.751551, -7297098911.349546, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593]}","{'mean_env_wait_ms': 11.990737880351084, 'mean_processing_ms': 3.050571967024281, 'mean_inference_ms': 1.8154113044880698}",{},0,296000,"{'sample_time_ms': 68131.937, 'sample_throughput': 58.71, 'learn_time_ms': 18020.996, 'learn_throughput': 221.963}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 519753550004224.0, 'policy_loss': -0.0012775788200087845, 'vf_loss': 519753550004224.0, 'vf_explained_var': 1.1175871e-08, 'kl': 0.00719844333070796, 'entropy': 0.9273708052933216, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2524993564966912.0, 'policy_loss': 0.0020088493765797466, 'vf_loss': 2524993564966912.0, 'vf_explained_var': 0.0, 'kl': 0.012021470502077136, 'entropy': 1.7981803975999355, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 296000, 'num_steps_trained': 296000}",False,120,74,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-14-04,1615742044,91.0969557762146,6284.333575487137,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6284.333575487137,0,74,"{'cpu_util_percent': 30.68359375, 'ram_util_percent': 52.62421875000001}"
148,74,MARL,gneJ12,False,-1492193727.9310474,-14065922442.680698,-6405637424.113391,2431.4,1,-6360153602.347856,-240361471.98858276,-1164661951.771877,{},"{'episode_reward': [-7968182171.15419, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244], 'episode_lengths': [2691, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385], 'policy_gneJ12_reward': [-1151046276.113098, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792], 'policy_light1_reward': [-6817135895.041087, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551]}","{'mean_env_wait_ms': 11.98662331274797, 'mean_processing_ms': 3.053108467726935, 'mean_inference_ms': 1.8148485344293936}",{},0,300000,"{'sample_time_ms': 67266.488, 'sample_throughput': 59.465, 'learn_time_ms': 18057.204, 'learn_throughput': 221.518}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 64929233895424.0, 'policy_loss': -0.00933504055137746, 'vf_loss': 64929233895424.0, 'vf_explained_var': 1.8626451e-08, 'kl': 0.013577572186477482, 'entropy': 0.5201858594082296, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1899854989099008.0, 'policy_loss': -0.005520845239516348, 'vf_loss': 1899854989099008.0, 'vf_explained_var': 2.6077032e-08, 'kl': 0.011113432541606016, 'entropy': 1.3984016180038452, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 300000, 'num_steps_trained': 300000}",False,121,75,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-15-24,1615742124,80.41992092132568,6364.7534964084625,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6364.7534964084625,0,75,"{'cpu_util_percent': 31.187610619469027, 'ram_util_percent': 52.61681415929204}"
149,74,MARL,light1,False,-1492193727.9310474,-14065922442.680698,-6405637424.113391,2431.4,1,-11111196608.93751,-1251832255.9424639,-5240975472.341511,{},"{'episode_reward': [-7968182171.15419, -14065922442.680698, -9887304431.805023, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244], 'episode_lengths': [2691, 2289, 2689, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385], 'policy_gneJ12_reward': [-1151046276.113098, -2954725833.743199, -1609907313.875391, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792], 'policy_light1_reward': [-6817135895.041087, -11111196608.93751, -8277397117.929639, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551]}","{'mean_env_wait_ms': 11.98662331274797, 'mean_processing_ms': 3.053108467726935, 'mean_inference_ms': 1.8148485344293936}",{},0,300000,"{'sample_time_ms': 67266.488, 'sample_throughput': 59.465, 'learn_time_ms': 18057.204, 'learn_throughput': 221.518}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 64929233895424.0, 'policy_loss': -0.00933504055137746, 'vf_loss': 64929233895424.0, 'vf_explained_var': 1.8626451e-08, 'kl': 0.013577572186477482, 'entropy': 0.5201858594082296, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1899854989099008.0, 'policy_loss': -0.005520845239516348, 'vf_loss': 1899854989099008.0, 'vf_explained_var': 2.6077032e-08, 'kl': 0.011113432541606016, 'entropy': 1.3984016180038452, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 300000, 'num_steps_trained': 300000}",False,121,75,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-15-24,1615742124,80.41992092132568,6364.7534964084625,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6364.7534964084625,0,75,"{'cpu_util_percent': 31.187610619469027, 'ram_util_percent': 52.61681415929204}"
150,75,MARL,gneJ12,True,-1492193727.9310474,-13903271510.926207,-6237242828.368466,2426.4,2,-6360153602.347856,-240361471.98858276,-1129849470.6398382,{},"{'episode_reward': [-2382050929.558002, -4731716370.43546, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419], 'episode_lengths': [1935, 2543, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691], 'policy_gneJ12_reward': [-371659347.2860377, -711725687.1286288, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098], 'policy_light1_reward': [-2010391582.271968, -4019990683.3068314, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087]}","{'mean_env_wait_ms': 11.979359096573944, 'mean_processing_ms': 3.058708235593761, 'mean_inference_ms': 1.813885022815593}",{},0,304000,"{'sample_time_ms': 67273.771, 'sample_throughput': 59.459, 'learn_time_ms': 18055.466, 'learn_throughput': 221.54}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 49824786415616.0, 'policy_loss': -0.010289396945154294, 'vf_loss': 49824786415616.0, 'vf_explained_var': -5.5879354e-09, 'kl': 0.01116801812167978, 'entropy': 0.3059636827092618, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1415228893954048.0, 'policy_loss': -0.010216697686701082, 'vf_loss': 1415228893954048.0, 'vf_explained_var': 5.2154064e-08, 'kl': 0.01490324032783974, 'entropy': 1.3965098969638348, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 304000, 'num_steps_trained': 304000}",False,123,76,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-16-51,1615742211,87.18058490753174,6451.934081315994,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6451.934081315994,0,76,"{'cpu_util_percent': 29.291056910569107, 'ram_util_percent': 52.634959349593515}"
151,75,MARL,light1,True,-1492193727.9310474,-13903271510.926207,-6237242828.368466,2426.4,2,-10965740521.917059,-1251832255.9424639,-5107393357.728628,{},"{'episode_reward': [-2382050929.558002, -4731716370.43546, -6973768963.014075, -2702796301.4121284, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419], 'episode_lengths': [1935, 2543, 2335, 2025, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691], 'policy_gneJ12_reward': [-371659347.2860377, -711725687.1286288, -1259642618.67862, -437585389.44147974, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098], 'policy_light1_reward': [-2010391582.271968, -4019990683.3068314, -5714126344.335461, -2265210911.970647, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087]}","{'mean_env_wait_ms': 11.979359096573944, 'mean_processing_ms': 3.058708235593761, 'mean_inference_ms': 1.813885022815593}",{},0,304000,"{'sample_time_ms': 67273.771, 'sample_throughput': 59.459, 'learn_time_ms': 18055.466, 'learn_throughput': 221.54}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 49824786415616.0, 'policy_loss': -0.010289396945154294, 'vf_loss': 49824786415616.0, 'vf_explained_var': -5.5879354e-09, 'kl': 0.01116801812167978, 'entropy': 0.3059636827092618, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1415228893954048.0, 'policy_loss': -0.010216697686701082, 'vf_loss': 1415228893954048.0, 'vf_explained_var': 5.2154064e-08, 'kl': 0.01490324032783974, 'entropy': 1.3965098969638348, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 304000, 'num_steps_trained': 304000}",False,123,76,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-16-51,1615742211,87.18058490753174,6451.934081315994,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6451.934081315994,0,76,"{'cpu_util_percent': 29.291056910569107, 'ram_util_percent': 52.634959349593515}"
152,76,MARL,gneJ12,False,-1492193727.9310474,-13903271510.926207,-6272128708.883197,2426.81,2,-6360153602.347856,-240361471.98858276,-1131274761.6843927,{},"{'episode_reward': [-6666458452.552175, -6498694863.347114, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546], 'episode_lengths': [2272, 2129, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543], 'policy_gneJ12_reward': [-931092535.4871192, -908664577.0884508, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288], 'policy_light1_reward': [-5735365917.065057, -5590030286.258678, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314]}","{'mean_env_wait_ms': 11.972847592705655, 'mean_processing_ms': 3.063080955691396, 'mean_inference_ms': 1.8130260054884402}",{},0,308000,"{'sample_time_ms': 68113.202, 'sample_throughput': 58.726, 'learn_time_ms': 18135.787, 'learn_throughput': 220.558}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 82614810836992.0, 'policy_loss': -0.02191260815015994, 'vf_loss': 82614810836992.0, 'vf_explained_var': -5.5879354e-09, 'kl': 0.011660740128718317, 'entropy': 0.5308265220373869, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2374768565157888.0, 'policy_loss': 0.004172371787717566, 'vf_loss': 2374768565157888.0, 'vf_explained_var': -7.0780516e-08, 'kl': 0.013113548513501883, 'entropy': 1.5084748938679695, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 308000, 'num_steps_trained': 308000}",False,125,77,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-18-20,1615742300,88.80384993553162,6540.737931251526,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6540.737931251526,0,77,"{'cpu_util_percent': 31.458064516129035, 'ram_util_percent': 52.62661290322582}"
153,76,MARL,light1,False,-1492193727.9310474,-13903271510.926207,-6272128708.883197,2426.81,2,-10965740521.917059,-1251832255.9424639,-5140853947.198804,{},"{'episode_reward': [-6666458452.552175, -6498694863.347114, -13092312763.036932, -4337090628.119313, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546], 'episode_lengths': [2272, 2129, 3024, 1950, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543], 'policy_gneJ12_reward': [-931092535.4871192, -908664577.0884508, -2126572241.1198597, -709287456.5439576, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288], 'policy_light1_reward': [-5735365917.065057, -5590030286.258678, -10965740521.917059, -3627803171.575361, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314]}","{'mean_env_wait_ms': 11.972847592705655, 'mean_processing_ms': 3.063080955691396, 'mean_inference_ms': 1.8130260054884402}",{},0,308000,"{'sample_time_ms': 68113.202, 'sample_throughput': 58.726, 'learn_time_ms': 18135.787, 'learn_throughput': 220.558}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 82614810836992.0, 'policy_loss': -0.02191260815015994, 'vf_loss': 82614810836992.0, 'vf_explained_var': -5.5879354e-09, 'kl': 0.011660740128718317, 'entropy': 0.5308265220373869, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2374768565157888.0, 'policy_loss': 0.004172371787717566, 'vf_loss': 2374768565157888.0, 'vf_explained_var': -7.0780516e-08, 'kl': 0.013113548513501883, 'entropy': 1.5084748938679695, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 308000, 'num_steps_trained': 308000}",False,125,77,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-18-20,1615742300,88.80384993553162,6540.737931251526,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6540.737931251526,0,77,"{'cpu_util_percent': 31.458064516129035, 'ram_util_percent': 52.62661290322582}"
154,77,MARL,gneJ12,False,-1444233443.3195717,-13903271510.926207,-6177380038.680172,2418.26,2,-6360153602.347856,-240361471.98858276,-1114582223.648532,{},"{'episode_reward': [-1444233443.3195717, -6510302927.534121, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114], 'episode_lengths': [2124, 1995, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129], 'policy_gneJ12_reward': [-243804053.56138143, -922801840.5163531, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508], 'policy_light1_reward': [-1200429389.7581913, -5587501087.017774, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678]}","{'mean_env_wait_ms': 11.966715991087597, 'mean_processing_ms': 3.067533962988024, 'mean_inference_ms': 1.8122455219052227}",{},0,312000,"{'sample_time_ms': 68445.469, 'sample_throughput': 58.441, 'learn_time_ms': 18156.094, 'learn_throughput': 220.312}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 70935119265792.0, 'policy_loss': 0.002719032490858808, 'vf_loss': 70935119265792.0, 'vf_explained_var': -2.9802322e-08, 'kl': 0.016140344931045547, 'entropy': 0.2743315012194216, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1697303551279104.0, 'policy_loss': -0.004417362448293716, 'vf_loss': 1697303551279104.0, 'vf_explained_var': 1.3038516e-08, 'kl': 0.01615720680274535, 'entropy': 0.9928690195083618, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 312000, 'num_steps_trained': 312000}",False,127,78,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-19-50,1615742390,89.38145279884338,6630.119384050369,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6630.119384050369,0,78,"{'cpu_util_percent': 28.897599999999997, 'ram_util_percent': 52.63360000000002}"
155,77,MARL,light1,False,-1444233443.3195717,-13903271510.926207,-6177380038.680172,2418.26,2,-10138596848.88492,-1200429389.7581913,-5062797815.03164,{},"{'episode_reward': [-1444233443.3195717, -6510302927.534121, -10698663530.73486, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114], 'episode_lengths': [2124, 1995, 2506, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129], 'policy_gneJ12_reward': [-243804053.56138143, -922801840.5163531, -1878810111.6350858, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508], 'policy_light1_reward': [-1200429389.7581913, -5587501087.017774, -8819853419.099773, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678]}","{'mean_env_wait_ms': 11.966715991087597, 'mean_processing_ms': 3.067533962988024, 'mean_inference_ms': 1.8122455219052227}",{},0,312000,"{'sample_time_ms': 68445.469, 'sample_throughput': 58.441, 'learn_time_ms': 18156.094, 'learn_throughput': 220.312}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 70935119265792.0, 'policy_loss': 0.002719032490858808, 'vf_loss': 70935119265792.0, 'vf_explained_var': -2.9802322e-08, 'kl': 0.016140344931045547, 'entropy': 0.2743315012194216, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1697303551279104.0, 'policy_loss': -0.004417362448293716, 'vf_loss': 1697303551279104.0, 'vf_explained_var': 1.3038516e-08, 'kl': 0.01615720680274535, 'entropy': 0.9928690195083618, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 312000, 'num_steps_trained': 312000}",False,127,78,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-19-50,1615742390,89.38145279884338,6630.119384050369,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6630.119384050369,0,78,"{'cpu_util_percent': 28.897599999999997, 'ram_util_percent': 52.63360000000002}"
156,78,MARL,gneJ12,False,-1444233443.3195717,-13903271510.926207,-6131236968.038527,2423.71,1,-6360153602.347856,-240361471.98858276,-1104875352.1130488,{},"{'episode_reward': [-6084356466.57016, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121], 'episode_lengths': [3051, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995], 'policy_gneJ12_reward': [-908122958.086771, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531], 'policy_light1_reward': [-5176233508.483386, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774]}","{'mean_env_wait_ms': 11.96394321072753, 'mean_processing_ms': 3.0693450851068826, 'mean_inference_ms': 1.811905978271916}",{},0,316000,"{'sample_time_ms': 67723.787, 'sample_throughput': 59.063, 'learn_time_ms': 18174.167, 'learn_throughput': 220.093}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 61530066255872.0, 'policy_loss': -0.009886386804282665, 'vf_loss': 61530066255872.0, 'vf_explained_var': 3.7252903e-09, 'kl': 0.011535075274878182, 'entropy': 0.5428533470258117, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1496425087107072.0, 'policy_loss': -0.0011780729400925338, 'vf_loss': 1496425087107072.0, 'vf_explained_var': 1.0244548e-07, 'kl': 0.013148349156836048, 'entropy': 1.4744631499052048, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 316000, 'num_steps_trained': 316000}",False,128,79,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-21-10,1615742470,80.87067008018494,6710.990054130554,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6710.990054130554,0,79,"{'cpu_util_percent': 31.166666666666664, 'ram_util_percent': 52.672807017543875}"
157,78,MARL,light1,False,-1444233443.3195717,-13903271510.926207,-6131236968.038527,2423.71,1,-10138596848.88492,-1200429389.7581913,-5026361615.925475,{},"{'episode_reward': [-6084356466.57016, -8425260774.904094, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121], 'episode_lengths': [3051, 2084, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995], 'policy_gneJ12_reward': [-908122958.086771, -1329293161.70196, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531], 'policy_light1_reward': [-5176233508.483386, -7095967613.202136, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774]}","{'mean_env_wait_ms': 11.96394321072753, 'mean_processing_ms': 3.0693450851068826, 'mean_inference_ms': 1.811905978271916}",{},0,316000,"{'sample_time_ms': 67723.787, 'sample_throughput': 59.063, 'learn_time_ms': 18174.167, 'learn_throughput': 220.093}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 61530066255872.0, 'policy_loss': -0.009886386804282665, 'vf_loss': 61530066255872.0, 'vf_explained_var': 3.7252903e-09, 'kl': 0.011535075274878182, 'entropy': 0.5428533470258117, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 1496425087107072.0, 'policy_loss': -0.0011780729400925338, 'vf_loss': 1496425087107072.0, 'vf_explained_var': 1.0244548e-07, 'kl': 0.013148349156836048, 'entropy': 1.4744631499052048, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 316000, 'num_steps_trained': 316000}",False,128,79,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-21-10,1615742470,80.87067008018494,6710.990054130554,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6710.990054130554,0,79,"{'cpu_util_percent': 31.166666666666664, 'ram_util_percent': 52.672807017543875}"
158,79,MARL,gneJ12,False,-1444233443.3195717,-13903271510.926207,-6135926648.690108,2432.86,1,-6360153602.347856,-240361471.98858276,-1104065038.5722926,{},"{'episode_reward': [-8894228840.062227, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016], 'episode_lengths': [2999, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051], 'policy_gneJ12_reward': [-1248261807.6263287, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771], 'policy_light1_reward': [-7645967032.435898, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386]}","{'mean_env_wait_ms': 11.961177897746582, 'mean_processing_ms': 3.07102592605349, 'mean_inference_ms': 1.811567779332145}",{},0,320000,"{'sample_time_ms': 67814.886, 'sample_throughput': 58.984, 'learn_time_ms': 18303.293, 'learn_throughput': 218.54}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 76084817297408.0, 'policy_loss': -0.011475203733425587, 'vf_loss': 76084817297408.0, 'vf_explained_var': -3.3527613e-08, 'kl': 0.01380989042809233, 'entropy': 0.8678127899765968, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 3055092689272832.0, 'policy_loss': -0.003088530385866761, 'vf_loss': 3055092689272832.0, 'vf_explained_var': 5.029142e-08, 'kl': 0.008629131574707571, 'entropy': 1.6687243059277534, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 320000, 'num_steps_trained': 320000}",False,129,80,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-22-33,1615742553,82.78952503204346,6793.779579162598,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6793.779579162598,0,80,"{'cpu_util_percent': 33.09051724137932, 'ram_util_percent': 52.617241379310364}"
159,79,MARL,light1,False,-1444233443.3195717,-13903271510.926207,-6135926648.690108,2432.86,1,-10138596848.88492,-1200429389.7581913,-5031861610.117813,{},"{'episode_reward': [-8894228840.062227, -4729620124.92776, -12040794274.753006, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016], 'episode_lengths': [2999, 2915, 3012, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051], 'policy_gneJ12_reward': [-1248261807.6263287, -766599035.3552872, -1902197425.8680964, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771], 'policy_light1_reward': [-7645967032.435898, -3963021089.5724688, -10138596848.88492, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386]}","{'mean_env_wait_ms': 11.961177897746582, 'mean_processing_ms': 3.07102592605349, 'mean_inference_ms': 1.811567779332145}",{},0,320000,"{'sample_time_ms': 67814.886, 'sample_throughput': 58.984, 'learn_time_ms': 18303.293, 'learn_throughput': 218.54}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 76084817297408.0, 'policy_loss': -0.011475203733425587, 'vf_loss': 76084817297408.0, 'vf_explained_var': -3.3527613e-08, 'kl': 0.01380989042809233, 'entropy': 0.8678127899765968, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 3055092689272832.0, 'policy_loss': -0.003088530385866761, 'vf_loss': 3055092689272832.0, 'vf_explained_var': 5.029142e-08, 'kl': 0.008629131574707571, 'entropy': 1.6687243059277534, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 320000, 'num_steps_trained': 320000}",False,129,80,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-22-33,1615742553,82.78952503204346,6793.779579162598,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6793.779579162598,0,80,"{'cpu_util_percent': 33.09051724137932, 'ram_util_percent': 52.617241379310364}"
160,80,MARL,gneJ12,True,-1444233443.3195717,-13903271510.926207,-6120636170.533029,2429.03,2,-6360153602.347856,-240361471.98858276,-1096844999.1858401,{},"{'episode_reward': [-7846510150.3855095, -7394856433.587324, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227], 'episode_lengths': [2605, 2939, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999], 'policy_gneJ12_reward': [-942666099.8653208, -1004126422.7128243, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287], 'policy_light1_reward': [-6903844050.520193, -6390730010.874503, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898]}","{'mean_env_wait_ms': 11.955945470702098, 'mean_processing_ms': 3.0750538796034284, 'mean_inference_ms': 1.8109535993573578}",{},0,324000,"{'sample_time_ms': 67690.485, 'sample_throughput': 59.093, 'learn_time_ms': 18329.31, 'learn_throughput': 218.23}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 64880529375232.0, 'policy_loss': -0.003442202490987256, 'vf_loss': 64880529375232.0, 'vf_explained_var': 2.9802322e-08, 'kl': 0.01969935864326544, 'entropy': 0.6919007729738951, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2082240934707200.0, 'policy_loss': -0.0071138020139187574, 'vf_loss': 2082240934707200.0, 'vf_explained_var': -1.0058284e-07, 'kl': 0.012070842014509253, 'entropy': 1.493818860501051, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 324000, 'num_steps_trained': 324000}",False,131,81,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-24-02,1615742642,88.36011004447937,6882.139689207077,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6882.139689207077,0,81,"{'cpu_util_percent': 31.32983870967742, 'ram_util_percent': 52.724193548387085}"
161,80,MARL,light1,True,-1444233443.3195717,-13903271510.926207,-6120636170.533029,2429.03,2,-9139331491.923727,-1200429389.7581913,-5023791171.347187,{},"{'episode_reward': [-7846510150.3855095, -7394856433.587324, -12978244377.377497, -7329303989.71261, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227], 'episode_lengths': [2605, 2939, 2346, 2894, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999], 'policy_gneJ12_reward': [-942666099.8653208, -1004126422.7128243, -4475339082.098021, -1240725683.755743, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287], 'policy_light1_reward': [-6903844050.520193, -6390730010.874503, -8502905295.279441, -6088578305.956874, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898]}","{'mean_env_wait_ms': 11.955945470702098, 'mean_processing_ms': 3.0750538796034284, 'mean_inference_ms': 1.8109535993573578}",{},0,324000,"{'sample_time_ms': 67690.485, 'sample_throughput': 59.093, 'learn_time_ms': 18329.31, 'learn_throughput': 218.23}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 64880529375232.0, 'policy_loss': -0.003442202490987256, 'vf_loss': 64880529375232.0, 'vf_explained_var': 2.9802322e-08, 'kl': 0.01969935864326544, 'entropy': 0.6919007729738951, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2082240934707200.0, 'policy_loss': -0.0071138020139187574, 'vf_loss': 2082240934707200.0, 'vf_explained_var': -1.0058284e-07, 'kl': 0.012070842014509253, 'entropy': 1.493818860501051, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 324000, 'num_steps_trained': 324000}",False,131,81,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-24-02,1615742642,88.36011004447937,6882.139689207077,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6882.139689207077,0,81,"{'cpu_util_percent': 31.32983870967742, 'ram_util_percent': 52.724193548387085}"
162,81,MARL,gneJ12,False,-1444233443.3195717,-13903271510.926207,-6047825652.500857,2419.86,2,-6360153602.347856,-240361471.98858276,-1076297269.0984414,{},"{'episode_reward': [-6384312330.904245, -6642184232.968674, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324], 'episode_lengths': [2121, 2202, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939], 'policy_gneJ12_reward': [-904888550.263196, -2756403206.8506866, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243], 'policy_light1_reward': [-5479423780.6410475, -3885781026.117995, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503]}","{'mean_env_wait_ms': 11.950860865471235, 'mean_processing_ms': 3.079247119866613, 'mean_inference_ms': 1.8103822008313666}",{},0,328000,"{'sample_time_ms': 67649.447, 'sample_throughput': 59.128, 'learn_time_ms': 18367.136, 'learn_throughput': 217.78}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 599733567488000.0, 'policy_loss': -0.008212098444346339, 'vf_loss': 599733567488000.0, 'vf_explained_var': 3.7252903e-08, 'kl': 0.010889310462516733, 'entropy': 0.985108045861125, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2070644644642816.0, 'policy_loss': -0.00012903718743473291, 'vf_loss': 2070644644642816.0, 'vf_explained_var': -1.0058284e-07, 'kl': 0.007729871635092422, 'entropy': 1.671989381313324, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 328000, 'num_steps_trained': 328000}",False,133,82,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-25-31,1615742731,89.50473809242249,6971.6444272994995,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6971.6444272994995,0,82,"{'cpu_util_percent': 29.660317460317458, 'ram_util_percent': 52.63809523809526}"
163,81,MARL,light1,False,-1444233443.3195717,-13903271510.926207,-6047825652.500857,2419.86,2,-9139331491.923727,-1200429389.7581913,-4971528383.402414,{},"{'episode_reward': [-6384312330.904245, -6642184232.968674, -11080593425.566738, -8783369878.264051, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324], 'episode_lengths': [2121, 2202, 2876, 3105, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939], 'policy_gneJ12_reward': [-904888550.263196, -2756403206.8506866, -1941261933.6430032, -1472519265.5803735, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243], 'policy_light1_reward': [-5479423780.6410475, -3885781026.117995, -9139331491.923727, -7310850612.683665, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503]}","{'mean_env_wait_ms': 11.950860865471235, 'mean_processing_ms': 3.079247119866613, 'mean_inference_ms': 1.8103822008313666}",{},0,328000,"{'sample_time_ms': 67649.447, 'sample_throughput': 59.128, 'learn_time_ms': 18367.136, 'learn_throughput': 217.78}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 599733567488000.0, 'policy_loss': -0.008212098444346339, 'vf_loss': 599733567488000.0, 'vf_explained_var': 3.7252903e-08, 'kl': 0.010889310462516733, 'entropy': 0.985108045861125, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2070644644642816.0, 'policy_loss': -0.00012903718743473291, 'vf_loss': 2070644644642816.0, 'vf_explained_var': -1.0058284e-07, 'kl': 0.007729871635092422, 'entropy': 1.671989381313324, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 328000, 'num_steps_trained': 328000}",False,133,82,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-25-31,1615742731,89.50473809242249,6971.6444272994995,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",6971.6444272994995,0,82,"{'cpu_util_percent': 29.660317460317458, 'ram_util_percent': 52.63809523809526}"
164,82,MARL,gneJ12,False,-1444233443.3195717,-13903271510.926207,-5970487319.605838,2396.84,2,-6360153602.347856,-240361471.98858276,-1059164069.2755823,{},"{'episode_reward': [-7150941804.425393, -4979188209.903512, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674], 'episode_lengths': [2026, 1653, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202], 'policy_gneJ12_reward': [-962571938.1070608, -737889278.8303882, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866], 'policy_light1_reward': [-6188369866.3183155, -4241298931.073124, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995]}","{'mean_env_wait_ms': 11.946360413279209, 'mean_processing_ms': 3.0833319160466077, 'mean_inference_ms': 1.8098769106778034}",{},0,332000,"{'sample_time_ms': 68326.978, 'sample_throughput': 58.542, 'learn_time_ms': 18346.343, 'learn_throughput': 218.027}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 109161605234688.0, 'policy_loss': -0.004577826650347561, 'vf_loss': 109161605234688.0, 'vf_explained_var': 2.9802322e-08, 'kl': 0.022172501776367426, 'entropy': 0.8735138699412346, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 3260405455519744.0, 'policy_loss': -0.0006910323863849044, 'vf_loss': 3260405455519744.0, 'vf_explained_var': -1.1175871e-08, 'kl': 0.012555643006635364, 'entropy': 1.689472459256649, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 332000, 'num_steps_trained': 332000}",False,135,83,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-27-00,1615742820,88.33012509346008,7059.97455239296,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7059.97455239296,0,83,"{'cpu_util_percent': 29.048387096774196, 'ram_util_percent': 52.64274193548389}"
165,82,MARL,light1,False,-1444233443.3195717,-13903271510.926207,-5970487319.605838,2396.84,2,-8911700917.450415,-1200429389.7581913,-4911323250.330255,{},"{'episode_reward': [-7150941804.425393, -4979188209.903512, -10053264700.792597, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674], 'episode_lengths': [2026, 1653, 3020, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202], 'policy_gneJ12_reward': [-962571938.1070608, -737889278.8303882, -1647077757.5035317, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866], 'policy_light1_reward': [-6188369866.3183155, -4241298931.073124, -8406186943.289081, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995]}","{'mean_env_wait_ms': 11.946360413279209, 'mean_processing_ms': 3.0833319160466077, 'mean_inference_ms': 1.8098769106778034}",{},0,332000,"{'sample_time_ms': 68326.978, 'sample_throughput': 58.542, 'learn_time_ms': 18346.343, 'learn_throughput': 218.027}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 109161605234688.0, 'policy_loss': -0.004577826650347561, 'vf_loss': 109161605234688.0, 'vf_explained_var': 2.9802322e-08, 'kl': 0.022172501776367426, 'entropy': 0.8735138699412346, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 3260405455519744.0, 'policy_loss': -0.0006910323863849044, 'vf_loss': 3260405455519744.0, 'vf_explained_var': -1.1175871e-08, 'kl': 0.012555643006635364, 'entropy': 1.689472459256649, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 332000, 'num_steps_trained': 332000}",False,135,83,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-27-00,1615742820,88.33012509346008,7059.97455239296,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7059.97455239296,0,83,"{'cpu_util_percent': 29.048387096774196, 'ram_util_percent': 52.64274193548389}"
166,83,MARL,gneJ12,False,-1444233443.3195717,-13903271510.926207,-5933407235.3393135,2389.1,1,-6360153602.347856,-240361471.98858276,-1052794783.7044079,{},"{'episode_reward': [-6345256274.140091, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512], 'episode_lengths': [2246, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653], 'policy_gneJ12_reward': [-1010149200.3861468, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882], 'policy_light1_reward': [-5335107073.753951, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124]}","{'mean_env_wait_ms': 11.944268161631548, 'mean_processing_ms': 3.085605930612062, 'mean_inference_ms': 1.8096578963135357}",{},0,336000,"{'sample_time_ms': 67720.434, 'sample_throughput': 59.066, 'learn_time_ms': 18391.324, 'learn_throughput': 217.494}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 97506376286208.0, 'policy_loss': -0.007495318364817649, 'vf_loss': 97506376286208.0, 'vf_explained_var': -1.1175871e-07, 'kl': 0.012301269729505293, 'entropy': 0.7683975789695978, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2797299340148736.0, 'policy_loss': 0.0033068387710954994, 'vf_loss': 2797299340148736.0, 'vf_explained_var': 9.313226e-09, 'kl': 0.021522073744563386, 'entropy': 1.7892996296286583, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 336000, 'num_steps_trained': 336000}",False,136,84,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-28-25,1615742905,85.48520588874817,7145.459758281708,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7145.459758281708,0,84,"{'cpu_util_percent': 41.0775, 'ram_util_percent': 52.76083333333331}"
167,83,MARL,light1,False,-1444233443.3195717,-13903271510.926207,-5933407235.3393135,2389.1,1,-8911700917.450415,-1200429389.7581913,-4880612451.634902,{},"{'episode_reward': [-6345256274.140091, -10669336925.681664, -5268825658.253636, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512], 'episode_lengths': [2246, 2641, 1606, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653], 'policy_gneJ12_reward': [-1010149200.3861468, -1767461206.207429, -656957225.5945992, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882], 'policy_light1_reward': [-5335107073.753951, -8901875719.474207, -4611868432.659031, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124]}","{'mean_env_wait_ms': 11.944268161631548, 'mean_processing_ms': 3.085605930612062, 'mean_inference_ms': 1.8096578963135357}",{},0,336000,"{'sample_time_ms': 67720.434, 'sample_throughput': 59.066, 'learn_time_ms': 18391.324, 'learn_throughput': 217.494}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 97506376286208.0, 'policy_loss': -0.007495318364817649, 'vf_loss': 97506376286208.0, 'vf_explained_var': -1.1175871e-07, 'kl': 0.012301269729505293, 'entropy': 0.7683975789695978, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.0125000000000002, 'cur_lr': 0.001, 'total_loss': 2797299340148736.0, 'policy_loss': 0.0033068387710954994, 'vf_loss': 2797299340148736.0, 'vf_explained_var': 9.313226e-09, 'kl': 0.021522073744563386, 'entropy': 1.7892996296286583, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 336000, 'num_steps_trained': 336000}",False,136,84,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-28-25,1615742905,85.48520588874817,7145.459758281708,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7145.459758281708,0,84,"{'cpu_util_percent': 41.0775, 'ram_util_percent': 52.76083333333331}"
168,84,MARL,gneJ12,False,-1444233443.3195717,-13903271510.926207,-5900661836.69276,2398.86,2,-6360153602.347856,-240361471.98858276,-1046306466.5556259,{},"{'episode_reward': [-8747493966.019304, -3916128753.260735, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512, -6345256274.140091], 'episode_lengths': [2681, 2542, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653, 2246], 'policy_gneJ12_reward': [-1171682471.9054458, -603904245.0183595, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882, -1010149200.3861468], 'policy_light1_reward': [-7575811494.113875, -3312224508.2423725, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124, -5335107073.753951]}","{'mean_env_wait_ms': 11.940422642711804, 'mean_processing_ms': 3.089752302122584, 'mean_inference_ms': 1.8092788805272297}",{},0,340000,"{'sample_time_ms': 68885.343, 'sample_throughput': 58.068, 'learn_time_ms': 18369.074, 'learn_throughput': 217.757}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 31762872664064.0, 'policy_loss': -0.011068416381021962, 'vf_loss': 31762872664064.0, 'vf_explained_var': 2.9802322e-08, 'kl': 0.008634965197416022, 'entropy': 0.12053937427117489, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 941712459431936.0, 'policy_loss': -0.01056392610189505, 'vf_loss': 941712459431936.0, 'vf_explained_var': 1.4901161e-08, 'kl': 0.01997606412624009, 'entropy': 1.0548757929354906, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 340000, 'num_steps_trained': 340000}",False,138,85,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-29-57,1615742997,91.84691190719604,7237.306670188904,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7237.306670188904,0,85,"{'cpu_util_percent': 37.90859375, 'ram_util_percent': 52.769531250000014}"
169,84,MARL,light1,False,-1444233443.3195717,-13903271510.926207,-5900661836.69276,2398.86,2,-8911700917.450415,-1200429389.7581913,-4854355370.137134,{},"{'episode_reward': [-8747493966.019304, -3916128753.260735, -4213545219.615416, -7053246475.639692, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512, -6345256274.140091], 'episode_lengths': [2681, 2542, 2774, 2573, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653, 2246], 'policy_gneJ12_reward': [-1171682471.9054458, -603904245.0183595, -773582290.3348384, -1074052235.9507473, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882, -1010149200.3861468], 'policy_light1_reward': [-7575811494.113875, -3312224508.2423725, -3439962929.280575, -5979194239.688955, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124, -5335107073.753951]}","{'mean_env_wait_ms': 11.940422642711804, 'mean_processing_ms': 3.089752302122584, 'mean_inference_ms': 1.8092788805272297}",{},0,340000,"{'sample_time_ms': 68885.343, 'sample_throughput': 58.068, 'learn_time_ms': 18369.074, 'learn_throughput': 217.757}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 31762872664064.0, 'policy_loss': -0.011068416381021962, 'vf_loss': 31762872664064.0, 'vf_explained_var': 2.9802322e-08, 'kl': 0.008634965197416022, 'entropy': 0.12053937427117489, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 941712459431936.0, 'policy_loss': -0.01056392610189505, 'vf_loss': 941712459431936.0, 'vf_explained_var': 1.4901161e-08, 'kl': 0.01997606412624009, 'entropy': 1.0548757929354906, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 340000, 'num_steps_trained': 340000}",False,138,85,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-29-57,1615742997,91.84691190719604,7237.306670188904,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7237.306670188904,0,85,"{'cpu_util_percent': 37.90859375, 'ram_util_percent': 52.769531250000014}"
170,85,MARL,gneJ12,True,-1444233443.3195717,-13903271510.926207,-5887243178.098594,2388.31,2,-6360153602.347856,-240361471.98858276,-1042927095.2341014,{},"{'episode_reward': [-4363685544.600636, -5561240291.237711, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512, -6345256274.140091, -8747493966.019304, -3916128753.260735], 'episode_lengths': [2234, 2058, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653, 2246, 2681, 2542], 'policy_gneJ12_reward': [-578388864.9489703, -931308529.1841843, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882, -1010149200.3861468, -1171682471.9054458, -603904245.0183595], 'policy_light1_reward': [-3785296679.6516576, -4629931762.053526, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124, -5335107073.753951, -7575811494.113875, -3312224508.2423725]}","{'mean_env_wait_ms': 11.937149017821875, 'mean_processing_ms': 3.094555542188631, 'mean_inference_ms': 1.8089858571696487}",{},0,344000,"{'sample_time_ms': 69538.27, 'sample_throughput': 57.522, 'learn_time_ms': 18509.378, 'learn_throughput': 216.107}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 80671721652224.0, 'policy_loss': -0.0071180374070536345, 'vf_loss': 80671721652224.0, 'vf_explained_var': -9.313226e-08, 'kl': 0.010028052289271727, 'entropy': 0.6449339389801025, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 1988353515847680.0, 'policy_loss': 0.004351129668066278, 'vf_loss': 1988353515847680.0, 'vf_explained_var': -1.8626451e-08, 'kl': 0.019553479505702853, 'entropy': 1.5604380518198013, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 344000, 'num_steps_trained': 344000}",False,140,86,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-31-32,1615743092,95.1126720905304,7332.419342279434,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7332.419342279434,0,86,"{'cpu_util_percent': 36.35597014925372, 'ram_util_percent': 53.1820895522388}"
171,85,MARL,light1,True,-1444233443.3195717,-13903271510.926207,-5887243178.098594,2388.31,2,-8911700917.450415,-1200429389.7581913,-4844316082.86449,{},"{'episode_reward': [-4363685544.600636, -5561240291.237711, -8782702559.209944, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512, -6345256274.140091, -8747493966.019304, -3916128753.260735], 'episode_lengths': [2234, 2058, 2535, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653, 2246, 2681, 2542], 'policy_gneJ12_reward': [-578388864.9489703, -931308529.1841843, -1547415053.342992, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882, -1010149200.3861468, -1171682471.9054458, -603904245.0183595], 'policy_light1_reward': [-3785296679.6516576, -4629931762.053526, -7235287505.866957, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124, -5335107073.753951, -7575811494.113875, -3312224508.2423725]}","{'mean_env_wait_ms': 11.937149017821875, 'mean_processing_ms': 3.094555542188631, 'mean_inference_ms': 1.8089858571696487}",{},0,344000,"{'sample_time_ms': 69538.27, 'sample_throughput': 57.522, 'learn_time_ms': 18509.378, 'learn_throughput': 216.107}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 80671721652224.0, 'policy_loss': -0.0071180374070536345, 'vf_loss': 80671721652224.0, 'vf_explained_var': -9.313226e-08, 'kl': 0.010028052289271727, 'entropy': 0.6449339389801025, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 1988353515847680.0, 'policy_loss': 0.004351129668066278, 'vf_loss': 1988353515847680.0, 'vf_explained_var': -1.8626451e-08, 'kl': 0.019553479505702853, 'entropy': 1.5604380518198013, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 344000, 'num_steps_trained': 344000}",False,140,86,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-31-32,1615743092,95.1126720905304,7332.419342279434,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7332.419342279434,0,86,"{'cpu_util_percent': 36.35597014925372, 'ram_util_percent': 53.1820895522388}"
172,86,MARL,gneJ12,False,-1444233443.3195717,-13903271510.926207,-5878706995.673082,2392.38,1,-6360153602.347856,-240361471.98858276,-1037576144.9043621,{},"{'episode_reward': [-7929084316.6590395, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512, -6345256274.140091, -8747493966.019304, -3916128753.260735, -4363685544.600636, -5561240291.237711], 'episode_lengths': [2942, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653, 2246, 2681, 2542, 2234, 2058], 'policy_gneJ12_reward': [-1012320020.3690333, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882, -1010149200.3861468, -1171682471.9054458, -603904245.0183595, -578388864.9489703, -931308529.1841843], 'policy_light1_reward': [-6916764296.290024, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124, -5335107073.753951, -7575811494.113875, -3312224508.2423725, -3785296679.6516576, -4629931762.053526]}","{'mean_env_wait_ms': 11.935640790583527, 'mean_processing_ms': 3.0967007033420204, 'mean_inference_ms': 1.8088714920168127}",{},0,348000,"{'sample_time_ms': 69410.074, 'sample_throughput': 57.629, 'learn_time_ms': 18737.141, 'learn_throughput': 213.48}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 76090009714688.0, 'policy_loss': -0.005844599305419251, 'vf_loss': 76090009714688.0, 'vf_explained_var': 2.7939677e-08, 'kl': 0.018822140176780522, 'entropy': 0.7030096314847469, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 2370648236097536.0, 'policy_loss': -0.012160955579020083, 'vf_loss': 2370648236097536.0, 'vf_explained_var': 1.8626451e-09, 'kl': 0.006196391870616935, 'entropy': 1.8101901933550835, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 348000, 'num_steps_trained': 348000}",False,141,87,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-33-02,1615743182,89.80011081695557,7422.21945309639,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7422.21945309639,0,87,"{'cpu_util_percent': 43.46269841269841, 'ram_util_percent': 53.83253968253968}"
173,86,MARL,light1,False,-1444233443.3195717,-13903271510.926207,-5878706995.673082,2392.38,1,-8911700917.450415,-1200429389.7581913,-4841130850.76872,{},"{'episode_reward': [-7929084316.6590395, -5682742826.437693, -3479202234.4075365, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512, -6345256274.140091, -8747493966.019304, -3916128753.260735, -4363685544.600636, -5561240291.237711], 'episode_lengths': [2942, 1824, 2663, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653, 2246, 2681, 2542, 2234, 2058], 'policy_gneJ12_reward': [-1012320020.3690333, -876684152.1178232, -536401371.1142776, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882, -1010149200.3861468, -1171682471.9054458, -603904245.0183595, -578388864.9489703, -931308529.1841843], 'policy_light1_reward': [-6916764296.290024, -4806058674.319857, -2942800863.2932553, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124, -5335107073.753951, -7575811494.113875, -3312224508.2423725, -3785296679.6516576, -4629931762.053526]}","{'mean_env_wait_ms': 11.935640790583527, 'mean_processing_ms': 3.0967007033420204, 'mean_inference_ms': 1.8088714920168127}",{},0,348000,"{'sample_time_ms': 69410.074, 'sample_throughput': 57.629, 'learn_time_ms': 18737.141, 'learn_throughput': 213.48}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 76090009714688.0, 'policy_loss': -0.005844599305419251, 'vf_loss': 76090009714688.0, 'vf_explained_var': 2.7939677e-08, 'kl': 0.018822140176780522, 'entropy': 0.7030096314847469, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 2370648236097536.0, 'policy_loss': -0.012160955579020083, 'vf_loss': 2370648236097536.0, 'vf_explained_var': 1.8626451e-09, 'kl': 0.006196391870616935, 'entropy': 1.8101901933550835, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 348000, 'num_steps_trained': 348000}",False,141,87,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-33-02,1615743182,89.80011081695557,7422.21945309639,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7422.21945309639,0,87,"{'cpu_util_percent': 43.46269841269841, 'ram_util_percent': 53.83253968253968}"
174,87,MARL,gneJ12,False,-1444233443.3195717,-13903271510.926207,-5929223423.5058565,2400.76,2,-6360153602.347856,-240361471.98858276,-1046563392.2041793,{},"{'episode_reward': [-8780921090.918877, -5432666753.203772, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512, -6345256274.140091, -8747493966.019304, -3916128753.260735, -4363685544.600636, -5561240291.237711, -7929084316.6590395], 'episode_lengths': [3073, 2252, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653, 2246, 2681, 2542, 2234, 2058, 2942], 'policy_gneJ12_reward': [-1364339932.7225602, -947470320.4912701, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882, -1010149200.3861468, -1171682471.9054458, -603904245.0183595, -578388864.9489703, -931308529.1841843, -1012320020.3690333], 'policy_light1_reward': [-7416581158.196318, -4485196432.7125, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124, -5335107073.753951, -7575811494.113875, -3312224508.2423725, -3785296679.6516576, -4629931762.053526, -6916764296.290024]}","{'mean_env_wait_ms': 11.933720556723904, 'mean_processing_ms': 3.1004784554156686, 'mean_inference_ms': 1.808756318929646}",{},0,352000,"{'sample_time_ms': 70584.826, 'sample_throughput': 56.669, 'learn_time_ms': 18875.184, 'learn_throughput': 211.918}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 156855034970112.0, 'policy_loss': -0.00907425320474431, 'vf_loss': 156855034970112.0, 'vf_explained_var': 6.3329935e-08, 'kl': 0.005862275073013734, 'entropy': 0.8602175703272223, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 1937706925948928.0, 'policy_loss': -0.005106657452415675, 'vf_loss': 1937706925948928.0, 'vf_explained_var': -7.450581e-09, 'kl': 0.009088216669624671, 'entropy': 1.884275984019041, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 352000, 'num_steps_trained': 352000}",False,143,88,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-34-45,1615743285,102.50842308998108,7524.727876186371,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7524.727876186371,0,88,"{'cpu_util_percent': 47.68819444444445, 'ram_util_percent': 54.39791666666666}"
175,87,MARL,light1,False,-1444233443.3195717,-13903271510.926207,-5929223423.5058565,2400.76,2,-8911700917.450415,-1200429389.7581913,-4882660031.301678,{},"{'episode_reward': [-8780921090.918877, -5432666753.203772, -4178021435.672462, -5221321618.974252, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512, -6345256274.140091, -8747493966.019304, -3916128753.260735, -4363685544.600636, -5561240291.237711, -7929084316.6590395], 'episode_lengths': [3073, 2252, 2426, 1837, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653, 2246, 2681, 2542, 2234, 2058, 2942], 'policy_gneJ12_reward': [-1364339932.7225602, -947470320.4912701, -702225870.504788, -844368171.9841616, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882, -1010149200.3861468, -1171682471.9054458, -603904245.0183595, -578388864.9489703, -931308529.1841843, -1012320020.3690333], 'policy_light1_reward': [-7416581158.196318, -4485196432.7125, -3475795565.1676683, -4376953446.990093, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124, -5335107073.753951, -7575811494.113875, -3312224508.2423725, -3785296679.6516576, -4629931762.053526, -6916764296.290024]}","{'mean_env_wait_ms': 11.933720556723904, 'mean_processing_ms': 3.1004784554156686, 'mean_inference_ms': 1.808756318929646}",{},0,352000,"{'sample_time_ms': 70584.826, 'sample_throughput': 56.669, 'learn_time_ms': 18875.184, 'learn_throughput': 211.918}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 156855034970112.0, 'policy_loss': -0.00907425320474431, 'vf_loss': 156855034970112.0, 'vf_explained_var': 6.3329935e-08, 'kl': 0.005862275073013734, 'entropy': 0.8602175703272223, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 1937706925948928.0, 'policy_loss': -0.005106657452415675, 'vf_loss': 1937706925948928.0, 'vf_explained_var': -7.450581e-09, 'kl': 0.009088216669624671, 'entropy': 1.884275984019041, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 352000, 'num_steps_trained': 352000}",False,143,88,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-34-45,1615743285,102.50842308998108,7524.727876186371,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7524.727876186371,0,88,"{'cpu_util_percent': 47.68819444444445, 'ram_util_percent': 54.39791666666666}"
176,88,MARL,gneJ12,False,-1444233443.3195717,-13903271510.926207,-5975355053.464916,2406.25,2,-6360153602.347856,-240361471.98858276,-1074469843.5234444,{},"{'episode_reward': [-7713961206.733048, -6298544843.819634, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512, -6345256274.140091, -8747493966.019304, -3916128753.260735, -4363685544.600636, -5561240291.237711, -7929084316.6590395, -8780921090.918877, -5432666753.203772], 'episode_lengths': [2648, 2164, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653, 2246, 2681, 2542, 2234, 2058, 2942, 3073, 2252], 'policy_gneJ12_reward': [-3378062153.840285, -959177020.5751818, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882, -1010149200.3861468, -1171682471.9054458, -603904245.0183595, -578388864.9489703, -931308529.1841843, -1012320020.3690333, -1364339932.7225602, -947470320.4912701], 'policy_light1_reward': [-4335899052.892768, -5339367823.244458, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124, -5335107073.753951, -7575811494.113875, -3312224508.2423725, -3785296679.6516576, -4629931762.053526, -6916764296.290024, -7416581158.196318, -4485196432.7125]}","{'mean_env_wait_ms': 11.932536296093438, 'mean_processing_ms': 3.103872686866543, 'mean_inference_ms': 1.8087236660336325}",{},0,356000,"{'sample_time_ms': 72101.622, 'sample_throughput': 55.477, 'learn_time_ms': 19148.26, 'learn_throughput': 208.896}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 639168343441408.0, 'policy_loss': -0.005393002618802711, 'vf_loss': 639168343441408.0, 'vf_explained_var': 3.5390258e-08, 'kl': 0.004517423170909751, 'entropy': 0.9950313810259104, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 1727093436055552.0, 'policy_loss': -0.004391054972074926, 'vf_loss': 1727093436055552.0, 'vf_explained_var': 4.656613e-08, 'kl': 0.006440317032684106, 'entropy': 1.932508572936058, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 356000, 'num_steps_trained': 356000}",False,145,89,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-36-23,1615743383,98.769122838974,7623.496999025345,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7623.496999025345,0,89,"{'cpu_util_percent': 39.798550724637686, 'ram_util_percent': 54.59855072463768}"
177,88,MARL,light1,False,-1444233443.3195717,-13903271510.926207,-5975355053.464916,2406.25,2,-8911700917.450415,-1200429389.7581913,-4900885209.941472,{},"{'episode_reward': [-7713961206.733048, -6298544843.819634, -2823702951.3313484, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512, -6345256274.140091, -8747493966.019304, -3916128753.260735, -4363685544.600636, -5561240291.237711, -7929084316.6590395, -8780921090.918877, -5432666753.203772], 'episode_lengths': [2648, 2164, 1652, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653, 2246, 2681, 2542, 2234, 2058, 2942, 3073, 2252], 'policy_gneJ12_reward': [-3378062153.840285, -959177020.5751818, -345456002.53957677, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882, -1010149200.3861468, -1171682471.9054458, -603904245.0183595, -578388864.9489703, -931308529.1841843, -1012320020.3690333, -1364339932.7225602, -947470320.4912701], 'policy_light1_reward': [-4335899052.892768, -5339367823.244458, -2478246948.791769, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124, -5335107073.753951, -7575811494.113875, -3312224508.2423725, -3785296679.6516576, -4629931762.053526, -6916764296.290024, -7416581158.196318, -4485196432.7125]}","{'mean_env_wait_ms': 11.932536296093438, 'mean_processing_ms': 3.103872686866543, 'mean_inference_ms': 1.8087236660336325}",{},0,356000,"{'sample_time_ms': 72101.622, 'sample_throughput': 55.477, 'learn_time_ms': 19148.26, 'learn_throughput': 208.896}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.278125, 'cur_lr': 0.001, 'total_loss': 639168343441408.0, 'policy_loss': -0.005393002618802711, 'vf_loss': 639168343441408.0, 'vf_explained_var': 3.5390258e-08, 'kl': 0.004517423170909751, 'entropy': 0.9950313810259104, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 1727093436055552.0, 'policy_loss': -0.004391054972074926, 'vf_loss': 1727093436055552.0, 'vf_explained_var': 4.656613e-08, 'kl': 0.006440317032684106, 'entropy': 1.932508572936058, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 356000, 'num_steps_trained': 356000}",False,145,89,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-36-23,1615743383,98.769122838974,7623.496999025345,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7623.496999025345,0,89,"{'cpu_util_percent': 39.798550724637686, 'ram_util_percent': 54.59855072463768}"
178,89,MARL,gneJ12,False,-1444233443.3195717,-13903271510.926207,-5972157532.637827,2417.44,1,-6360153602.347856,-240361471.98858276,-1075143523.7062669,{},"{'episode_reward': [-2503950868.622543, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512, -6345256274.140091, -8747493966.019304, -3916128753.260735, -4363685544.600636, -5561240291.237711, -7929084316.6590395, -8780921090.918877, -5432666753.203772, -7713961206.733048, -6298544843.819634], 'episode_lengths': [2771, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653, 2246, 2681, 2542, 2234, 2058, 2942, 3073, 2252, 2648, 2164], 'policy_gneJ12_reward': [-412824020.82181233, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882, -1010149200.3861468, -1171682471.9054458, -603904245.0183595, -578388864.9489703, -931308529.1841843, -1012320020.3690333, -1364339932.7225602, -947470320.4912701, -3378062153.840285, -959177020.5751818], 'policy_light1_reward': [-2091126847.800735, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124, -5335107073.753951, -7575811494.113875, -3312224508.2423725, -3785296679.6516576, -4629931762.053526, -6916764296.290024, -7416581158.196318, -4485196432.7125, -4335899052.892768, -5339367823.244458]}","{'mean_env_wait_ms': 11.932223781529338, 'mean_processing_ms': 3.1052267876075006, 'mean_inference_ms': 1.808743842332425}",{},0,360000,"{'sample_time_ms': 72642.294, 'sample_throughput': 55.064, 'learn_time_ms': 19158.029, 'learn_throughput': 208.79}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 1054955083399168.0, 'policy_loss': -0.00786363278166391, 'vf_loss': 1054955083399168.0, 'vf_explained_var': 2.4214387e-08, 'kl': 0.008249889939179411, 'entropy': 0.382946704281494, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 725395085197312.0, 'policy_loss': -0.005937054374953732, 'vf_loss': 725395085197312.0, 'vf_explained_var': -5.2154064e-08, 'kl': 0.010423007370263804, 'entropy': 0.9053601119667292, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 360000, 'num_steps_trained': 360000}",False,146,90,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-37-52,1615743472,88.29384970664978,7711.790848731995,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7711.790848731995,0,90,"{'cpu_util_percent': 41.31854838709678, 'ram_util_percent': 54.616129032258094}"
179,89,MARL,light1,False,-1444233443.3195717,-13903271510.926207,-5972157532.637827,2417.44,1,-8911700917.450415,-1200429389.7581913,-4897014008.931561,{},"{'episode_reward': [-2503950868.622543, -2111585148.7219243, -5310184701.267029, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512, -6345256274.140091, -8747493966.019304, -3916128753.260735, -4363685544.600636, -5561240291.237711, -7929084316.6590395, -8780921090.918877, -5432666753.203772, -7713961206.733048, -6298544843.819634], 'episode_lengths': [2771, 1689, 1903, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653, 2246, 2681, 2542, 2234, 2058, 2942, 3073, 2252, 2648, 2164], 'policy_gneJ12_reward': [-412824020.82181233, -432505749.62653625, -717641329.397345, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882, -1010149200.3861468, -1171682471.9054458, -603904245.0183595, -578388864.9489703, -931308529.1841843, -1012320020.3690333, -1364339932.7225602, -947470320.4912701, -3378062153.840285, -959177020.5751818], 'policy_light1_reward': [-2091126847.800735, -1679079399.0953887, -4592543371.869682, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124, -5335107073.753951, -7575811494.113875, -3312224508.2423725, -3785296679.6516576, -4629931762.053526, -6916764296.290024, -7416581158.196318, -4485196432.7125, -4335899052.892768, -5339367823.244458]}","{'mean_env_wait_ms': 11.932223781529338, 'mean_processing_ms': 3.1052267876075006, 'mean_inference_ms': 1.808743842332425}",{},0,360000,"{'sample_time_ms': 72642.294, 'sample_throughput': 55.064, 'learn_time_ms': 19158.029, 'learn_throughput': 208.79}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 1054955083399168.0, 'policy_loss': -0.00786363278166391, 'vf_loss': 1054955083399168.0, 'vf_explained_var': 2.4214387e-08, 'kl': 0.008249889939179411, 'entropy': 0.382946704281494, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 725395085197312.0, 'policy_loss': -0.005937054374953732, 'vf_loss': 725395085197312.0, 'vf_explained_var': -5.2154064e-08, 'kl': 0.010423007370263804, 'entropy': 0.9053601119667292, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 360000, 'num_steps_trained': 360000}",False,146,90,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-37-52,1615743472,88.29384970664978,7711.790848731995,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7711.790848731995,0,90,"{'cpu_util_percent': 41.31854838709678, 'ram_util_percent': 54.616129032258094}"
180,90,MARL,gneJ12,True,-1444233443.3195717,-13903271510.926207,-6064740456.741677,2427.96,2,-6360153602.347856,-240361471.98858276,-1127554978.349788,{},"{'episode_reward': [-10189861588.434553, -6490200671.939265, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512, -6345256274.140091, -8747493966.019304, -3916128753.260735, -4363685544.600636, -5561240291.237711, -7929084316.6590395, -8780921090.918877, -5432666753.203772, -7713961206.733048, -6298544843.819634, -2503950868.622543], 'episode_lengths': [2590, 2054, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653, 2246, 2681, 2542, 2234, 2058, 2942, 3073, 2252, 2648, 2164, 2771], 'policy_gneJ12_reward': [-5298546351.528854, -1092746191.8471358, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882, -1010149200.3861468, -1171682471.9054458, -603904245.0183595, -578388864.9489703, -931308529.1841843, -1012320020.3690333, -1364339932.7225602, -947470320.4912701, -3378062153.840285, -959177020.5751818, -412824020.82181233], 'policy_light1_reward': [-4891315236.905735, -5397454480.092128, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124, -5335107073.753951, -7575811494.113875, -3312224508.2423725, -3785296679.6516576, -4629931762.053526, -6916764296.290024, -7416581158.196318, -4485196432.7125, -4335899052.892768, -5339367823.244458, -2091126847.800735]}","{'mean_env_wait_ms': 11.93195999018446, 'mean_processing_ms': 3.1078632175950234, 'mean_inference_ms': 1.8088442228233932}",{},0,364000,"{'sample_time_ms': 73359.99, 'sample_throughput': 54.526, 'learn_time_ms': 19179.836, 'learn_throughput': 208.552}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 776675585425408.0, 'policy_loss': -0.0004377987643238157, 'vf_loss': 776675585425408.0, 'vf_explained_var': 1.4901161e-08, 'kl': 0.01057718149968423, 'entropy': 0.9812980275601149, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 2047340881903616.0, 'policy_loss': -0.0037224278785288334, 'vf_loss': 2047340881903616.0, 'vf_explained_var': 0.0, 'kl': 0.006607225681364071, 'entropy': 1.7267352417111397, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 364000, 'num_steps_trained': 364000}",False,148,91,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-39-28,1615743568,95.75539994239807,7807.546248674393,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7807.546248674393,0,91,"{'cpu_util_percent': 37.480740740740735, 'ram_util_percent': 54.6674074074074}"
181,90,MARL,light1,True,-1444233443.3195717,-13903271510.926207,-6064740456.741677,2427.96,2,-8911700917.450415,-1200429389.7581913,-4937185478.39189,{},"{'episode_reward': [-10189861588.434553, -6490200671.939265, -5663051425.912619, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512, -6345256274.140091, -8747493966.019304, -3916128753.260735, -4363685544.600636, -5561240291.237711, -7929084316.6590395, -8780921090.918877, -5432666753.203772, -7713961206.733048, -6298544843.819634, -2503950868.622543], 'episode_lengths': [2590, 2054, 1727, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653, 2246, 2681, 2542, 2234, 2058, 2942, 3073, 2252, 2648, 2164, 2771], 'policy_gneJ12_reward': [-5298546351.528854, -1092746191.8471358, -1117330705.3847182, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882, -1010149200.3861468, -1171682471.9054458, -603904245.0183595, -578388864.9489703, -931308529.1841843, -1012320020.3690333, -1364339932.7225602, -947470320.4912701, -3378062153.840285, -959177020.5751818, -412824020.82181233], 'policy_light1_reward': [-4891315236.905735, -5397454480.092128, -4545720720.527898, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124, -5335107073.753951, -7575811494.113875, -3312224508.2423725, -3785296679.6516576, -4629931762.053526, -6916764296.290024, -7416581158.196318, -4485196432.7125, -4335899052.892768, -5339367823.244458, -2091126847.800735]}","{'mean_env_wait_ms': 11.93195999018446, 'mean_processing_ms': 3.1078632175950234, 'mean_inference_ms': 1.8088442228233932}",{},0,364000,"{'sample_time_ms': 73359.99, 'sample_throughput': 54.526, 'learn_time_ms': 19179.836, 'learn_throughput': 208.552}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 776675585425408.0, 'policy_loss': -0.0004377987643238157, 'vf_loss': 776675585425408.0, 'vf_explained_var': 1.4901161e-08, 'kl': 0.01057718149968423, 'entropy': 0.9812980275601149, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 2047340881903616.0, 'policy_loss': -0.0037224278785288334, 'vf_loss': 2047340881903616.0, 'vf_explained_var': 0.0, 'kl': 0.006607225681364071, 'entropy': 1.7267352417111397, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 364000, 'num_steps_trained': 364000}",False,148,91,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-39-28,1615743568,95.75539994239807,7807.546248674393,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7807.546248674393,0,91,"{'cpu_util_percent': 37.480740740740735, 'ram_util_percent': 54.6674074074074}"
182,91,MARL,gneJ12,False,-1444233443.3195717,-13903271510.926207,-6048943751.440652,2432.18,1,-6360153602.347856,-240361471.98858276,-1123919568.8139558,{},"{'episode_reward': [-4083380895.8101482, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512, -6345256274.140091, -8747493966.019304, -3916128753.260735, -4363685544.600636, -5561240291.237711, -7929084316.6590395, -8780921090.918877, -5432666753.203772, -7713961206.733048, -6298544843.819634, -2503950868.622543, -10189861588.434553, -6490200671.939265], 'episode_lengths': [2149, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653, 2246, 2681, 2542, 2234, 2058, 2942, 3073, 2252, 2648, 2164, 2771, 2590, 2054], 'policy_gneJ12_reward': [-753789751.801514, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882, -1010149200.3861468, -1171682471.9054458, -603904245.0183595, -578388864.9489703, -931308529.1841843, -1012320020.3690333, -1364339932.7225602, -947470320.4912701, -3378062153.840285, -959177020.5751818, -412824020.82181233, -5298546351.528854, -1092746191.8471358], 'policy_light1_reward': [-3329591144.0086308, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124, -5335107073.753951, -7575811494.113875, -3312224508.2423725, -3785296679.6516576, -4629931762.053526, -6916764296.290024, -7416581158.196318, -4485196432.7125, -4335899052.892768, -5339367823.244458, -2091126847.800735, -4891315236.905735, -5397454480.092128]}","{'mean_env_wait_ms': 11.93179211198557, 'mean_processing_ms': 3.1089393067069464, 'mean_inference_ms': 1.8088910844843025}",{},0,368000,"{'sample_time_ms': 72326.628, 'sample_throughput': 55.305, 'learn_time_ms': 19070.176, 'learn_throughput': 209.752}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 32954318061568.0, 'policy_loss': 0.01682584229274653, 'vf_loss': 32954318061568.0, 'vf_explained_var': -4.4703484e-08, 'kl': 0.05676382966339588, 'entropy': -0.16984949487959966, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 551530362044416.0, 'policy_loss': -0.0051165472832508385, 'vf_loss': 551530362044416.0, 'vf_explained_var': -5.2154064e-08, 'kl': 0.017439747811295092, 'entropy': 0.5352818388491869, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 368000, 'num_steps_trained': 368000}",False,149,92,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-40-46,1615743646,78.0752420425415,7885.621490716934,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7885.621490716934,0,92,"{'cpu_util_percent': 30.335454545454546, 'ram_util_percent': 54.625454545454545}"
183,91,MARL,light1,False,-1444233443.3195717,-13903271510.926207,-6048943751.440652,2432.18,1,-8911700917.450415,-1200429389.7581913,-4925024182.626697,{},"{'episode_reward': [-4083380895.8101482, -5913834772.612201, -4346340302.141951, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512, -6345256274.140091, -8747493966.019304, -3916128753.260735, -4363685544.600636, -5561240291.237711, -7929084316.6590395, -8780921090.918877, -5432666753.203772, -7713961206.733048, -6298544843.819634, -2503950868.622543, -10189861588.434553, -6490200671.939265], 'episode_lengths': [2149, 2493, 2556, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653, 2246, 2681, 2542, 2234, 2058, 2942, 3073, 2252, 2648, 2164, 2771, 2590, 2054], 'policy_gneJ12_reward': [-753789751.801514, -871464333.6156688, -666463901.1322331, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882, -1010149200.3861468, -1171682471.9054458, -603904245.0183595, -578388864.9489703, -931308529.1841843, -1012320020.3690333, -1364339932.7225602, -947470320.4912701, -3378062153.840285, -959177020.5751818, -412824020.82181233, -5298546351.528854, -1092746191.8471358], 'policy_light1_reward': [-3329591144.0086308, -5042370438.996545, -3679876401.009723, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124, -5335107073.753951, -7575811494.113875, -3312224508.2423725, -3785296679.6516576, -4629931762.053526, -6916764296.290024, -7416581158.196318, -4485196432.7125, -4335899052.892768, -5339367823.244458, -2091126847.800735, -4891315236.905735, -5397454480.092128]}","{'mean_env_wait_ms': 11.93179211198557, 'mean_processing_ms': 3.1089393067069464, 'mean_inference_ms': 1.8088910844843025}",{},0,368000,"{'sample_time_ms': 72326.628, 'sample_throughput': 55.305, 'learn_time_ms': 19070.176, 'learn_throughput': 209.752}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.1390625, 'cur_lr': 0.001, 'total_loss': 32954318061568.0, 'policy_loss': 0.01682584229274653, 'vf_loss': 32954318061568.0, 'vf_explained_var': -4.4703484e-08, 'kl': 0.05676382966339588, 'entropy': -0.16984949487959966, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 551530362044416.0, 'policy_loss': -0.0051165472832508385, 'vf_loss': 551530362044416.0, 'vf_explained_var': -5.2154064e-08, 'kl': 0.017439747811295092, 'entropy': 0.5352818388491869, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 368000, 'num_steps_trained': 368000}",False,149,92,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-40-46,1615743646,78.0752420425415,7885.621490716934,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7885.621490716934,0,92,"{'cpu_util_percent': 30.335454545454546, 'ram_util_percent': 54.625454545454545}"
184,92,MARL,gneJ12,False,-1444233443.3195717,-13903271510.926207,-6047647690.3041525,2439.7,2,-6360153602.347856,-240361471.98858276,-1125276736.9931257,{},"{'episode_reward': [-1771043758.3131554, -8359525202.790905, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512, -6345256274.140091, -8747493966.019304, -3916128753.260735, -4363685544.600636, -5561240291.237711, -7929084316.6590395, -8780921090.918877, -5432666753.203772, -7713961206.733048, -6298544843.819634, -2503950868.622543, -10189861588.434553, -6490200671.939265, -4083380895.8101482], 'episode_lengths': [2797, 3004, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653, 2246, 2681, 2542, 2234, 2058, 2942, 3073, 2252, 2648, 2164, 2771, 2590, 2054, 2149], 'policy_gneJ12_reward': [-354876341.92401654, -1318768710.7408783, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882, -1010149200.3861468, -1171682471.9054458, -603904245.0183595, -578388864.9489703, -931308529.1841843, -1012320020.3690333, -1364339932.7225602, -947470320.4912701, -3378062153.840285, -959177020.5751818, -412824020.82181233, -5298546351.528854, -1092746191.8471358, -753789751.801514], 'policy_light1_reward': [-1416167416.3891382, -7040756492.050025, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124, -5335107073.753951, -7575811494.113875, -3312224508.2423725, -3785296679.6516576, -4629931762.053526, -6916764296.290024, -7416581158.196318, -4485196432.7125, -4335899052.892768, -5339367823.244458, -2091126847.800735, -4891315236.905735, -5397454480.092128, -3329591144.0086308]}","{'mean_env_wait_ms': 11.932158752404229, 'mean_processing_ms': 3.110849689263006, 'mean_inference_ms': 1.809075726565913}",{},0,372000,"{'sample_time_ms': 73313.321, 'sample_throughput': 54.56, 'learn_time_ms': 19074.475, 'learn_throughput': 209.704}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.7085937500000001, 'cur_lr': 0.001, 'total_loss': 80822941646848.0, 'policy_loss': -0.014447857276536524, 'vf_loss': 80822941646848.0, 'vf_explained_var': -7.0780516e-08, 'kl': 0.007375183253316209, 'entropy': 0.7952448055148125, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 2193989981700096.0, 'policy_loss': 0.002042625186732039, 'vf_loss': 2193989981700096.0, 'vf_explained_var': 6.3329935e-08, 'kl': 0.012489146058214828, 'entropy': 1.716987743973732, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 372000, 'num_steps_trained': 372000}",False,151,93,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-42-24,1615743744,98.2399070262909,7983.861397743225,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7983.861397743225,0,93,"{'cpu_util_percent': 46.082481751824815, 'ram_util_percent': 54.94525547445255}"
185,92,MARL,light1,False,-1444233443.3195717,-13903271510.926207,-6047647690.3041525,2439.7,2,-8911700917.450415,-1200429389.7581913,-4922370953.311026,{},"{'episode_reward': [-1771043758.3131554, -8359525202.790905, -9934857857.50397, -10359173322.694244, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512, -6345256274.140091, -8747493966.019304, -3916128753.260735, -4363685544.600636, -5561240291.237711, -7929084316.6590395, -8780921090.918877, -5432666753.203772, -7713961206.733048, -6298544843.819634, -2503950868.622543, -10189861588.434553, -6490200671.939265, -4083380895.8101482], 'episode_lengths': [2797, 3004, 2635, 2686, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653, 2246, 2681, 2542, 2234, 2058, 2942, 3073, 2252, 2648, 2164, 2771, 2590, 2054, 2149], 'policy_gneJ12_reward': [-354876341.92401654, -1318768710.7408783, -1878983930.9776862, -2028256000.611692, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882, -1010149200.3861468, -1171682471.9054458, -603904245.0183595, -578388864.9489703, -931308529.1841843, -1012320020.3690333, -1364339932.7225602, -947470320.4912701, -3378062153.840285, -959177020.5751818, -412824020.82181233, -5298546351.528854, -1092746191.8471358, -753789751.801514], 'policy_light1_reward': [-1416167416.3891382, -7040756492.050025, -8055873926.52628, -8330917322.082564, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124, -5335107073.753951, -7575811494.113875, -3312224508.2423725, -3785296679.6516576, -4629931762.053526, -6916764296.290024, -7416581158.196318, -4485196432.7125, -4335899052.892768, -5339367823.244458, -2091126847.800735, -4891315236.905735, -5397454480.092128, -3329591144.0086308]}","{'mean_env_wait_ms': 11.932158752404229, 'mean_processing_ms': 3.110849689263006, 'mean_inference_ms': 1.809075726565913}",{},0,372000,"{'sample_time_ms': 73313.321, 'sample_throughput': 54.56, 'learn_time_ms': 19074.475, 'learn_throughput': 209.704}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.7085937500000001, 'cur_lr': 0.001, 'total_loss': 80822941646848.0, 'policy_loss': -0.014447857276536524, 'vf_loss': 80822941646848.0, 'vf_explained_var': -7.0780516e-08, 'kl': 0.007375183253316209, 'entropy': 0.7952448055148125, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 2193989981700096.0, 'policy_loss': 0.002042625186732039, 'vf_loss': 2193989981700096.0, 'vf_explained_var': 6.3329935e-08, 'kl': 0.012489146058214828, 'entropy': 1.716987743973732, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 372000, 'num_steps_trained': 372000}",False,151,93,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-42-24,1615743744,98.2399070262909,7983.861397743225,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",7983.861397743225,0,93,"{'cpu_util_percent': 46.082481751824815, 'ram_util_percent': 54.94525547445255}"
186,93,MARL,gneJ12,False,-1444233443.3195717,-13903271510.926207,-5954040923.310408,2427.45,2,-6360153602.347856,-240361471.98858276,-1105334385.3938718,{},"{'episode_reward': [-6632473076.682601, -4300881404.141275, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512, -6345256274.140091, -8747493966.019304, -3916128753.260735, -4363685544.600636, -5561240291.237711, -7929084316.6590395, -8780921090.918877, -5432666753.203772, -7713961206.733048, -6298544843.819634, -2503950868.622543, -10189861588.434553, -6490200671.939265, -4083380895.8101482, -1771043758.3131554, -8359525202.790905], 'episode_lengths': [2083, 2013, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653, 2246, 2681, 2542, 2234, 2058, 2942, 3073, 2252, 2648, 2164, 2771, 2590, 2054, 2149, 2797, 3004], 'policy_gneJ12_reward': [-1129770077.09919, -783234694.5647941, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882, -1010149200.3861468, -1171682471.9054458, -603904245.0183595, -578388864.9489703, -931308529.1841843, -1012320020.3690333, -1364339932.7225602, -947470320.4912701, -3378062153.840285, -959177020.5751818, -412824020.82181233, -5298546351.528854, -1092746191.8471358, -753789751.801514, -354876341.92401654, -1318768710.7408783], 'policy_light1_reward': [-5502702999.583421, -3517646709.5764804, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124, -5335107073.753951, -7575811494.113875, -3312224508.2423725, -3785296679.6516576, -4629931762.053526, -6916764296.290024, -7416581158.196318, -4485196432.7125, -4335899052.892768, -5339367823.244458, -2091126847.800735, -4891315236.905735, -5397454480.092128, -3329591144.0086308, -1416167416.3891382, -7040756492.050025]}","{'mean_env_wait_ms': 11.932550720700817, 'mean_processing_ms': 3.1134354733609615, 'mean_inference_ms': 1.8092824388410915}",{},0,376000,"{'sample_time_ms': 73713.392, 'sample_throughput': 54.264, 'learn_time_ms': 19009.188, 'learn_throughput': 210.425}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.7085937500000001, 'cur_lr': 0.001, 'total_loss': 160157309337600.0, 'policy_loss': -0.008843143878038973, 'vf_loss': 160157309337600.0, 'vf_explained_var': 1.6763806e-08, 'kl': 0.010649486706824973, 'entropy': 0.965704994276166, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 2018914800238592.0, 'policy_loss': -0.012374055513646454, 'vf_loss': 2018914800238592.0, 'vf_explained_var': 5.2154064e-08, 'kl': 0.007994244144356344, 'entropy': 1.6779111251235008, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 376000, 'num_steps_trained': 376000}",False,153,94,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-43-53,1615743833,88.82933211326599,8072.690729856491,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8072.690729856491,0,94,"{'cpu_util_percent': 29.8768, 'ram_util_percent': 55.059999999999995}"
187,93,MARL,light1,False,-1444233443.3195717,-13903271510.926207,-5954040923.310408,2427.45,2,-8911700917.450415,-1200429389.7581913,-4848706537.916537,{},"{'episode_reward': [-6632473076.682601, -4300881404.141275, -3170491870.107619, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512, -6345256274.140091, -8747493966.019304, -3916128753.260735, -4363685544.600636, -5561240291.237711, -7929084316.6590395, -8780921090.918877, -5432666753.203772, -7713961206.733048, -6298544843.819634, -2503950868.622543, -10189861588.434553, -6490200671.939265, -4083380895.8101482, -1771043758.3131554, -8359525202.790905], 'episode_lengths': [2083, 2013, 1705, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653, 2246, 2681, 2542, 2234, 2058, 2942, 3073, 2252, 2648, 2164, 2771, 2590, 2054, 2149, 2797, 3004], 'policy_gneJ12_reward': [-1129770077.09919, -783234694.5647941, -484973537.2413313, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882, -1010149200.3861468, -1171682471.9054458, -603904245.0183595, -578388864.9489703, -931308529.1841843, -1012320020.3690333, -1364339932.7225602, -947470320.4912701, -3378062153.840285, -959177020.5751818, -412824020.82181233, -5298546351.528854, -1092746191.8471358, -753789751.801514, -354876341.92401654, -1318768710.7408783], 'policy_light1_reward': [-5502702999.583421, -3517646709.5764804, -2685518332.8662896, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124, -5335107073.753951, -7575811494.113875, -3312224508.2423725, -3785296679.6516576, -4629931762.053526, -6916764296.290024, -7416581158.196318, -4485196432.7125, -4335899052.892768, -5339367823.244458, -2091126847.800735, -4891315236.905735, -5397454480.092128, -3329591144.0086308, -1416167416.3891382, -7040756492.050025]}","{'mean_env_wait_ms': 11.932550720700817, 'mean_processing_ms': 3.1134354733609615, 'mean_inference_ms': 1.8092824388410915}",{},0,376000,"{'sample_time_ms': 73713.392, 'sample_throughput': 54.264, 'learn_time_ms': 19009.188, 'learn_throughput': 210.425}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.7085937500000001, 'cur_lr': 0.001, 'total_loss': 160157309337600.0, 'policy_loss': -0.008843143878038973, 'vf_loss': 160157309337600.0, 'vf_explained_var': 1.6763806e-08, 'kl': 0.010649486706824973, 'entropy': 0.965704994276166, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 2018914800238592.0, 'policy_loss': -0.012374055513646454, 'vf_loss': 2018914800238592.0, 'vf_explained_var': 5.2154064e-08, 'kl': 0.007994244144356344, 'entropy': 1.6779111251235008, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 376000, 'num_steps_trained': 376000}",False,153,94,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-43-53,1615743833,88.82933211326599,8072.690729856491,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8072.690729856491,0,94,"{'cpu_util_percent': 29.8768, 'ram_util_percent': 55.059999999999995}"
188,94,MARL,gneJ12,False,-1444233443.3195717,-13903271510.926207,-6011963601.471698,2438.65,1,-6360153602.347856,-240361471.98858276,-1115919464.2283409,{},"{'episode_reward': [-8962759686.236603, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512, -6345256274.140091, -8747493966.019304, -3916128753.260735, -4363685544.600636, -5561240291.237711, -7929084316.6590395, -8780921090.918877, -5432666753.203772, -7713961206.733048, -6298544843.819634, -2503950868.622543, -10189861588.434553, -6490200671.939265, -4083380895.8101482, -1771043758.3131554, -8359525202.790905, -6632473076.682601, -4300881404.141275], 'episode_lengths': [2825, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653, 2246, 2681, 2542, 2234, 2058, 2942, 3073, 2252, 2648, 2164, 2771, 2590, 2054, 2149, 2797, 3004, 2083, 2013], 'policy_gneJ12_reward': [-1543481420.688249, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882, -1010149200.3861468, -1171682471.9054458, -603904245.0183595, -578388864.9489703, -931308529.1841843, -1012320020.3690333, -1364339932.7225602, -947470320.4912701, -3378062153.840285, -959177020.5751818, -412824020.82181233, -5298546351.528854, -1092746191.8471358, -753789751.801514, -354876341.92401654, -1318768710.7408783, -1129770077.09919, -783234694.5647941], 'policy_light1_reward': [-7419278265.54835, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124, -5335107073.753951, -7575811494.113875, -3312224508.2423725, -3785296679.6516576, -4629931762.053526, -6916764296.290024, -7416581158.196318, -4485196432.7125, -4335899052.892768, -5339367823.244458, -2091126847.800735, -4891315236.905735, -5397454480.092128, -3329591144.0086308, -1416167416.3891382, -7040756492.050025, -5502702999.583421, -3517646709.5764804]}","{'mean_env_wait_ms': 11.932837987430144, 'mean_processing_ms': 3.1145193839684184, 'mean_inference_ms': 1.8093945417640418}",{},0,380000,"{'sample_time_ms': 72794.16, 'sample_throughput': 54.949, 'learn_time_ms': 19054.359, 'learn_throughput': 209.926}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.7085937500000001, 'cur_lr': 0.001, 'total_loss': 108209998135296.0, 'policy_loss': -0.00974710495211184, 'vf_loss': 108209998135296.0, 'vf_explained_var': 1.3038516e-08, 'kl': 0.005883671925403178, 'entropy': 1.0027453787624836, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 2280306602147840.0, 'policy_loss': 0.0038704991748090833, 'vf_loss': 2280306602147840.0, 'vf_explained_var': 5.5879354e-08, 'kl': 0.009276764154492412, 'entropy': 1.8852528892457485, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 380000, 'num_steps_trained': 380000}",False,154,95,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-45-16,1615743916,83.10563611984253,8155.796365976334,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8155.796365976334,0,95,"{'cpu_util_percent': 33.332478632478626, 'ram_util_percent': 55.74273504273504}"
189,94,MARL,light1,False,-1444233443.3195717,-13903271510.926207,-6011963601.471698,2438.65,1,-8911700917.450415,-1200429389.7581913,-4896044137.243359,{},"{'episode_reward': [-8962759686.236603, -6120881779.208017, -2884065040.9479156, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512, -6345256274.140091, -8747493966.019304, -3916128753.260735, -4363685544.600636, -5561240291.237711, -7929084316.6590395, -8780921090.918877, -5432666753.203772, -7713961206.733048, -6298544843.819634, -2503950868.622543, -10189861588.434553, -6490200671.939265, -4083380895.8101482, -1771043758.3131554, -8359525202.790905, -6632473076.682601, -4300881404.141275], 'episode_lengths': [2825, 2699, 2040, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653, 2246, 2681, 2542, 2234, 2058, 2942, 3073, 2252, 2648, 2164, 2771, 2590, 2054, 2149, 2797, 3004, 2083, 2013], 'policy_gneJ12_reward': [-1543481420.688249, -827954789.3643361, -491230848.9122557, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882, -1010149200.3861468, -1171682471.9054458, -603904245.0183595, -578388864.9489703, -931308529.1841843, -1012320020.3690333, -1364339932.7225602, -947470320.4912701, -3378062153.840285, -959177020.5751818, -412824020.82181233, -5298546351.528854, -1092746191.8471358, -753789751.801514, -354876341.92401654, -1318768710.7408783, -1129770077.09919, -783234694.5647941], 'policy_light1_reward': [-7419278265.54835, -5292926989.84368, -2392834192.0356603, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124, -5335107073.753951, -7575811494.113875, -3312224508.2423725, -3785296679.6516576, -4629931762.053526, -6916764296.290024, -7416581158.196318, -4485196432.7125, -4335899052.892768, -5339367823.244458, -2091126847.800735, -4891315236.905735, -5397454480.092128, -3329591144.0086308, -1416167416.3891382, -7040756492.050025, -5502702999.583421, -3517646709.5764804]}","{'mean_env_wait_ms': 11.932837987430144, 'mean_processing_ms': 3.1145193839684184, 'mean_inference_ms': 1.8093945417640418}",{},0,380000,"{'sample_time_ms': 72794.16, 'sample_throughput': 54.949, 'learn_time_ms': 19054.359, 'learn_throughput': 209.926}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.7085937500000001, 'cur_lr': 0.001, 'total_loss': 108209998135296.0, 'policy_loss': -0.00974710495211184, 'vf_loss': 108209998135296.0, 'vf_explained_var': 1.3038516e-08, 'kl': 0.005883671925403178, 'entropy': 1.0027453787624836, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 2280306602147840.0, 'policy_loss': 0.0038704991748090833, 'vf_loss': 2280306602147840.0, 'vf_explained_var': 5.5879354e-08, 'kl': 0.009276764154492412, 'entropy': 1.8852528892457485, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 380000, 'num_steps_trained': 380000}",False,154,95,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-45-16,1615743916,83.10563611984253,8155.796365976334,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8155.796365976334,0,95,"{'cpu_util_percent': 33.332478632478626, 'ram_util_percent': 55.74273504273504}"
190,95,MARL,gneJ12,True,-1444233443.3195717,-13903271510.926207,-6047677767.588301,2439.52,2,-6360153602.347856,-240361471.98858276,-1122157739.130442,{},"{'episode_reward': [-7216269425.057859, -5360094006.758274, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512, -6345256274.140091, -8747493966.019304, -3916128753.260735, -4363685544.600636, -5561240291.237711, -7929084316.6590395, -8780921090.918877, -5432666753.203772, -7713961206.733048, -6298544843.819634, -2503950868.622543, -10189861588.434553, -6490200671.939265, -4083380895.8101482, -1771043758.3131554, -8359525202.790905, -6632473076.682601, -4300881404.141275, -8962759686.236603], 'episode_lengths': [2877, 1949, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653, 2246, 2681, 2542, 2234, 2058, 2942, 3073, 2252, 2648, 2164, 2771, 2590, 2054, 2149, 2797, 3004, 2083, 2013, 2825], 'policy_gneJ12_reward': [-1146086421.3892217, -796926707.097473, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882, -1010149200.3861468, -1171682471.9054458, -603904245.0183595, -578388864.9489703, -931308529.1841843, -1012320020.3690333, -1364339932.7225602, -947470320.4912701, -3378062153.840285, -959177020.5751818, -412824020.82181233, -5298546351.528854, -1092746191.8471358, -753789751.801514, -354876341.92401654, -1318768710.7408783, -1129770077.09919, -783234694.5647941, -1543481420.688249], 'policy_light1_reward': [-6070183003.668629, -4563167299.660805, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124, -5335107073.753951, -7575811494.113875, -3312224508.2423725, -3785296679.6516576, -4629931762.053526, -6916764296.290024, -7416581158.196318, -4485196432.7125, -4335899052.892768, -5339367823.244458, -2091126847.800735, -4891315236.905735, -5397454480.092128, -3329591144.0086308, -1416167416.3891382, -7040756492.050025, -5502702999.583421, -3517646709.5764804, -7419278265.54835]}","{'mean_env_wait_ms': 11.933587001200873, 'mean_processing_ms': 3.116449446118305, 'mean_inference_ms': 1.8096280879262452}",{},0,384000,"{'sample_time_ms': 72248.458, 'sample_throughput': 55.365, 'learn_time_ms': 19109.674, 'learn_throughput': 209.318}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.7085937500000001, 'cur_lr': 0.001, 'total_loss': 79889850171392.0, 'policy_loss': -0.00685376807814464, 'vf_loss': 79889850171392.0, 'vf_explained_var': -5.9604645e-08, 'kl': 0.013780090230284259, 'entropy': 0.606956921517849, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 1731750019465216.0, 'policy_loss': -0.008469078515190631, 'vf_loss': 1731750019465216.0, 'vf_explained_var': -4.0978193e-08, 'kl': 0.010395899938885123, 'entropy': 1.6654083989560604, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 384000, 'num_steps_trained': 384000}",False,156,96,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-46-46,1615744006,90.20906615257263,8246.005432128906,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8246.005432128906,0,96,"{'cpu_util_percent': 34.763779527559066, 'ram_util_percent': 56.214173228346446}"
191,95,MARL,light1,True,-1444233443.3195717,-13903271510.926207,-6047677767.588301,2439.52,2,-8911700917.450415,-1200429389.7581913,-4925520028.457858,{},"{'episode_reward': [-7216269425.057859, -5360094006.758274, -7903047521.345258, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512, -6345256274.140091, -8747493966.019304, -3916128753.260735, -4363685544.600636, -5561240291.237711, -7929084316.6590395, -8780921090.918877, -5432666753.203772, -7713961206.733048, -6298544843.819634, -2503950868.622543, -10189861588.434553, -6490200671.939265, -4083380895.8101482, -1771043758.3131554, -8359525202.790905, -6632473076.682601, -4300881404.141275, -8962759686.236603], 'episode_lengths': [2877, 1949, 2453, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653, 2246, 2681, 2542, 2234, 2058, 2942, 3073, 2252, 2648, 2164, 2771, 2590, 2054, 2149, 2797, 3004, 2083, 2013, 2825], 'policy_gneJ12_reward': [-1146086421.3892217, -796926707.097473, -1719044786.856025, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882, -1010149200.3861468, -1171682471.9054458, -603904245.0183595, -578388864.9489703, -931308529.1841843, -1012320020.3690333, -1364339932.7225602, -947470320.4912701, -3378062153.840285, -959177020.5751818, -412824020.82181233, -5298546351.528854, -1092746191.8471358, -753789751.801514, -354876341.92401654, -1318768710.7408783, -1129770077.09919, -783234694.5647941, -1543481420.688249], 'policy_light1_reward': [-6070183003.668629, -4563167299.660805, -6184002734.489236, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124, -5335107073.753951, -7575811494.113875, -3312224508.2423725, -3785296679.6516576, -4629931762.053526, -6916764296.290024, -7416581158.196318, -4485196432.7125, -4335899052.892768, -5339367823.244458, -2091126847.800735, -4891315236.905735, -5397454480.092128, -3329591144.0086308, -1416167416.3891382, -7040756492.050025, -5502702999.583421, -3517646709.5764804, -7419278265.54835]}","{'mean_env_wait_ms': 11.933587001200873, 'mean_processing_ms': 3.116449446118305, 'mean_inference_ms': 1.8096280879262452}",{},0,384000,"{'sample_time_ms': 72248.458, 'sample_throughput': 55.365, 'learn_time_ms': 19109.674, 'learn_throughput': 209.318}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.7085937500000001, 'cur_lr': 0.001, 'total_loss': 79889850171392.0, 'policy_loss': -0.00685376807814464, 'vf_loss': 79889850171392.0, 'vf_explained_var': -5.9604645e-08, 'kl': 0.013780090230284259, 'entropy': 0.606956921517849, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 1731750019465216.0, 'policy_loss': -0.008469078515190631, 'vf_loss': 1731750019465216.0, 'vf_explained_var': -4.0978193e-08, 'kl': 0.010395899938885123, 'entropy': 1.6654083989560604, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 384000, 'num_steps_trained': 384000}",False,156,96,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-46-46,1615744006,90.20906615257263,8246.005432128906,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8246.005432128906,0,96,"{'cpu_util_percent': 34.763779527559066, 'ram_util_percent': 56.214173228346446}"
192,96,MARL,gneJ12,False,-1444233443.3195717,-13903271510.926207,-6018537173.724634,2441.75,1,-6360153602.347856,-240361471.98858276,-1113094421.9455788,{},"{'episode_reward': [-4988988134.978658, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512, -6345256274.140091, -8747493966.019304, -3916128753.260735, -4363685544.600636, -5561240291.237711, -7929084316.6590395, -8780921090.918877, -5432666753.203772, -7713961206.733048, -6298544843.819634, -2503950868.622543, -10189861588.434553, -6490200671.939265, -4083380895.8101482, -1771043758.3131554, -8359525202.790905, -6632473076.682601, -4300881404.141275, -8962759686.236603, -7216269425.057859, -5360094006.758274], 'episode_lengths': [2676, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653, 2246, 2681, 2542, 2234, 2058, 2942, 3073, 2252, 2648, 2164, 2771, 2590, 2054, 2149, 2797, 3004, 2083, 2013, 2825, 2877, 1949], 'policy_gneJ12_reward': [-812713068.3697001, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882, -1010149200.3861468, -1171682471.9054458, -603904245.0183595, -578388864.9489703, -931308529.1841843, -1012320020.3690333, -1364339932.7225602, -947470320.4912701, -3378062153.840285, -959177020.5751818, -412824020.82181233, -5298546351.528854, -1092746191.8471358, -753789751.801514, -354876341.92401654, -1318768710.7408783, -1129770077.09919, -783234694.5647941, -1543481420.688249, -1146086421.3892217, -796926707.097473], 'policy_light1_reward': [-4176275066.6089425, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124, -5335107073.753951, -7575811494.113875, -3312224508.2423725, -3785296679.6516576, -4629931762.053526, -6916764296.290024, -7416581158.196318, -4485196432.7125, -4335899052.892768, -5339367823.244458, -2091126847.800735, -4891315236.905735, -5397454480.092128, -3329591144.0086308, -1416167416.3891382, -7040756492.050025, -5502702999.583421, -3517646709.5764804, -7419278265.54835, -6070183003.668629, -4563167299.660805]}","{'mean_env_wait_ms': 11.934101386432035, 'mean_processing_ms': 3.1175587021411078, 'mean_inference_ms': 1.8097781987717292}",{},0,388000,"{'sample_time_ms': 72133.156, 'sample_throughput': 55.453, 'learn_time_ms': 18824.08, 'learn_throughput': 212.494}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.7085937500000001, 'cur_lr': 0.001, 'total_loss': 43949873299456.0, 'policy_loss': -0.009070905740372837, 'vf_loss': 43949873299456.0, 'vf_explained_var': 1.4901161e-08, 'kl': 0.009283206229156349, 'entropy': 0.3356943279504776, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 1391590878740480.0, 'policy_loss': -0.004499524948187172, 'vf_loss': 1391590878740480.0, 'vf_explained_var': -2.9802322e-08, 'kl': 0.012443041523511056, 'entropy': 1.546087585389614, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 388000, 'num_steps_trained': 388000}",False,157,97,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-48-12,1615744092,85.79075908660889,8331.796191215515,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8331.796191215515,0,97,"{'cpu_util_percent': 40.59583333333333, 'ram_util_percent': 57.06166666666666}"
193,96,MARL,light1,False,-1444233443.3195717,-13903271510.926207,-6018537173.724634,2441.75,1,-8911700917.450415,-1200429389.7581913,-4905442751.779056,{},"{'episode_reward': [-4988988134.978658, -5787081395.009127, -7502081490.759654, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512, -6345256274.140091, -8747493966.019304, -3916128753.260735, -4363685544.600636, -5561240291.237711, -7929084316.6590395, -8780921090.918877, -5432666753.203772, -7713961206.733048, -6298544843.819634, -2503950868.622543, -10189861588.434553, -6490200671.939265, -4083380895.8101482, -1771043758.3131554, -8359525202.790905, -6632473076.682601, -4300881404.141275, -8962759686.236603, -7216269425.057859, -5360094006.758274], 'episode_lengths': [2676, 2962, 1960, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653, 2246, 2681, 2542, 2234, 2058, 2942, 3073, 2252, 2648, 2164, 2771, 2590, 2054, 2149, 2797, 3004, 2083, 2013, 2825, 2877, 1949], 'policy_gneJ12_reward': [-812713068.3697001, -734728779.0476569, -1098202236.9525063, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882, -1010149200.3861468, -1171682471.9054458, -603904245.0183595, -578388864.9489703, -931308529.1841843, -1012320020.3690333, -1364339932.7225602, -947470320.4912701, -3378062153.840285, -959177020.5751818, -412824020.82181233, -5298546351.528854, -1092746191.8471358, -753789751.801514, -354876341.92401654, -1318768710.7408783, -1129770077.09919, -783234694.5647941, -1543481420.688249, -1146086421.3892217, -796926707.097473], 'policy_light1_reward': [-4176275066.6089425, -5052352615.961467, -6403879253.807137, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124, -5335107073.753951, -7575811494.113875, -3312224508.2423725, -3785296679.6516576, -4629931762.053526, -6916764296.290024, -7416581158.196318, -4485196432.7125, -4335899052.892768, -5339367823.244458, -2091126847.800735, -4891315236.905735, -5397454480.092128, -3329591144.0086308, -1416167416.3891382, -7040756492.050025, -5502702999.583421, -3517646709.5764804, -7419278265.54835, -6070183003.668629, -4563167299.660805]}","{'mean_env_wait_ms': 11.934101386432035, 'mean_processing_ms': 3.1175587021411078, 'mean_inference_ms': 1.8097781987717292}",{},0,388000,"{'sample_time_ms': 72133.156, 'sample_throughput': 55.453, 'learn_time_ms': 18824.08, 'learn_throughput': 212.494}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.7085937500000001, 'cur_lr': 0.001, 'total_loss': 43949873299456.0, 'policy_loss': -0.009070905740372837, 'vf_loss': 43949873299456.0, 'vf_explained_var': 1.4901161e-08, 'kl': 0.009283206229156349, 'entropy': 0.3356943279504776, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 1391590878740480.0, 'policy_loss': -0.004499524948187172, 'vf_loss': 1391590878740480.0, 'vf_explained_var': -2.9802322e-08, 'kl': 0.012443041523511056, 'entropy': 1.546087585389614, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 388000, 'num_steps_trained': 388000}",False,157,97,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-48-12,1615744092,85.79075908660889,8331.796191215515,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8331.796191215515,0,97,"{'cpu_util_percent': 40.59583333333333, 'ram_util_percent': 57.06166666666666}"
194,97,MARL,gneJ12,False,-1444233443.3195717,-13903271510.926207,-6026069373.726589,2445.09,2,-6360153602.347856,-240361471.98858276,-1116895376.7787943,{},"{'episode_reward': [-5779784782.742201, -8262598103.222058, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512, -6345256274.140091, -8747493966.019304, -3916128753.260735, -4363685544.600636, -5561240291.237711, -7929084316.6590395, -8780921090.918877, -5432666753.203772, -7713961206.733048, -6298544843.819634, -2503950868.622543, -10189861588.434553, -6490200671.939265, -4083380895.8101482, -1771043758.3131554, -8359525202.790905, -6632473076.682601, -4300881404.141275, -8962759686.236603, -7216269425.057859, -5360094006.758274, -4988988134.978658], 'episode_lengths': [2612, 2644, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653, 2246, 2681, 2542, 2234, 2058, 2942, 3073, 2252, 2648, 2164, 2771, 2590, 2054, 2149, 2797, 3004, 2083, 2013, 2825, 2877, 1949, 2676], 'policy_gneJ12_reward': [-790332273.0687871, -1422694226.2529328, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882, -1010149200.3861468, -1171682471.9054458, -603904245.0183595, -578388864.9489703, -931308529.1841843, -1012320020.3690333, -1364339932.7225602, -947470320.4912701, -3378062153.840285, -959177020.5751818, -412824020.82181233, -5298546351.528854, -1092746191.8471358, -753789751.801514, -354876341.92401654, -1318768710.7408783, -1129770077.09919, -783234694.5647941, -1543481420.688249, -1146086421.3892217, -796926707.097473, -812713068.3697001], 'policy_light1_reward': [-4989452509.673407, -6839903876.969129, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124, -5335107073.753951, -7575811494.113875, -3312224508.2423725, -3785296679.6516576, -4629931762.053526, -6916764296.290024, -7416581158.196318, -4485196432.7125, -4335899052.892768, -5339367823.244458, -2091126847.800735, -4891315236.905735, -5397454480.092128, -3329591144.0086308, -1416167416.3891382, -7040756492.050025, -5502702999.583421, -3517646709.5764804, -7419278265.54835, -6070183003.668629, -4563167299.660805, -4176275066.6089425]}","{'mean_env_wait_ms': 11.935015481194165, 'mean_processing_ms': 3.1196197023213323, 'mean_inference_ms': 1.8100721604333296}",{},0,392000,"{'sample_time_ms': 71079.503, 'sample_throughput': 56.275, 'learn_time_ms': 18732.125, 'learn_throughput': 213.537}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.7085937500000001, 'cur_lr': 0.001, 'total_loss': 143715098558464.0, 'policy_loss': -0.009468701551668346, 'vf_loss': 143715098558464.0, 'vf_explained_var': 1.8626451e-08, 'kl': 0.0076822720729978755, 'entropy': 0.7246719691902399, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 2310187637538816.0, 'policy_loss': -0.011809399060439318, 'vf_loss': 2310187637538816.0, 'vf_explained_var': -8.940697e-08, 'kl': 0.008272425438917708, 'entropy': 1.9468516521155834, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 392000, 'num_steps_trained': 392000}",False,159,98,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-49-43,1615744183,91.05326581001282,8422.849457025528,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8422.849457025528,0,98,"{'cpu_util_percent': 28.246874999999996, 'ram_util_percent': 56.94218749999999}"
195,97,MARL,light1,False,-1444233443.3195717,-13903271510.926207,-6026069373.726589,2445.09,2,-8911700917.450415,-1200429389.7581913,-4909173996.947795,{},"{'episode_reward': [-5779784782.742201, -8262598103.222058, -13903271510.926207, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512, -6345256274.140091, -8747493966.019304, -3916128753.260735, -4363685544.600636, -5561240291.237711, -7929084316.6590395, -8780921090.918877, -5432666753.203772, -7713961206.733048, -6298544843.819634, -2503950868.622543, -10189861588.434553, -6490200671.939265, -4083380895.8101482, -1771043758.3131554, -8359525202.790905, -6632473076.682601, -4300881404.141275, -8962759686.236603, -7216269425.057859, -5360094006.758274, -4988988134.978658], 'episode_lengths': [2612, 2644, 2353, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653, 2246, 2681, 2542, 2234, 2058, 2942, 3073, 2252, 2648, 2164, 2771, 2590, 2054, 2149, 2797, 3004, 2083, 2013, 2825, 2877, 1949, 2676], 'policy_gneJ12_reward': [-790332273.0687871, -1422694226.2529328, -6360153602.347856, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882, -1010149200.3861468, -1171682471.9054458, -603904245.0183595, -578388864.9489703, -931308529.1841843, -1012320020.3690333, -1364339932.7225602, -947470320.4912701, -3378062153.840285, -959177020.5751818, -412824020.82181233, -5298546351.528854, -1092746191.8471358, -753789751.801514, -354876341.92401654, -1318768710.7408783, -1129770077.09919, -783234694.5647941, -1543481420.688249, -1146086421.3892217, -796926707.097473, -812713068.3697001], 'policy_light1_reward': [-4989452509.673407, -6839903876.969129, -7543117908.578321, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124, -5335107073.753951, -7575811494.113875, -3312224508.2423725, -3785296679.6516576, -4629931762.053526, -6916764296.290024, -7416581158.196318, -4485196432.7125, -4335899052.892768, -5339367823.244458, -2091126847.800735, -4891315236.905735, -5397454480.092128, -3329591144.0086308, -1416167416.3891382, -7040756492.050025, -5502702999.583421, -3517646709.5764804, -7419278265.54835, -6070183003.668629, -4563167299.660805, -4176275066.6089425]}","{'mean_env_wait_ms': 11.935015481194165, 'mean_processing_ms': 3.1196197023213323, 'mean_inference_ms': 1.8100721604333296}",{},0,392000,"{'sample_time_ms': 71079.503, 'sample_throughput': 56.275, 'learn_time_ms': 18732.125, 'learn_throughput': 213.537}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.7085937500000001, 'cur_lr': 0.001, 'total_loss': 143715098558464.0, 'policy_loss': -0.009468701551668346, 'vf_loss': 143715098558464.0, 'vf_explained_var': 1.8626451e-08, 'kl': 0.0076822720729978755, 'entropy': 0.7246719691902399, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 2310187637538816.0, 'policy_loss': -0.011809399060439318, 'vf_loss': 2310187637538816.0, 'vf_explained_var': -8.940697e-08, 'kl': 0.008272425438917708, 'entropy': 1.9468516521155834, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 392000, 'num_steps_trained': 392000}",False,159,98,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-49-43,1615744183,91.05326581001282,8422.849457025528,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8422.849457025528,0,98,"{'cpu_util_percent': 28.246874999999996, 'ram_util_percent': 56.94218749999999}"
196,98,MARL,gneJ12,False,-1444233443.3195717,-10319368058.19908,-5948930531.759937,2450.92,1,-5298546351.528854,-240361471.98858276,-1062549196.1113282,{},"{'episode_reward': [-6189387314.261108, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512, -6345256274.140091, -8747493966.019304, -3916128753.260735, -4363685544.600636, -5561240291.237711, -7929084316.6590395, -8780921090.918877, -5432666753.203772, -7713961206.733048, -6298544843.819634, -2503950868.622543, -10189861588.434553, -6490200671.939265, -4083380895.8101482, -1771043758.3131554, -8359525202.790905, -6632473076.682601, -4300881404.141275, -8962759686.236603, -7216269425.057859, -5360094006.758274, -4988988134.978658, -5779784782.742201, -8262598103.222058], 'episode_lengths': [2936, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653, 2246, 2681, 2542, 2234, 2058, 2942, 3073, 2252, 2648, 2164, 2771, 2590, 2054, 2149, 2797, 3004, 2083, 2013, 2825, 2877, 1949, 2676, 2612, 2644], 'policy_gneJ12_reward': [-925535535.6012557, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882, -1010149200.3861468, -1171682471.9054458, -603904245.0183595, -578388864.9489703, -931308529.1841843, -1012320020.3690333, -1364339932.7225602, -947470320.4912701, -3378062153.840285, -959177020.5751818, -412824020.82181233, -5298546351.528854, -1092746191.8471358, -753789751.801514, -354876341.92401654, -1318768710.7408783, -1129770077.09919, -783234694.5647941, -1543481420.688249, -1146086421.3892217, -796926707.097473, -812713068.3697001, -790332273.0687871, -1422694226.2529328], 'policy_light1_reward': [-5263851778.659844, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124, -5335107073.753951, -7575811494.113875, -3312224508.2423725, -3785296679.6516576, -4629931762.053526, -6916764296.290024, -7416581158.196318, -4485196432.7125, -4335899052.892768, -5339367823.244458, -2091126847.800735, -4891315236.905735, -5397454480.092128, -3329591144.0086308, -1416167416.3891382, -7040756492.050025, -5502702999.583421, -3517646709.5764804, -7419278265.54835, -6070183003.668629, -4563167299.660805, -4176275066.6089425, -4989452509.673407, -6839903876.969129]}","{'mean_env_wait_ms': 11.935422186363015, 'mean_processing_ms': 3.120365744851695, 'mean_inference_ms': 1.8102141527984563}",{},0,396000,"{'sample_time_ms': 69433.384, 'sample_throughput': 57.609, 'learn_time_ms': 18420.717, 'learn_throughput': 217.147}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.7085937500000001, 'cur_lr': 0.001, 'total_loss': 30929950932992.0, 'policy_loss': -0.0011024671257473528, 'vf_loss': 30929950932992.0, 'vf_explained_var': -4.4703484e-08, 'kl': 0.02392212316772202, 'entropy': -0.006926255766302347, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 888834585788416.0, 'policy_loss': -0.0023077832302078605, 'vf_loss': 888834585788416.0, 'vf_explained_var': 1.3038516e-08, 'kl': 0.009898052492644638, 'entropy': 1.1975744105875492, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 396000, 'num_steps_trained': 396000}",False,160,99,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-51-02,1615744262,79.19363975524902,8502.043096780777,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8502.043096780777,0,99,"{'cpu_util_percent': 29.64324324324324, 'ram_util_percent': 56.91081081081078}"
197,98,MARL,light1,False,-1444233443.3195717,-10319368058.19908,-5948930531.759937,2450.92,1,-8911700917.450415,-1200429389.7581913,-4886381335.648609,{},"{'episode_reward': [-6189387314.261108, -7408462047.101337, -5012328777.292989, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512, -6345256274.140091, -8747493966.019304, -3916128753.260735, -4363685544.600636, -5561240291.237711, -7929084316.6590395, -8780921090.918877, -5432666753.203772, -7713961206.733048, -6298544843.819634, -2503950868.622543, -10189861588.434553, -6490200671.939265, -4083380895.8101482, -1771043758.3131554, -8359525202.790905, -6632473076.682601, -4300881404.141275, -8962759686.236603, -7216269425.057859, -5360094006.758274, -4988988134.978658, -5779784782.742201, -8262598103.222058], 'episode_lengths': [2936, 2759, 2772, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653, 2246, 2681, 2542, 2234, 2058, 2942, 3073, 2252, 2648, 2164, 2771, 2590, 2054, 2149, 2797, 3004, 2083, 2013, 2825, 2877, 1949, 2676, 2612, 2644], 'policy_gneJ12_reward': [-925535535.6012557, -1164611680.418224, -671991082.9004169, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882, -1010149200.3861468, -1171682471.9054458, -603904245.0183595, -578388864.9489703, -931308529.1841843, -1012320020.3690333, -1364339932.7225602, -947470320.4912701, -3378062153.840285, -959177020.5751818, -412824020.82181233, -5298546351.528854, -1092746191.8471358, -753789751.801514, -354876341.92401654, -1318768710.7408783, -1129770077.09919, -783234694.5647941, -1543481420.688249, -1146086421.3892217, -796926707.097473, -812713068.3697001, -790332273.0687871, -1422694226.2529328], 'policy_light1_reward': [-5263851778.659844, -6243850366.683111, -4340337694.392566, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124, -5335107073.753951, -7575811494.113875, -3312224508.2423725, -3785296679.6516576, -4629931762.053526, -6916764296.290024, -7416581158.196318, -4485196432.7125, -4335899052.892768, -5339367823.244458, -2091126847.800735, -4891315236.905735, -5397454480.092128, -3329591144.0086308, -1416167416.3891382, -7040756492.050025, -5502702999.583421, -3517646709.5764804, -7419278265.54835, -6070183003.668629, -4563167299.660805, -4176275066.6089425, -4989452509.673407, -6839903876.969129]}","{'mean_env_wait_ms': 11.935422186363015, 'mean_processing_ms': 3.120365744851695, 'mean_inference_ms': 1.8102141527984563}",{},0,396000,"{'sample_time_ms': 69433.384, 'sample_throughput': 57.609, 'learn_time_ms': 18420.717, 'learn_throughput': 217.147}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.7085937500000001, 'cur_lr': 0.001, 'total_loss': 30929950932992.0, 'policy_loss': -0.0011024671257473528, 'vf_loss': 30929950932992.0, 'vf_explained_var': -4.4703484e-08, 'kl': 0.02392212316772202, 'entropy': -0.006926255766302347, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 888834585788416.0, 'policy_loss': -0.0023077832302078605, 'vf_loss': 888834585788416.0, 'vf_explained_var': 1.3038516e-08, 'kl': 0.009898052492644638, 'entropy': 1.1975744105875492, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 396000, 'num_steps_trained': 396000}",False,160,99,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-51-02,1615744262,79.19363975524902,8502.043096780777,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8502.043096780777,0,99,"{'cpu_util_percent': 29.64324324324324, 'ram_util_percent': 56.91081081081078}"
198,99,MARL,gneJ12,False,-1444233443.3195717,-10319368058.19908,-5943053836.104506,2450.69,2,-5298546351.528854,-240361471.98858276,-1090120663.2094338,{},"{'episode_reward': [-3266658428.8556767, -8566462829.995478, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512, -6345256274.140091, -8747493966.019304, -3916128753.260735, -4363685544.600636, -5561240291.237711, -7929084316.6590395, -8780921090.918877, -5432666753.203772, -7713961206.733048, -6298544843.819634, -2503950868.622543, -10189861588.434553, -6490200671.939265, -4083380895.8101482, -1771043758.3131554, -8359525202.790905, -6632473076.682601, -4300881404.141275, -8962759686.236603, -7216269425.057859, -5360094006.758274, -4988988134.978658, -5779784782.742201, -8262598103.222058, -6189387314.261108], 'episode_lengths': [3046, 2462, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653, 2246, 2681, 2542, 2234, 2058, 2942, 3073, 2252, 2648, 2164, 2771, 2590, 2054, 2149, 2797, 3004, 2083, 2013, 2825, 2877, 1949, 2676, 2612, 2644, 2936], 'policy_gneJ12_reward': [-455890809.15184647, -4137858663.977332, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882, -1010149200.3861468, -1171682471.9054458, -603904245.0183595, -578388864.9489703, -931308529.1841843, -1012320020.3690333, -1364339932.7225602, -947470320.4912701, -3378062153.840285, -959177020.5751818, -412824020.82181233, -5298546351.528854, -1092746191.8471358, -753789751.801514, -354876341.92401654, -1318768710.7408783, -1129770077.09919, -783234694.5647941, -1543481420.688249, -1146086421.3892217, -796926707.097473, -812713068.3697001, -790332273.0687871, -1422694226.2529328, -925535535.6012557], 'policy_light1_reward': [-2810767619.703829, -4428604166.018175, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124, -5335107073.753951, -7575811494.113875, -3312224508.2423725, -3785296679.6516576, -4629931762.053526, -6916764296.290024, -7416581158.196318, -4485196432.7125, -4335899052.892768, -5339367823.244458, -2091126847.800735, -4891315236.905735, -5397454480.092128, -3329591144.0086308, -1416167416.3891382, -7040756492.050025, -5502702999.583421, -3517646709.5764804, -7419278265.54835, -6070183003.668629, -4563167299.660805, -4176275066.6089425, -4989452509.673407, -6839903876.969129, -5263851778.659844]}","{'mean_env_wait_ms': 11.936516275490543, 'mean_processing_ms': 3.1222576217864355, 'mean_inference_ms': 1.8105320635278956}",{},0,400000,"{'sample_time_ms': 69957.298, 'sample_throughput': 57.178, 'learn_time_ms': 18387.886, 'learn_throughput': 217.535}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.562890625, 'cur_lr': 0.001, 'total_loss': 1142749233414144.0, 'policy_loss': 0.0028638928779400885, 'vf_loss': 1142749233414144.0, 'vf_explained_var': -1.1175871e-08, 'kl': 0.010976634999678936, 'entropy': 0.5590854920446873, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 1159861964374016.0, 'policy_loss': -0.012690436735283583, 'vf_loss': 1159861964374016.0, 'vf_explained_var': 6.146729e-08, 'kl': 0.009699366048153024, 'entropy': 1.6093596816062927, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 400000, 'num_steps_trained': 400000}",False,162,100,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-52-36,1615744356,93.2042760848999,8595.247372865677,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8595.247372865677,0,100,"{'cpu_util_percent': 35.78091603053435, 'ram_util_percent': 56.97709923664122}"
199,99,MARL,light1,False,-1444233443.3195717,-10319368058.19908,-5943053836.104506,2450.69,2,-8911700917.450415,-1200429389.7581913,-4852933172.895073,{},"{'episode_reward': [-3266658428.8556767, -8566462829.995478, -2417432422.48234, -5599793768.616113, -4272085435.506847, -6929809377.830323, -1686754835.8733134, -7411107361.832801, -4639905152.603937, -8429769091.925227, -7891335683.515518, -5891909446.885428, -2200733305.7762156, -3023365255.209923, -7664817717.674085, -10319368058.19908, -6409178763.96813, -4998279002.191491, -4129652171.3543386, -3096926695.15342, -6719203995.772927, -7239842065.5500145, -2469182055.903954, -3232931303.8067436, -5477981833.357709, -6629418058.777674, -8122143510.3583355, -2546354459.6854653, -10088638675.472885, -9161855599.02221, -1755536547.973253, -4401198718.008069, -10159391130.441244, -8578569471.075841, -7682975338.08967, -10109422670.647093, -3070566084.3977823, -7063168522.918712, -4337888901.664533, -7333638237.264958, -6293488093.421741, -6207584560.953309, -5342779711.51648, -1492193727.9310474, -5086973722.37946, -5809425999.603443, -5583340389.3349695, -8262016890.165334, -3544071693.232634, -3495744691.473967, -3121846543.736691, -7885309264.72593, -7726902498.753979, -4117389826.929455, -3112356562.179847, -7293927110.61356, -8065336836.090649, -3090659570.922184, -8554029376.3252325, -7436354967.230244, -7968182171.15419, -2382050929.558002, -4731716370.43546, -6666458452.552175, -6498694863.347114, -1444233443.3195717, -6510302927.534121, -6084356466.57016, -8894228840.062227, -7846510150.3855095, -7394856433.587324, -6384312330.904245, -6642184232.968674, -7150941804.425393, -4979188209.903512, -6345256274.140091, -8747493966.019304, -3916128753.260735, -4363685544.600636, -5561240291.237711, -7929084316.6590395, -8780921090.918877, -5432666753.203772, -7713961206.733048, -6298544843.819634, -2503950868.622543, -10189861588.434553, -6490200671.939265, -4083380895.8101482, -1771043758.3131554, -8359525202.790905, -6632473076.682601, -4300881404.141275, -8962759686.236603, -7216269425.057859, -5360094006.758274, -4988988134.978658, -5779784782.742201, -8262598103.222058, -6189387314.261108], 'episode_lengths': [3046, 2462, 2735, 1744, 2383, 2092, 1751, 2490, 2454, 2284, 2690, 2680, 2828, 1709, 2699, 3107, 2207, 2385, 2886, 1865, 2145, 2950, 1590, 2037, 2144, 2447, 2474, 2780, 2885, 2915, 1629, 1865, 2961, 2914, 2636, 2956, 2280, 2926, 2503, 2559, 2156, 2946, 2531, 2431, 2285, 1902, 2119, 2679, 2784, 1803, 2605, 2763, 2751, 2011, 1668, 2748, 2529, 2748, 3027, 2385, 2691, 1935, 2543, 2272, 2129, 2124, 1995, 3051, 2999, 2605, 2939, 2121, 2202, 2026, 1653, 2246, 2681, 2542, 2234, 2058, 2942, 3073, 2252, 2648, 2164, 2771, 2590, 2054, 2149, 2797, 3004, 2083, 2013, 2825, 2877, 1949, 2676, 2612, 2644, 2936], 'policy_gneJ12_reward': [-455890809.15184647, -4137858663.977332, -300039252.8852076, -844624085.897139, -688232558.147012, -1070868767.743339, -287137176.1454663, -1293453692.8043478, -724660140.7607212, -4068779683.6180153, -1256913074.1409013, -901115457.074669, -335037224.7266496, -396865326.8800977, -1046594547.2681506, -1407667140.7486799, -945017381.9076248, -822993752.3205738, -705244936.0510466, -465166408.38311154, -1080475317.5374076, -1214397546.5526025, -376314002.68504137, -493933796.4141268, -909809534.7084033, -1124942767.6886528, -2929168253.5400286, -390514374.14264065, -1271372927.9860237, -1403547595.7073157, -329488228.0422415, -642479678.7980547, -3610339306.861568, -1273956617.0817642, -1932314421.7172155, -1470186295.3253741, -459109979.3895999, -894171971.0820235, -619145639.4702997, -1204831790.6013885, -1090377955.4048524, -895584598.6864187, -689148798.0495437, -240361471.98858276, -734672239.7103533, -877936282.0853721, -855170166.1095194, -1234332402.5819883, -585805773.4265519, -518099863.981158, -472614073.474828, -1268253222.4443936, -1080165470.1456554, -536590291.3253861, -424987865.27157956, -1607514609.0146015, -1163373683.253074, -452805668.15621835, -1193868000.630011, -2060890627.4786792, -1151046276.113098, -371659347.2860377, -711725687.1286288, -931092535.4871192, -908664577.0884508, -243804053.56138143, -922801840.5163531, -908122958.086771, -1248261807.6263287, -942666099.8653208, -1004126422.7128243, -904888550.263196, -2756403206.8506866, -962571938.1070608, -737889278.8303882, -1010149200.3861468, -1171682471.9054458, -603904245.0183595, -578388864.9489703, -931308529.1841843, -1012320020.3690333, -1364339932.7225602, -947470320.4912701, -3378062153.840285, -959177020.5751818, -412824020.82181233, -5298546351.528854, -1092746191.8471358, -753789751.801514, -354876341.92401654, -1318768710.7408783, -1129770077.09919, -783234694.5647941, -1543481420.688249, -1146086421.3892217, -796926707.097473, -812713068.3697001, -790332273.0687871, -1422694226.2529328, -925535535.6012557], 'policy_light1_reward': [-2810767619.703829, -4428604166.018175, -2117393169.5971327, -4755169682.718984, -3583852877.3598323, -5858940610.086982, -1399617659.7278473, -6117653669.028437, -3915245011.8432126, -4360989408.307195, -6634422609.37463, -4990793989.810763, -1865696081.049564, -2626499928.329827, -6618223170.405935, -8911700917.450415, -5464161382.060507, -4175285249.8709173, -3424407235.3032975, -2631760286.770302, -5638728678.235514, -6025444518.997421, -2092868053.2189114, -2738997507.3926215, -4568172298.649288, -5504475291.089009, -5192975256.818316, -2155840085.5428247, -8817265747.486847, -7758308003.314882, -1426048319.9310126, -3758719039.2100058, -6549051823.579716, -7304612853.994057, -5750660916.3724575, -8639236375.32171, -2611456105.0081816, -6168996551.836704, -3718743262.194234, -6128806446.66358, -5203110138.016882, -5311999962.266876, -4653630913.46693, -1251832255.9424639, -4352301482.669098, -4931489717.51806, -4728170223.225439, -7027684487.5833435, -2958265919.8060827, -2977644827.492804, -2649232470.2618575, -6617056042.281524, -6646737028.608324, -3580799535.6040707, -2687368696.90827, -5686412501.598962, -6901963152.837594, -2637853902.7659593, -7360161375.695224, -5375464339.751551, -6817135895.041087, -2010391582.271968, -4019990683.3068314, -5735365917.065057, -5590030286.258678, -1200429389.7581913, -5587501087.017774, -5176233508.483386, -7645967032.435898, -6903844050.520193, -6390730010.874503, -5479423780.6410475, -3885781026.117995, -6188369866.3183155, -4241298931.073124, -5335107073.753951, -7575811494.113875, -3312224508.2423725, -3785296679.6516576, -4629931762.053526, -6916764296.290024, -7416581158.196318, -4485196432.7125, -4335899052.892768, -5339367823.244458, -2091126847.800735, -4891315236.905735, -5397454480.092128, -3329591144.0086308, -1416167416.3891382, -7040756492.050025, -5502702999.583421, -3517646709.5764804, -7419278265.54835, -6070183003.668629, -4563167299.660805, -4176275066.6089425, -4989452509.673407, -6839903876.969129, -5263851778.659844]}","{'mean_env_wait_ms': 11.936516275490543, 'mean_processing_ms': 3.1222576217864355, 'mean_inference_ms': 1.8105320635278956}",{},0,400000,"{'sample_time_ms': 69957.298, 'sample_throughput': 57.178, 'learn_time_ms': 18387.886, 'learn_throughput': 217.535}","{'learner': {'gneJ12': {'allreduce_latency': 0.0, 'cur_kl_coeff': 2.562890625, 'cur_lr': 0.001, 'total_loss': 1142749233414144.0, 'policy_loss': 0.0028638928779400885, 'vf_loss': 1142749233414144.0, 'vf_explained_var': -1.1175871e-08, 'kl': 0.010976634999678936, 'entropy': 0.5590854920446873, 'entropy_coeff': 0.0}, 'light1': {'allreduce_latency': 0.0, 'cur_kl_coeff': 1.5187500000000003, 'cur_lr': 0.001, 'total_loss': 1159861964374016.0, 'policy_loss': -0.012690436735283583, 'vf_loss': 1159861964374016.0, 'vf_explained_var': 6.146729e-08, 'kl': 0.009699366048153024, 'entropy': 1.6093596816062927, 'entropy_coeff': 0.0}}, 'num_steps_sampled': 400000, 'num_steps_trained': 400000}",False,162,100,b5e8f242cd86420ab1b01de99736eb45,2021-03-14_13-52-36,1615744356,93.2042760848999,8595.247372865677,24757,nathaniels-imac.lan,192.168.86.26,"{'num_workers': 0, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'custom_options': -1}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {'gui': False, 'net-file': 'configs/two_inter/two_inter.net.xml', 'rand_routes_on_reset': True}, 'env': 'MultiPolicySumoEnv', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 0.001, 'monitor': False, 'log_level': 'ERROR', 'callbacks': <class 'ray.rllib.agents.callbacks.DefaultCallbacks'>, 'ignore_worker_failures': False, 'log_sys_usage': True, 'fake_sampler': False, 'framework': 'torch', 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'sample_async': False, '_use_trajectory_view_api': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {'gneJ12': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95}), 'light1': (<class 'ray.rllib.policy.torch_policy_template.PPOTorchPolicy'>, Box(7,), Box(1,), {'gamma': 0.95})}, 'policy_mapping_fn': <function multiagent_ray_train.<locals>.<lambda> at 0x16bc371f0>, 'policies_to_train': None, 'observation_fn': None, 'replay_mode': 'independent'}, 'replay_sequence_length': 1, 'use_pytorch': -1, 'eager': -1, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': True, '_fake_gpus': False}",8595.247372865677,0,100,"{'cpu_util_percent': 35.78091603053435, 'ram_util_percent': 56.97709923664122}"
